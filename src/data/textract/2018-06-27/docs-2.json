{
  "version": "2.0",
  "service": "<p>Amazon Textract detects and analyzes text in documents and converts it into machine-readable text. This is the API reference documentation for Amazon Textract.</p>",
  "operations": {
    "AnalyzeDocument": "<p>Analyzes an input document for relationships in the detected text and tables. </p> <p>Two types of information are returned: </p> <ul> <li> <p>Words and lines that are related to nearby lines and words. The related information is returned in two <a>Block</a> objects: a KEY Block object and a VALUE Block object. For example, <i>Name: Ana Silva Carolina</i> contains a key and value. <i>Name:</i> is the key. <i>Ana Silva Carolina</i> is the value.</p> </li> <li> <p>Table and table cell data. A TABLE Block contains information about a detected table. A CELL block is returned for each cell in a table.</p> </li> </ul> <p>You can choose which type of analysis to perform by specifying the <code>FeatureTypes</code> list. </p> <p>The output is returned in a list of <code>BLOCK</code> objects (Blocks). For more information, see <a>how-it-works-analyzing</a>.</p> <p> <code>AnalyzeDocument</code> is a synchronous operation. To analyze documents asynchronously, use <a>StartDocumentAnalysis</a>.</p>",
    "DetectDocumentText": "<p>Detects text in the input document. Amazon Textract can detect lines of text and the words that make up a line of text. The input document must be an image in JPG or PNG format. <code>DetectDocumentText</code> returns the detected text in an array of <a>Block</a> objects. For more information, see <a>how-it-works-detecting</a>.</p> <p> <code>DetectDocumentText</code> is a synchronous operation. To analyze documents asynchronously, use <a>StartDocumentTextDetection</a>.</p>",
    "GetDocumentAnalysis": "<p>Gets the results for an Amazon Textract asynchronous operation that analyzes text in a document image.</p> <p>You start asynchronous text analysis by calling <a>StartDocumentAnalysis</a>, which returns a job identifier (<code>JobId</code>). When the text analysis operation finishes, Amazon Textract publishes a completion status to the Amazon Simple Notification Service (Amazon SNS) topic that's registered in the initial call to <code>StartDocumentAnalysis</code>. To get the results of the text-detection operation, first check that the status value published to the Amazon SNS topic is <code>SUCCEEDED</code>. If so, call <code>GetDocumentAnalysis</code>, and pass the job identifier (<code>JobId</code>) from the initial call to <code>StartDocumentAnalysis</code>.</p> <p> <code>GetDocumentAnalysis</code> returns an array of <a>Block</a> objects. For more information, see <a>how-it-works-analyzing</a>.</p> <p>Use the <code>MaxResults</code> parameter to limit the number of blocks returned. If there are more results than specified in <code>MaxResults</code>, the value of <code>NextToken</code> in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call <code>GetDocumentAnalysis</code>, and populate the <code>NextToken</code> request parameter with the token value that's returned from the previous call to <code>GetDocumentAnalysis</code>.</p>",
    "GetDocumentTextDetection": "<p>Gets the results for an Amazon Textract asynchronous operation that detects text in a document image. Amazon Textract can detect lines of text and the words that make up a line of text.</p> <p>You start asynchronous text detection by calling <a>StartDocumentTextDetection</a>, which returns a job identifier (<code>JobId</code>). When the text detection operation finishes, Amazon Textract publishes a completion status to the Amazon Simple Notification Service (Amazon SNS) topic that's registered in the initial call to <code>StartDocumentTextDetection</code>. To get the results of the text-detection operation, first check that the status value published to the Amazon SNS topic is <code>SUCCEEDED</code>. If so, call <code>GetDocumentTextDetection</code>, and pass the job identifier (<code>JobId</code>) from the initial call to <code>StartDocumentTextDetection</code>.</p> <p> <code>GetDocumentTextDetection</code> returns an array of <a>Block</a> objects. For more information, see <a>how-it-works-detecting</a>.</p> <p>Use the MaxResults parameter to limit the number of blocks that are returned. If there are more results than specified in <code>MaxResults</code>, the value of <code>NextToken</code> in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call <code>GetDocumentTextDetection</code>, and populate the <code>NextToken</code> request parameter with the token value that's returned from the previous call to <code>GetDocumentTextDetection</code>.</p> <p>For more information, see Document Text Detection in the Amazon Textract Developer Guide.</p>",
    "StartDocumentAnalysis": "<p>Starts asynchronous analysis of text for relationships in the text and tables that are detected in a document. Amazon Textract returns for two types of information: </p> <ul> <li> <p>Words and lines that are related to nearby lines and words. The related information is returned in two <a>Block</a> objects: A KEY Block object and a VALUE Block object. For example, <i>Name: Ana Silva Carolina</i> contains a key and value. <i>Name:</i> is the key. <i>Ana Silva Carolina</i> is the value.</p> </li> <li> <p>Table and table cell data. A TABLE block contains information about a detected table. A CELL block is returned for each cell in a table.</p> </li> </ul> <p>Amazon Textract can analyze text in document images and PDF files that are stored in an Amazon S3 bucket. Use <a>DocumentLocation</a> to specify the bucket name and file name of the document image. </p> <p> <code>StartDocumentAnalysis</code> returns a job identifier (<code>JobId</code>) that you use to get the results of the operation. When text analysis is finished, Amazon Textract publishes a completion status to the Amazon Simple Notification Service (Amazon SNS) topic that you specify in <code>NotificationChannel</code>. To get the results of the text analysis operation, first check that the status value published to the Amazon SNS topic is <code>SUCCEEDED</code>. If so, call <a>GetDocumentAnalysis</a>, and pass the job identifier (<code>JobId</code>) from the initial call to <code>StartDocumentAnalysis</code>.</p>",
    "StartDocumentTextDetection": "<p>Starts the asynchronous detection of text in a document. Amazon Textract can detect lines of text and the words that make up a line of text.</p> <p>Amazon Textract can detect text in document images and PDF files that are stored in an Amazon S3 bucket. Use <a>DocumentLocation</a> to specify the bucket name and the file name of the document image. </p> <p> <code>StartTextDetection</code> returns a job identifier (<code>JobId</code>) that you use to get the results of the operation. When text detection is finished, Amazon Textract publishes a completion status to the Amazon Simple Notification Service (Amazon SNS) topic that you specify in <code>NotificationChannel</code>. To get the results of the text detection operation, first check that the status value published to the Amazon SNS topic is <code>SUCCEEDED</code>. If so, call <a>GetDocumentTextDetection</a>, and pass the job identifier (<code>JobId</code>) from the initial call to <code>StartDocumentTextDetection</code>.</p> <p>For more information, see Document Text Detection in the Amazon Textract Developer Guide.</p>"
  },
  "shapes": {
    "AccessDeniedException": {
      "base": "<p>You aren't authorized to perform the action.</p>",
      "refs": {
      }
    },
    "AnalyzeDocumentRequest": {
      "base": null,
      "refs": {
      }
    },
    "AnalyzeDocumentResponse": {
      "base": null,
      "refs": {
      }
    },
    "BadDocumentException": {
      "base": "<p>Amazon Textract isn't able to read the document.</p>",
      "refs": {
      }
    },
    "Block": {
      "base": "<p>A <code>Block</code> represents text that's recognized in a document within a group of pixels close to each other. The information returned in a <code>Block</code> depends on the type of operation. In document-text detection (for example <a>DetectDocumentText</a>), you get information about the detected words and lines of text. In text analysis (for example <a>AnalyzeDocument</a>), you can get information about the fields and tables that are detected in the document.</p> <p>An array of <code>Block</code> objects is returned by both synchronous and asynchronous operations. In synchronous operations, such as <a>DetectDocumentText</a>, the array of <code>Block</code> objects is the entire set of results. In asynchronous operations, such as <a>GetDocumentAnalysis</a>, the array is returned over one or more responses.</p>",
      "refs": {
        "BlockList$member": null
      }
    },
    "BlockList": {
      "base": null,
      "refs": {
        "AnalyzeDocumentResponse$Blocks": "<p>The text that's detected and analyzed by <code>AnalyzeDocument</code>.</p>",
        "DetectDocumentTextResponse$Blocks": "<p>An array of Block objects containing the text detected in the document.</p>",
        "GetDocumentAnalysisResponse$Blocks": "<p>The results of the text analysis operation.</p>",
        "GetDocumentTextDetectionResponse$Blocks": "<p>The results of the text-detection operation.</p>"
      }
    },
    "BlockType": {
      "base": null,
      "refs": {
        "Block$BlockType": "<p>The type of text that's recognized in a block. In text-detection operations, the following types are returned:</p> <ul> <li> <p> <i>PAGE</i> - Contains a list of the LINE Block objects that are detected on a specific page.</p> </li> <li> <p> <i>WORD</i> - One or more ISO basic Latin script characters that aren't separated by spaces.</p> </li> <li> <p> <i>LINE</i> - A string of equally spaced words.</p> </li> </ul> <p>In text analysis operations, the following types are returned:</p> <ul> <li> <p> <i>PAGE</i> - Contains a list of child Block objects that are detected on a specific page.</p> </li> <li> <p> <i>KEY_VALUE_SET</i> - Stores the KEY and VALUE Block objects for a field that's detected in a document. Use the <code>EntityType</code> field to determine if a KEY_VALUE_SET object is a KEY Block object or a VALUE Block object. </p> </li> <li> <p> <i>WORD</i> - One or more ISO basic Latin script characters that aren't separated by spaces.</p> </li> <li> <p> <i>LINE</i> - A string of tab-delimited, contiguous words.</p> </li> <li> <p> <i>TABLE</i> - A table that's detected in the document.</p> </li> <li> <p> <i>CELL</i> - A cell within a detected table. The cell is the parent of the block that contains the text in the cell.</p> </li> </ul>"
      }
    },
    "BoundingBox": {
      "base": "<p>The bounding box around the recognized text, key, value, table or table cell on a document page. The <code>left</code> (x-coordinate) and <code>top</code> (y-coordinate) are coordinates that represent the top and left sides of the bounding box. Note that the upper-left corner of the image is the origin (0,0). </p> <p>The <code>top</code> and <code>left</code> values returned are ratios of the overall document page size. For example, if the input image is 700 x 200 pixels, and the top-left coordinate of the bounding box is 350 x 50 pixels, the API returns a <code>left</code> value of 0.5 (350/700) and a <code>top</code> value of 0.25 (50/200).</p> <p>The <code>width</code> and <code>height</code> values represent the dimensions of the bounding box as a ratio of the overall document page dimension. For example, if the document page size is 700 x 200 pixels, and the bounding box width is 70 pixels, the width returned is 0.1. </p>",
      "refs": {
        "Geometry$BoundingBox": "<p>An axis-aligned coarse representation of the location of the recognized text on the document page.</p>"
      }
    },
    "ClientRequestToken": {
      "base": null,
      "refs": {
        "StartDocumentAnalysisRequest$ClientRequestToken": "<p>The idempotent token that you use to identify the start request. If you use the same token with multiple <code>StartDocumentAnalysis</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidentally started more than once. </p>",
        "StartDocumentTextDetectionRequest$ClientRequestToken": "<p>The idempotent token that's used to identify the start request. If you use the same token with multiple <code>StartDocumentTextDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidentally started more than once. </p>"
      }
    },
    "DetectDocumentTextRequest": {
      "base": null,
      "refs": {
      }
    },
    "DetectDocumentTextResponse": {
      "base": null,
      "refs": {
      }
    },
    "Document": {
      "base": "<p>The input document, either as bytes or as an S3 object.</p> <p>You pass image bytes to an Amazon Textract API operation by using the <code>Bytes</code> property. For example, you would use the <code>Bytes</code> property to pass a document loaded from a local file system. Image bytes passed by using the <code>Bytes</code> property must be base64 encoded. Your code might not need to encode document file bytes if you're using an AWS SDK to call Amazon Textract API operations. </p> <p>You pass images stored in an S3 bucket to an Amazon Textract API operation by using the <code>S3Object</code> property. Documents stored in an S3 bucket don't need to be base64 encoded.</p> <p>The AWS Region for the S3 bucket that contains the S3 object must match the Region that you use for Amazon Textract operations.</p> <p>If you use the AWS CLI to call Amazon Textract operations, passing image bytes using the Bytes property isn't supported. You must first upload the document to an Amazon S3 bucket, and then call the operation using the S3Object property.</p> <p>For Amazon Textract to process an S3 object, the user must have permission to access the S3 object. </p>",
      "refs": {
        "AnalyzeDocumentRequest$Document": "<p>The input document as base64-encoded bytes or an Amazon S3 object. If you use the AWS CLI to call Amazon Textract operations, you can't pass image bytes. The document must be an image in JPG or PNG format.</p>",
        "DetectDocumentTextRequest$Document": "<p>The input document as base64-encoded bytes or an Amazon S3 object. If you use the AWS CLI to call Amazon Textract operations, you can't pass image bytes. The document must be an image in JPG or PNG format.</p>"
      }
    },
    "DocumentLocation": {
      "base": "<p>The Amazon S3 bucket that contains the document to be processed. It's used by asynchronous operations such as <a>StartDocumentTextDetection</a>.</p> <p>The input document can be an image file in JPG or PNG format. It can also be a file in PDF format.</p>",
      "refs": {
        "StartDocumentAnalysisRequest$DocumentLocation": "<p>The location of the document to be processed.</p>",
        "StartDocumentTextDetectionRequest$DocumentLocation": "<p>The location of the document to be processed.</p>"
      }
    },
    "DocumentMetadata": {
      "base": "<p>Information about the input document.</p>",
      "refs": {
        "AnalyzeDocumentResponse$DocumentMetadata": "<p>Metadata about the analyzed document. An example is the number of pages.</p>",
        "DetectDocumentTextResponse$DocumentMetadata": "<p>Metadata about the document. Contains the number of pages that are detected in the document.</p>",
        "GetDocumentAnalysisResponse$DocumentMetadata": "<p>Information about a document that Amazon Textract processed. <code>DocumentMetadata</code> is returned in every page of paginated responses from an Amazon Textract video operation.</p>",
        "GetDocumentTextDetectionResponse$DocumentMetadata": "<p>Information about a document that Amazon Textract processed. <code>DocumentMetadata</code> is returned in every page of paginated responses from an Amazon Textract video operation.</p>"
      }
    },
    "DocumentTooLargeException": {
      "base": "<p>The document can't be processed because it's too large. The maximum document size for synchronous operations 5 MB. The maximum document size for asynchronous operations is 500 MB for PDF format files.</p>",
      "refs": {
      }
    },
    "EntityType": {
      "base": null,
      "refs": {
        "EntityTypes$member": null
      }
    },
    "EntityTypes": {
      "base": null,
      "refs": {
        "Block$EntityTypes": "<p>The type of entity. The following can be returned:</p> <ul> <li> <p> <i>KEY</i> - An identifier for a field on the document.</p> </li> <li> <p> <i>VALUE</i> - The field text.</p> </li> </ul> <p> <code>EntityTypes</code> isn't returned by <code>DetectDocumentText</code> and <code>GetDocumentTextDetection</code>.</p>"
      }
    },
    "ErrorCode": {
      "base": null,
      "refs": {
        "Warning$ErrorCode": "<p>The error code for the warning.</p>"
      }
    },
    "FeatureType": {
      "base": null,
      "refs": {
        "FeatureTypes$member": null
      }
    },
    "FeatureTypes": {
      "base": null,
      "refs": {
        "AnalyzeDocumentRequest$FeatureTypes": "<p>A list of the types of analysis to perform. Add TABLES to the list to return information about the tables detected in the input document. Add FORMS to return detected fields and the associated text. To perform both types of analysis, add TABLES and FORMS to <code>FeatureTypes</code>.</p>",
        "StartDocumentAnalysisRequest$FeatureTypes": "<p>A list of the types of analysis to perform. Add TABLES to the list to return information about the tables that are detected in the input document. Add FORMS to return detected fields and the associated text. To perform both types of analysis, add TABLES and FORMS to <code>FeatureTypes</code>.</p>"
      }
    },
    "Float": {
      "base": null,
      "refs": {
        "BoundingBox$Width": "<p>The width of the bounding box as a ratio of the overall document page width.</p>",
        "BoundingBox$Height": "<p>The height of the bounding box as a ratio of the overall document page height.</p>",
        "BoundingBox$Left": "<p>The left coordinate of the bounding box as a ratio of overall document page width.</p>",
        "BoundingBox$Top": "<p>The top coordinate of the bounding box as a ratio of overall document page height.</p>",
        "Point$X": "<p>The value of the X coordinate for a point on a <code>Polygon</code>.</p>",
        "Point$Y": "<p>The value of the Y coordinate for a point on a <code>Polygon</code>.</p>"
      }
    },
    "Geometry": {
      "base": "<p>Information about where a recognized text, key, value, table, or table cell is located on a document page.</p>",
      "refs": {
        "Block$Geometry": "<p>The location of the recognized text on the image. It includes an axis-aligned, coarse bounding box that surrounds the text, and a finer-grain polygon for more accurate spatial information. </p>"
      }
    },
    "GetDocumentAnalysisRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetDocumentAnalysisResponse": {
      "base": null,
      "refs": {
      }
    },
    "GetDocumentTextDetectionRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetDocumentTextDetectionResponse": {
      "base": null,
      "refs": {
      }
    },
    "IdList": {
      "base": null,
      "refs": {
        "Relationship$Ids": "<p>An array of IDs for related blocks. You can get the type of the relationship from the <code>Type</code> element.</p>"
      }
    },
    "IdempotentParameterMismatchException": {
      "base": "<p>A <code>ClientRequestToken</code> input parameter was reused with an operation, but at least one of the other input parameters is different from the previous call to the operation. </p>",
      "refs": {
      }
    },
    "ImageBlob": {
      "base": null,
      "refs": {
        "Document$Bytes": "<p>A blob of documents bytes. The maximum size of a document that's provided in a blob of bytes is 5 MB.</p>"
      }
    },
    "InternalServerError": {
      "base": "<p>Amazon Textract experienced a service issue. Try your call again.</p>",
      "refs": {
      }
    },
    "InvalidJobIdException": {
      "base": "<p>An invalid job identifier was passed to <a>GetDocumentAnalysis</a> or to <a>GetDocumentAnalysis</a>.</p>",
      "refs": {
      }
    },
    "InvalidParameterException": {
      "base": "<p>An input parameter violated a constraint. For example, in synchronous operations, an <code>InvalidParameterException</code> exception occurs when neither of the <code>S3Object</code> or <code>Bytes</code> values are supplied in the <code>Document</code> request parameter. Validate your parameter before calling the API operation again.</p>",
      "refs": {
      }
    },
    "InvalidS3ObjectException": {
      "base": "<p>Amazon Textract is unable to access the S3 object that's specified in the request.</p>",
      "refs": {
      }
    },
    "JobId": {
      "base": null,
      "refs": {
        "GetDocumentAnalysisRequest$JobId": "<p>A unique identifier for the text-detection job. The <code>JobId</code> is returned from <code>StartDocumentAnalysis</code>.</p>",
        "GetDocumentTextDetectionRequest$JobId": "<p>A unique identifier for the text detection job. The <code>JobId</code> is returned from <code>StartDocumentTextDetection</code>.</p>",
        "StartDocumentAnalysisResponse$JobId": "<p>The identifier for the document text-detection job. Use <code>JobId</code> to identify the job in a subsequent call to <code>GetDocumentAnalysis</code>.</p>",
        "StartDocumentTextDetectionResponse$JobId": "<p>The identifier for the document text-detection job. Use <code>JobId</code> to identify the job in a subsequent call to <code>GetDocumentTextDetection</code>.</p>"
      }
    },
    "JobStatus": {
      "base": null,
      "refs": {
        "GetDocumentAnalysisResponse$JobStatus": "<p>The current status of the text detection job.</p>",
        "GetDocumentTextDetectionResponse$JobStatus": "<p>The current status of the text detection job.</p>"
      }
    },
    "JobTag": {
      "base": null,
      "refs": {
        "StartDocumentAnalysisRequest$JobTag": "<p>The unique identifier you specify to identify the job in the completion status that's published to the Amazon SNS topic.</p>",
        "StartDocumentTextDetectionRequest$JobTag": "<p>A unique identifier you specify to identify the job in the completion status that's published to the Amazon Simple Notification Service (Amazon SNS) topic.</p>"
      }
    },
    "LimitExceededException": {
      "base": "<p>An Amazon Textract service limit was exceeded. For example, if you start too many asynchronous jobs concurrently, calls to start operations (<code>StartDocumentTextDetection</code>, for example) raise a LimitExceededException exception (HTTP status code: 400) until the number of concurrently running jobs is below the Amazon Textract service limit. </p>",
      "refs": {
      }
    },
    "MaxResults": {
      "base": null,
      "refs": {
        "GetDocumentAnalysisRequest$MaxResults": "<p>The maximum number of results to return per paginated call. The largest value that you can specify is 1,000. If you specify a value greater than 1,000, a maximum of 1,000 results is returned. The default value is 1,000.</p>",
        "GetDocumentTextDetectionRequest$MaxResults": "<p>The maximum number of results to return per paginated call. The largest value you can specify is 1,000. If you specify a value greater than 1,000, a maximum of 1,000 results is returned. The default value is 1,000.</p>"
      }
    },
    "NonEmptyString": {
      "base": null,
      "refs": {
        "Block$Id": "<p>The identifier for the recognized text. The identifier is only unique for a single operation. </p>",
        "IdList$member": null
      }
    },
    "NotificationChannel": {
      "base": "<p>The Amazon Simple Notification Service (Amazon SNS) topic to which Amazon Textract publishes the completion status of an asynchronous document operation, such as <a>StartDocumentTextDetection</a>. </p>",
      "refs": {
        "StartDocumentAnalysisRequest$NotificationChannel": "<p>The Amazon SNS topic ARN that you want Amazon Textract to publish the completion status of the operation to. </p>",
        "StartDocumentTextDetectionRequest$NotificationChannel": "<p>The Amazon SNS topic ARN that you want Amazon Textract to publish the completion status of the operation to. </p>"
      }
    },
    "Pages": {
      "base": null,
      "refs": {
        "Warning$Pages": "<p>A list of the pages that the warning applies to.</p>"
      }
    },
    "PaginationToken": {
      "base": null,
      "refs": {
        "GetDocumentAnalysisRequest$NextToken": "<p>If the previous response was incomplete (because there are more blocks to retrieve), Amazon Textract returns a pagination token in the response. You can use this pagination token to retrieve the next set of blocks.</p>",
        "GetDocumentAnalysisResponse$NextToken": "<p>If the response is truncated, Amazon Textract returns this token. You can use this token in the subsequent request to retrieve the next set of text detection results.</p>",
        "GetDocumentTextDetectionRequest$NextToken": "<p>If the previous response was incomplete (because there are more blocks to retrieve), Amazon Textract returns a pagination token in the response. You can use this pagination token to retrieve the next set of blocks.</p>",
        "GetDocumentTextDetectionResponse$NextToken": "<p>If the response is truncated, Amazon Textract returns this token. You can use this token in the subsequent request to retrieve the next set of text-detection results.</p>"
      }
    },
    "Percent": {
      "base": null,
      "refs": {
        "Block$Confidence": "<p>The confidence that Amazon Textract has in the accuracy of the recognized text and the accuracy of the geometry points around the recognized text.</p>"
      }
    },
    "Point": {
      "base": "<p>The X and Y coordinates of a point on a document page. The X and Y values returned are ratios of the overall document page size. For example, if the input document is 700 x 200 and the operation returns X=0.5 and Y=0.25, then the point is at the (350,50) pixel coordinate on the document page.</p> <p>An array of <code>Point</code> objects, <code>Polygon</code>, is returned by <a>DetectDocumentText</a>. <code>Polygon</code> represents a fine-grained polygon around detected text. For more information, see Geometry in the Amazon Textract Developer Guide. </p>",
      "refs": {
        "Polygon$member": null
      }
    },
    "Polygon": {
      "base": null,
      "refs": {
        "Geometry$Polygon": "<p>Within the bounding box, a fine-grained polygon around the recognized text.</p>"
      }
    },
    "ProvisionedThroughputExceededException": {
      "base": "<p>The number of requests exceeded your throughput limit. If you want to increase this limit, contact Amazon Textract.</p>",
      "refs": {
      }
    },
    "Relationship": {
      "base": "<p>Information about how blocks are related to each other. A <code>Block</code> object contains 0 or more <code>Relation</code> objects in a list, <code>Relationships</code>. For more information, see <a>Block</a>.</p> <p>The <code>Type</code> element provides the type of the relationship for all blocks in the <code>IDs</code> array. </p>",
      "refs": {
        "RelationshipList$member": null
      }
    },
    "RelationshipList": {
      "base": null,
      "refs": {
        "Block$Relationships": "<p>A list of child blocks of the current block. For example a LINE object has child blocks for each WORD block that's part of the line of text. There aren't Relationship objects in the list for relationships that don't exist, such as when the current block has no child blocks. The list size can be the following:</p> <ul> <li> <p>0 - The block has no child blocks.</p> </li> <li> <p>1 - The block has child blocks.</p> </li> </ul>"
      }
    },
    "RelationshipType": {
      "base": null,
      "refs": {
        "Relationship$Type": "<p>The type of relationship that the blocks in the IDs array have with the current block. The relationship can be <code>VALUE</code> or <code>CHILD</code>.</p>"
      }
    },
    "RoleArn": {
      "base": null,
      "refs": {
        "NotificationChannel$RoleArn": "<p>The Amazon Resource Name (ARN) of an IAM role that gives Amazon Textract publishing permissions to the Amazon SNS topic. </p>"
      }
    },
    "S3Bucket": {
      "base": null,
      "refs": {
        "S3Object$Bucket": "<p>The name of the S3 bucket.</p>"
      }
    },
    "S3Object": {
      "base": "<p>The S3 bucket name and file name that identifies the document.</p> <p>The AWS Region for the S3 bucket that contains the document must match the Region that you use for Amazon Textract operations.</p> <p>For Amazon Textract to process a file in an S3 bucket, the user must have permission to access the S3 bucket and file. </p>",
      "refs": {
        "Document$S3Object": "<p>Identifies an S3 object as the document source. The maximum size of a document stored in an S3 bucket is 5 MB.</p>",
        "DocumentLocation$S3Object": "<p>The Amazon S3 bucket that contains the input document.</p>"
      }
    },
    "S3ObjectName": {
      "base": null,
      "refs": {
        "S3Object$Name": "<p>The file name of the input document. It must be an image file (.JPG or .PNG format). Asynchronous operations also support PDF files.</p>"
      }
    },
    "S3ObjectVersion": {
      "base": null,
      "refs": {
        "S3Object$Version": "<p>If the bucket has versioning enabled, you can specify the object version. </p>"
      }
    },
    "SNSTopicArn": {
      "base": null,
      "refs": {
        "NotificationChannel$SNSTopicArn": "<p>The Amazon SNS topic that Amazon Textract posts the completion status to.</p>"
      }
    },
    "StartDocumentAnalysisRequest": {
      "base": null,
      "refs": {
      }
    },
    "StartDocumentAnalysisResponse": {
      "base": null,
      "refs": {
      }
    },
    "StartDocumentTextDetectionRequest": {
      "base": null,
      "refs": {
      }
    },
    "StartDocumentTextDetectionResponse": {
      "base": null,
      "refs": {
      }
    },
    "StatusMessage": {
      "base": null,
      "refs": {
        "GetDocumentAnalysisResponse$StatusMessage": "<p>The current status of an asynchronous document analysis operation.</p>",
        "GetDocumentTextDetectionResponse$StatusMessage": "<p>The current status of an asynchronous document text-detection operation. </p>"
      }
    },
    "String": {
      "base": null,
      "refs": {
        "Block$Text": "<p>The word or line of text that's recognized by Amazon Textract. </p>"
      }
    },
    "ThrottlingException": {
      "base": "<p>Amazon Textract is temporarily unable to process the request. Try your call again.</p>",
      "refs": {
      }
    },
    "UInteger": {
      "base": null,
      "refs": {
        "Block$RowIndex": "<p>The row in which a table cell is located. The first row position is 1. <code>RowIndex</code> isn't returned by <code>DetectDocumentText</code> and <code>GetDocumentTextDetection</code>.</p>",
        "Block$ColumnIndex": "<p>The column in which a table cell appears. The first column position is 1. <code>ColumnIndex</code> isn't returned by <code>DetectDocumentText</code> and <code>GetDocumentTextDetection</code>.</p>",
        "Block$RowSpan": "<p>The number of rows that a table spans. <code>RowSpan</code> isn't returned by <code>DetectDocumentText</code> and <code>GetDocumentTextDetection</code>.</p>",
        "Block$ColumnSpan": "<p>The number of columns that a table cell spans. <code>ColumnSpan</code> isn't returned by <code>DetectDocumentText</code> and <code>GetDocumentTextDetection</code>. </p>",
        "Block$Page": "<p>The page in which a block was detected.</p>",
        "DocumentMetadata$Pages": "<p>The number of pages detected in the document.</p>",
        "Pages$member": null
      }
    },
    "UnsupportedDocumentException": {
      "base": "<p>The format of the input document isn't supported. Amazon Textract supports documents that are .png or .jpg format.</p>",
      "refs": {
      }
    },
    "Warning": {
      "base": "<p>A warning about an issue that occurred during asynchronous text analysis (<a>StartDocumentAnalysis</a>) or asynchronous document-text detection (<a>StartDocumentTextDetection</a>). </p>",
      "refs": {
        "Warnings$member": null
      }
    },
    "Warnings": {
      "base": null,
      "refs": {
        "GetDocumentAnalysisResponse$Warnings": "<p>A list of warnings that occurred during the document analysis operation.</p>",
        "GetDocumentTextDetectionResponse$Warnings": "<p>A list of warnings that occurred during the document text-detection operation.</p>"
      }
    }
  }
}
