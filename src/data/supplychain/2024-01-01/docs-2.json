{
  "version": "2.0",
  "service": "<p> AWS Supply Chain is a cloud-based application that works with your enterprise resource planning (ERP) and supply chain management systems. Using AWS Supply Chain, you can connect and extract your inventory, supply, and demand related data from existing ERP or supply chain systems into a single data model. </p> <p>The AWS Supply Chain API supports configuration data import for Supply Planning.</p> <p> All AWS Supply chain API operations are Amazon-authenticated and certificate-signed. They not only require the use of the AWS SDK, but also allow for the exclusive use of AWS Identity and Access Management users and roles to help facilitate access, trust, and permission policies. </p>",
  "operations": {
    "CreateBillOfMaterialsImportJob": "<p>CreateBillOfMaterialsImportJob creates an import job for the Product Bill Of Materials (BOM) entity. For information on the product_bom entity, see the AWS Supply Chain User Guide.</p> <p>The CSV file must be located in an Amazon S3 location accessible to AWS Supply Chain. It is recommended to use the same Amazon S3 bucket created during your AWS Supply Chain instance creation.</p>",
    "CreateDataIntegrationFlow": "<p>Enables you to programmatically create a data pipeline to ingest data from source systems such as Amazon S3 buckets, to a predefined Amazon Web Services Supply Chain dataset (product, inbound_order) or a temporary dataset along with the data transformation query provided with the API.</p>",
    "CreateDataLakeDataset": "<p>Enables you to programmatically create an Amazon Web Services Supply Chain data lake dataset. Developers can create the datasets using their pre-defined or custom schema for a given instance ID, namespace, and dataset name.</p>",
    "CreateDataLakeNamespace": "<p>Enables you to programmatically create an Amazon Web Services Supply Chain data lake namespace. Developers can create the namespaces for a given instance ID.</p>",
    "CreateInstance": "<p>Enables you to programmatically create an Amazon Web Services Supply Chain instance by applying KMS keys and relevant information associated with the API without using the Amazon Web Services console.</p> <p>This is an asynchronous operation. Upon receiving a CreateInstance request, Amazon Web Services Supply Chain immediately returns the instance resource, instance ID, and the initializing state while simultaneously creating all required Amazon Web Services resources for an instance creation. You can use GetInstance to check the status of the instance. If the instance results in an unhealthy state, you need to check the error message, delete the current instance, and recreate a new one based on the mitigation from the error message.</p>",
    "DeleteDataIntegrationFlow": "<p>Enable you to programmatically delete an existing data pipeline for the provided Amazon Web Services Supply Chain instance and DataIntegrationFlow name.</p>",
    "DeleteDataLakeDataset": "<p>Enables you to programmatically delete an Amazon Web Services Supply Chain data lake dataset. Developers can delete the existing datasets for a given instance ID, namespace, and instance name.</p>",
    "DeleteDataLakeNamespace": "<p>Enables you to programmatically delete an Amazon Web Services Supply Chain data lake namespace and its underling datasets. Developers can delete the existing namespaces for a given instance ID and namespace name.</p>",
    "DeleteInstance": "<p>Enables you to programmatically delete an Amazon Web Services Supply Chain instance by deleting the KMS keys and relevant information associated with the API without using the Amazon Web Services console.</p> <p>This is an asynchronous operation. Upon receiving a DeleteInstance request, Amazon Web Services Supply Chain immediately returns a response with the instance resource, delete state while cleaning up all Amazon Web Services resources created during the instance creation process. You can use the GetInstance action to check the instance status.</p>",
    "GetBillOfMaterialsImportJob": "<p>Get status and details of a BillOfMaterialsImportJob.</p>",
    "GetDataIntegrationEvent": "<p>Enables you to programmatically view an Amazon Web Services Supply Chain Data Integration Event. Developers can view the eventType, eventGroupId, eventTimestamp, datasetTarget, datasetLoadExecution.</p>",
    "GetDataIntegrationFlow": "<p>Enables you to programmatically view a specific data pipeline for the provided Amazon Web Services Supply Chain instance and DataIntegrationFlow name.</p>",
    "GetDataIntegrationFlowExecution": "<p>Get the flow execution.</p>",
    "GetDataLakeDataset": "<p>Enables you to programmatically view an Amazon Web Services Supply Chain data lake dataset. Developers can view the data lake dataset information such as namespace, schema, and so on for a given instance ID, namespace, and dataset name.</p>",
    "GetDataLakeNamespace": "<p>Enables you to programmatically view an Amazon Web Services Supply Chain data lake namespace. Developers can view the data lake namespace information such as description for a given instance ID and namespace name.</p>",
    "GetInstance": "<p>Enables you to programmatically retrieve the information related to an Amazon Web Services Supply Chain instance ID.</p>",
    "ListDataIntegrationEvents": "<p>Enables you to programmatically list all data integration events for the provided Amazon Web Services Supply Chain instance.</p>",
    "ListDataIntegrationFlowExecutions": "<p>List flow executions.</p>",
    "ListDataIntegrationFlows": "<p>Enables you to programmatically list all data pipelines for the provided Amazon Web Services Supply Chain instance.</p>",
    "ListDataLakeDatasets": "<p>Enables you to programmatically view the list of Amazon Web Services Supply Chain data lake datasets. Developers can view the datasets and the corresponding information such as namespace, schema, and so on for a given instance ID and namespace.</p>",
    "ListDataLakeNamespaces": "<p>Enables you to programmatically view the list of Amazon Web Services Supply Chain data lake namespaces. Developers can view the namespaces and the corresponding information such as description for a given instance ID. Note that this API only return custom namespaces, instance pre-defined namespaces are not included.</p>",
    "ListInstances": "<p>List all Amazon Web Services Supply Chain instances for a specific account. Enables you to programmatically list all Amazon Web Services Supply Chain instances based on their account ID, instance name, and state of the instance (active or delete).</p>",
    "ListTagsForResource": "<p>List all the tags for an Amazon Web ServicesSupply Chain resource. You can list all the tags added to a resource. By listing the tags, developers can view the tag level information on a resource and perform actions such as, deleting a resource associated with a particular tag.</p>",
    "SendDataIntegrationEvent": "<p>Send the data payload for the event with real-time data for analysis or monitoring. The real-time data events are stored in an Amazon Web Services service before being processed and stored in data lake.</p>",
    "TagResource": "<p>You can create tags during or after creating a resource such as instance, data flow, or dataset in AWS Supply chain. During the data ingestion process, you can add tags such as dev, test, or prod to data flows created during the data ingestion process in the AWS Supply Chain datasets. You can use these tags to identify a group of resources or a single resource used by the developer.</p>",
    "UntagResource": "<p>You can delete tags for an Amazon Web Services Supply chain resource such as instance, data flow, or dataset in AWS Supply Chain. During the data ingestion process, you can delete tags such as dev, test, or prod to data flows created during the data ingestion process in the AWS Supply Chain datasets. </p>",
    "UpdateDataIntegrationFlow": "<p>Enables you to programmatically update an existing data pipeline to ingest data from the source systems such as, Amazon S3 buckets, to a predefined Amazon Web Services Supply Chain dataset (product, inbound_order) or a temporary dataset along with the data transformation query provided with the API.</p>",
    "UpdateDataLakeDataset": "<p>Enables you to programmatically update an Amazon Web Services Supply Chain data lake dataset. Developers can update the description of a data lake dataset for a given instance ID, namespace, and dataset name.</p>",
    "UpdateDataLakeNamespace": "<p>Enables you to programmatically update an Amazon Web Services Supply Chain data lake namespace. Developers can update the description of a data lake namespace for a given instance ID and namespace name.</p>",
    "UpdateInstance": "<p>Enables you to programmatically update an Amazon Web Services Supply Chain instance description by providing all the relevant information such as account ID, instance ID and so on without using the AWS console.</p>"
  },
  "shapes": {
    "AccessDeniedException": {
      "base": "<p>You do not have the required privileges to perform this action.</p>",
      "refs": {
      }
    },
    "AscResourceArn": {
      "base": null,
      "refs": {
        "DataLakeDataset$arn": "<p>The arn of the dataset.</p>",
        "DataLakeNamespace$arn": "<p>The arn of the namespace.</p>",
        "ListTagsForResourceRequest$resourceArn": "<p>The Amazon Web Services Supply chain resource ARN that needs tags to be listed.</p>",
        "TagResourceRequest$resourceArn": "<p>The Amazon Web Services Supply chain resource ARN that needs to be tagged.</p>",
        "UntagResourceRequest$resourceArn": "<p>The Amazon Web Services Supply chain resource ARN that needs to be untagged.</p>"
      }
    },
    "AwsAccountId": {
      "base": null,
      "refs": {
        "Instance$awsAccountId": "<p>The Amazon Web Services account ID that owns the instance.</p>"
      }
    },
    "BillOfMaterialsImportJob": {
      "base": "<p>The BillOfMaterialsImportJob details.</p>",
      "refs": {
        "GetBillOfMaterialsImportJobResponse$job": "<p>The BillOfMaterialsImportJob.</p>"
      }
    },
    "Boolean": {
      "base": null,
      "refs": {
        "DataIntegrationFlowDatasetOptions$dedupeRecords": "<p>The option to perform deduplication on data records sharing same primary key values. If disabled, transformed data with duplicate primary key values will ingest into dataset, for datasets within <b>asc</b> namespace, such duplicates will cause ingestion fail. If enabled without dedupeStrategy, deduplication is done by retaining a random data record among those sharing the same primary key values. If enabled with dedupeStragtegy, the deduplication is done following the strategy.</p> <p>Note that target dataset may have partition configured, when dedupe is enabled, it only dedupe against primary keys and retain only one record out of those duplicates regardless of its partition status.</p>",
        "DataLakeDatasetSchemaField$isRequired": "<p>Indicate if the field is required or not.</p>"
      }
    },
    "ClientToken": {
      "base": "<p>Unique, case-sensitive identifier that you provide to ensure the idempotency of the request.</p>",
      "refs": {
        "CreateBillOfMaterialsImportJobRequest$clientToken": "<p>An idempotency token ensures the API request is only completed no more than once. This way, retrying the request will not trigger the operation multiple times. A client token is a unique, case-sensitive string of 33 to 128 ASCII characters. To make an idempotent API request, specify a client token in the request. You should not reuse the same client token for other requests. If you retry a successful request with the same client token, the request will succeed with no further actions being taken, and you will receive the same API response as the original successful request.</p>",
        "CreateInstanceRequest$clientToken": "<p>The client token for idempotency.</p>",
        "SendDataIntegrationEventRequest$clientToken": "<p>The idempotent client token. The token is active for 8 hours, and within its lifetime, it ensures the request completes only once upon retry with same client token. If omitted, the AWS SDK generates a unique value so that AWS SDK can safely retry the request upon network errors.</p>"
      }
    },
    "ConfigurationJobStatus": {
      "base": "<p>The status of the job.</p>",
      "refs": {
        "BillOfMaterialsImportJob$status": "<p>The BillOfMaterialsImportJob ConfigurationJobStatus.</p>"
      }
    },
    "ConfigurationS3Uri": {
      "base": null,
      "refs": {
        "BillOfMaterialsImportJob$s3uri": "<p>The S3 URI from which the CSV is read.</p>",
        "CreateBillOfMaterialsImportJobRequest$s3uri": "<p>The S3 URI of the CSV file to be imported. The bucket must grant permissions for AWS Supply Chain to read the file.</p>"
      }
    },
    "ConflictException": {
      "base": "<p>Updating or deleting a resource can cause an inconsistent state.</p>",
      "refs": {
      }
    },
    "CreateBillOfMaterialsImportJobRequest": {
      "base": "<p>The request parameters for CreateBillOfMaterialsImportJob.</p>",
      "refs": {
      }
    },
    "CreateBillOfMaterialsImportJobResponse": {
      "base": "<p>The response parameters of CreateBillOfMaterialsImportJob.</p>",
      "refs": {
      }
    },
    "CreateDataIntegrationFlowRequest": {
      "base": "<p>The request parameters for CreateDataIntegrationFlow.</p>",
      "refs": {
      }
    },
    "CreateDataIntegrationFlowResponse": {
      "base": "<p>The response parameters for CreateDataIntegrationFlow.</p>",
      "refs": {
      }
    },
    "CreateDataLakeDatasetRequest": {
      "base": "<p>The request parameters for CreateDataLakeDataset.</p>",
      "refs": {
      }
    },
    "CreateDataLakeDatasetResponse": {
      "base": "<p>The response parameters of CreateDataLakeDataset.</p>",
      "refs": {
      }
    },
    "CreateDataLakeNamespaceRequest": {
      "base": "<p>The request parameters for CreateDataLakeNamespace.</p>",
      "refs": {
      }
    },
    "CreateDataLakeNamespaceResponse": {
      "base": "<p>The response parameters of CreateDataLakeNamespace.</p>",
      "refs": {
      }
    },
    "CreateInstanceRequest": {
      "base": "<p>The request parameters for CreateInstance.</p>",
      "refs": {
      }
    },
    "CreateInstanceResponse": {
      "base": "<p>The response parameters for CreateInstance.</p>",
      "refs": {
      }
    },
    "DataIntegrationDatasetArn": {
      "base": null,
      "refs": {
        "DataIntegrationEventDatasetTargetConfiguration$datasetIdentifier": "<p>The datalake dataset ARN identifier.</p>",
        "DataIntegrationEventDatasetTargetDetails$datasetIdentifier": "<p>The datalake dataset ARN identifier.</p>",
        "DataIntegrationFlowDatasetSource$datasetIdentifier": "<p>The ARN of the dataset source.</p>"
      }
    },
    "DataIntegrationEvent": {
      "base": "<p>The data integration event details.</p>",
      "refs": {
        "DataIntegrationEventList$member": null,
        "GetDataIntegrationEventResponse$event": "<p>The details of the DataIntegrationEvent returned.</p>"
      }
    },
    "DataIntegrationEventData": {
      "base": null,
      "refs": {
        "SendDataIntegrationEventRequest$data": "<p>The data payload of the event, should follow the data schema of the target dataset, or see <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html\">Data entities supported in AWS Supply Chain</a>. To send single data record, use JsonObject format; to send multiple data records, use JsonArray format.</p> <p>Note that for AWS Supply Chain dataset under <b>asc</b> namespace, it has a connection_id internal field that is not allowed to be provided by client directly, they will be auto populated.</p>"
      }
    },
    "DataIntegrationEventDatasetLoadExecutionDetails": {
      "base": "<p>The target dataset load execution details.</p>",
      "refs": {
        "DataIntegrationEventDatasetTargetDetails$datasetLoadExecution": "<p>The target dataset load execution.</p>"
      }
    },
    "DataIntegrationEventDatasetLoadStatus": {
      "base": null,
      "refs": {
        "DataIntegrationEventDatasetLoadExecutionDetails$status": "<p>The event load execution status to target dataset.</p>"
      }
    },
    "DataIntegrationEventDatasetOperationType": {
      "base": null,
      "refs": {
        "DataIntegrationEventDatasetTargetConfiguration$operationType": "<p>The target dataset load operation type.</p>",
        "DataIntegrationEventDatasetTargetDetails$operationType": "<p>The target dataset load operation type. The available options are:</p> <ul> <li> <p> <b>APPEND</b> - Add new records to the dataset. Noted that this operation type will just try to append records as-is without any primary key or partition constraints.</p> </li> <li> <p> <b>UPSERT</b> - Modify existing records in the dataset with primary key configured, events for datasets without primary keys are not allowed. If event data contains primary keys that match records in the dataset within same partition, then those existing records (in that partition) will be updated. If primary keys do not match, new records will be added. Note that if dataset contain records with duplicate primary key values in the same partition, those duplicate records will be deduped into one updated record.</p> </li> <li> <p> <b>DELETE</b> - Remove existing records in the dataset with primary key configured, events for datasets without primary keys are not allowed. If event data contains primary keys that match records in the dataset within same partition, then those existing records (in that partition) will be deleted. If primary keys do not match, no actions will be done. Note that if dataset contain records with duplicate primary key values in the same partition, all those duplicates will be removed.</p> </li> </ul>"
      }
    },
    "DataIntegrationEventDatasetTargetConfiguration": {
      "base": "<p>The target dataset configuration for a DATASET event type.</p>",
      "refs": {
        "SendDataIntegrationEventRequest$datasetTarget": "<p>The target dataset configuration for <b>scn.data.dataset</b> event type.</p>"
      }
    },
    "DataIntegrationEventDatasetTargetDetails": {
      "base": "<p>The target dataset details for a DATASET event type.</p>",
      "refs": {
        "DataIntegrationEvent$datasetTargetDetails": "<p>The target dataset details for a DATASET event type.</p>"
      }
    },
    "DataIntegrationEventGroupId": {
      "base": null,
      "refs": {
        "DataIntegrationEvent$eventGroupId": "<p>Event identifier (for example, orderId for InboundOrder) used for data sharding or partitioning.</p>",
        "SendDataIntegrationEventRequest$eventGroupId": "<p>Event identifier (for example, orderId for InboundOrder) used for data sharding or partitioning. Noted under one eventGroupId of same eventType and instanceId, events are processed sequentially in the order they are received by the server.</p>"
      }
    },
    "DataIntegrationEventList": {
      "base": null,
      "refs": {
        "ListDataIntegrationEventsResponse$events": "<p>The list of data integration events.</p>"
      }
    },
    "DataIntegrationEventMaxResults": {
      "base": null,
      "refs": {
        "ListDataIntegrationEventsRequest$maxResults": "<p>Specify the maximum number of data integration events to fetch in one paginated request.</p>"
      }
    },
    "DataIntegrationEventNextToken": {
      "base": null,
      "refs": {
        "ListDataIntegrationEventsRequest$nextToken": "<p>The pagination token to fetch the next page of the data integration events.</p>",
        "ListDataIntegrationEventsResponse$nextToken": "<p>The pagination token to fetch the next page of the ListDataIntegrationEvents.</p>"
      }
    },
    "DataIntegrationEventType": {
      "base": null,
      "refs": {
        "DataIntegrationEvent$eventType": "<p>The data event type.</p>",
        "ListDataIntegrationEventsRequest$eventType": "<p>List data integration events for the specified eventType.</p>",
        "SendDataIntegrationEventRequest$eventType": "<p>The data event type.</p> <ul> <li> <p> <b>scn.data.dataset</b> - Send data directly to any specified dataset.</p> </li> <li> <p> <b>scn.data.supplyplan</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/supply-plan-entity.html\">supply_plan</a> dataset.</p> </li> <li> <p> <b>scn.data.shipmentstoporder</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/replenishment-shipment-stop-order-entity.html\">shipment_stop_order</a> dataset.</p> </li> <li> <p> <b>scn.data.shipmentstop</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/replenishment-shipment-stop-entity.html\">shipment_stop</a> dataset.</p> </li> <li> <p> <b>scn.data.shipment</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/replenishment-shipment-entity.html\">shipment</a> dataset.</p> </li> <li> <p> <b>scn.data.reservation</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/planning-reservation-entity.html\">reservation</a> dataset.</p> </li> <li> <p> <b>scn.data.processproduct</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/operation-process-product-entity.html\">process_product</a> dataset.</p> </li> <li> <p> <b>scn.data.processoperation</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/operation-process-operation-entity.html\">process_operation</a> dataset.</p> </li> <li> <p> <b>scn.data.processheader</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/operation-process-header-entity.html\">process_header</a> dataset.</p> </li> <li> <p> <b>scn.data.forecast</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/forecast-forecast-entity.html\">forecast</a> dataset.</p> </li> <li> <p> <b>scn.data.inventorylevel</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/inventory_mgmnt-inv-level-entity.html\">inv_level</a> dataset.</p> </li> <li> <p> <b>scn.data.inboundorder</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/replenishment-inbound-order-entity.html\">inbound_order</a> dataset.</p> </li> <li> <p> <b>scn.data.inboundorderline</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/replenishment-inbound-order-line-entity.html\">inbound_order_line</a> dataset.</p> </li> <li> <p> <b>scn.data.inboundorderlineschedule</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/replenishment-inbound-order-line-schedule-entity.html\">inbound_order_line_schedule</a> dataset.</p> </li> <li> <p> <b>scn.data.outboundorderline</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/outbound-fulfillment-order-line-entity.html\">outbound_order_line</a> dataset.</p> </li> <li> <p> <b>scn.data.outboundshipment</b> - Send data to <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/outbound-fulfillment-shipment-entity.html\">outbound_shipment</a> dataset.</p> </li> </ul>"
      }
    },
    "DataIntegrationFlow": {
      "base": "<p>The DataIntegrationFlow details.</p>",
      "refs": {
        "DataIntegrationFlowList$member": null,
        "GetDataIntegrationFlowResponse$flow": "<p>The details of the DataIntegrationFlow returned.</p>",
        "UpdateDataIntegrationFlowResponse$flow": "<p>The details of the updated DataIntegrationFlow.</p>"
      }
    },
    "DataIntegrationFlowDatasetOptions": {
      "base": "<p>The dataset options used in dataset source and target configurations.</p>",
      "refs": {
        "DataIntegrationFlowDatasetSourceConfiguration$options": "<p>The dataset DataIntegrationFlow source options.</p>",
        "DataIntegrationFlowDatasetTargetConfiguration$options": "<p>The dataset DataIntegrationFlow target options.</p>"
      }
    },
    "DataIntegrationFlowDatasetSource": {
      "base": "<p>The details of a flow execution with dataset source.</p>",
      "refs": {
        "DataIntegrationFlowExecutionSourceInfo$datasetSource": "<p>The source details of a flow execution with dataset source.</p>"
      }
    },
    "DataIntegrationFlowDatasetSourceConfiguration": {
      "base": "<p>The dataset DataIntegrationFlow source configuration parameters.</p>",
      "refs": {
        "DataIntegrationFlowSource$datasetSource": "<p>The dataset DataIntegrationFlow source.</p>"
      }
    },
    "DataIntegrationFlowDatasetTargetConfiguration": {
      "base": "<p>The dataset DataIntegrationFlow target configuration parameters.</p>",
      "refs": {
        "DataIntegrationFlowTarget$datasetTarget": "<p>The dataset DataIntegrationFlow target. Note that for AWS Supply Chain dataset under <b>asc</b> namespace, it has a connection_id internal field that is not allowed to be provided by client directly, they will be auto populated.</p>"
      }
    },
    "DataIntegrationFlowDedupeStrategy": {
      "base": "<p>The deduplication strategy details.</p>",
      "refs": {
        "DataIntegrationFlowDatasetOptions$dedupeStrategy": "<p>The deduplication strategy to dedupe the data records sharing same primary key values of the target dataset. This strategy only applies to target dataset with primary keys and with dedupeRecords option enabled. If transformed data still got duplicates after the dedupeStrategy evaluation, a random data record is chosen to be retained.</p>"
      }
    },
    "DataIntegrationFlowDedupeStrategyType": {
      "base": null,
      "refs": {
        "DataIntegrationFlowDedupeStrategy$type": "<p>The type of the deduplication strategy.</p> <ul> <li> <p> <b>FIELD_PRIORITY</b> - Field priority configuration for the deduplication strategy specifies an ordered list of fields used to tie-break the data records sharing the same primary key values. Fields earlier in the list have higher priority for evaluation. For each field, the sort order determines whether to retain data record with larger or smaller field value.</p> </li> </ul>"
      }
    },
    "DataIntegrationFlowExecution": {
      "base": "<p>The flow execution details.</p>",
      "refs": {
        "DataIntegrationFlowExecutionList$member": null,
        "GetDataIntegrationFlowExecutionResponse$flowExecution": "<p>The flow execution details.</p>"
      }
    },
    "DataIntegrationFlowExecutionDiagnosticReportsRootS3URI": {
      "base": null,
      "refs": {
        "DataIntegrationFlowExecutionOutputMetadata$diagnosticReportsRootS3URI": "<p>The S3 URI under which all diagnostic files (such as deduped records if any) are stored.</p>"
      }
    },
    "DataIntegrationFlowExecutionList": {
      "base": null,
      "refs": {
        "ListDataIntegrationFlowExecutionsResponse$flowExecutions": "<p>The list of flow executions.</p>"
      }
    },
    "DataIntegrationFlowExecutionMaxResults": {
      "base": null,
      "refs": {
        "ListDataIntegrationFlowExecutionsRequest$maxResults": "<p>The number to specify the max number of flow executions to fetch in this paginated request.</p>"
      }
    },
    "DataIntegrationFlowExecutionNextToken": {
      "base": null,
      "refs": {
        "ListDataIntegrationFlowExecutionsRequest$nextToken": "<p>The pagination token to fetch next page of flow executions.</p>",
        "ListDataIntegrationFlowExecutionsResponse$nextToken": "<p>The pagination token to fetch next page of flow executions.</p>"
      }
    },
    "DataIntegrationFlowExecutionOutputMetadata": {
      "base": "<p>The output metadata of the flow execution.</p>",
      "refs": {
        "DataIntegrationFlowExecution$outputMetadata": "<p>The flow execution output metadata.</p>"
      }
    },
    "DataIntegrationFlowExecutionSourceInfo": {
      "base": "<p>The source information of a flow execution.</p>",
      "refs": {
        "DataIntegrationFlowExecution$sourceInfo": "<p>The source information for a flow execution.</p>"
      }
    },
    "DataIntegrationFlowExecutionStatus": {
      "base": null,
      "refs": {
        "DataIntegrationFlowExecution$status": "<p>The status of flow execution.</p>"
      }
    },
    "DataIntegrationFlowFieldPriorityDedupeField": {
      "base": "<p>The field used in the field priority deduplication strategy.</p>",
      "refs": {
        "DataIntegrationFlowFieldPriorityDedupeFieldList$member": null
      }
    },
    "DataIntegrationFlowFieldPriorityDedupeFieldList": {
      "base": null,
      "refs": {
        "DataIntegrationFlowFieldPriorityDedupeStrategyConfiguration$fields": "<p>The list of field names and their sort order for deduplication, arranged in descending priority from highest to lowest.</p>"
      }
    },
    "DataIntegrationFlowFieldPriorityDedupeFieldName": {
      "base": null,
      "refs": {
        "DataIntegrationFlowFieldPriorityDedupeField$name": "<p>The name of the deduplication field. Must exist in the dataset and not be a primary key.</p>"
      }
    },
    "DataIntegrationFlowFieldPriorityDedupeSortOrder": {
      "base": null,
      "refs": {
        "DataIntegrationFlowFieldPriorityDedupeField$sortOrder": "<p>The sort order for the deduplication field.</p>"
      }
    },
    "DataIntegrationFlowFieldPriorityDedupeStrategyConfiguration": {
      "base": "<p>The field priority deduplication strategy details.</p>",
      "refs": {
        "DataIntegrationFlowDedupeStrategy$fieldPriority": "<p>The field priority deduplication strategy.</p>"
      }
    },
    "DataIntegrationFlowFileType": {
      "base": null,
      "refs": {
        "DataIntegrationFlowS3Options$fileType": "<p>The Amazon S3 file type in S3 options.</p>"
      }
    },
    "DataIntegrationFlowList": {
      "base": null,
      "refs": {
        "ListDataIntegrationFlowsResponse$flows": "<p>The response parameters for ListDataIntegrationFlows.</p>"
      }
    },
    "DataIntegrationFlowLoadType": {
      "base": null,
      "refs": {
        "DataIntegrationFlowDatasetOptions$loadType": "<p>The target dataset's data load type. This only affects how source S3 files are selected in the S3-to-dataset flow.</p> <ul> <li> <p> <b>REPLACE</b> - Target dataset will get replaced with the new file added under the source s3 prefix.</p> </li> <li> <p> <b>INCREMENTAL</b> - Target dataset will get updated with the up-to-date content under S3 prefix incorporating any file additions or removals there.</p> </li> </ul>"
      }
    },
    "DataIntegrationFlowMaxResults": {
      "base": null,
      "refs": {
        "ListDataIntegrationFlowsRequest$maxResults": "<p>Specify the maximum number of DataIntegrationFlows to fetch in one paginated request.</p>"
      }
    },
    "DataIntegrationFlowName": {
      "base": null,
      "refs": {
        "CreateDataIntegrationFlowRequest$name": "<p>Name of the DataIntegrationFlow.</p>",
        "CreateDataIntegrationFlowResponse$name": "<p>The name of the DataIntegrationFlow created.</p>",
        "DataIntegrationFlow$name": "<p>The DataIntegrationFlow name.</p>",
        "DataIntegrationFlowExecution$flowName": "<p>The flow execution's flowName.</p>",
        "DeleteDataIntegrationFlowRequest$name": "<p>The name of the DataIntegrationFlow to be deleted.</p>",
        "DeleteDataIntegrationFlowResponse$name": "<p>The name of the DataIntegrationFlow deleted.</p>",
        "GetDataIntegrationFlowExecutionRequest$flowName": "<p>The flow name.</p>",
        "GetDataIntegrationFlowRequest$name": "<p>The name of the DataIntegrationFlow created.</p>",
        "ListDataIntegrationFlowExecutionsRequest$flowName": "<p>The flow name.</p>",
        "UpdateDataIntegrationFlowRequest$name": "<p>The name of the DataIntegrationFlow to be updated.</p>"
      }
    },
    "DataIntegrationFlowNextToken": {
      "base": null,
      "refs": {
        "ListDataIntegrationFlowsRequest$nextToken": "<p>The pagination token to fetch the next page of the DataIntegrationFlows.</p>",
        "ListDataIntegrationFlowsResponse$nextToken": "<p>The pagination token to fetch the next page of the DataIntegrationFlows.</p>"
      }
    },
    "DataIntegrationFlowS3Options": {
      "base": "<p>The Amazon S3 options used in S3 source and target configurations.</p>",
      "refs": {
        "DataIntegrationFlowS3SourceConfiguration$options": "<p>The other options of the S3 DataIntegrationFlow source.</p>",
        "DataIntegrationFlowS3TargetConfiguration$options": "<p>The S3 DataIntegrationFlow target options.</p>"
      }
    },
    "DataIntegrationFlowS3Prefix": {
      "base": null,
      "refs": {
        "DataIntegrationFlowS3SourceConfiguration$prefix": "<p>The prefix of the S3 source objects. To trigger data ingestion, S3 files need to be put under <code>s3://<i>bucketName</i>/<i>prefix</i>/</code>.</p>",
        "DataIntegrationFlowS3TargetConfiguration$prefix": "<p>The prefix of the S3 target objects.</p>"
      }
    },
    "DataIntegrationFlowS3Source": {
      "base": "<p>The details of a flow execution with S3 source.</p>",
      "refs": {
        "DataIntegrationFlowExecutionSourceInfo$s3Source": "<p>The source details of a flow execution with S3 source.</p>"
      }
    },
    "DataIntegrationFlowS3SourceConfiguration": {
      "base": "<p>The S3 DataIntegrationFlow source configuration parameters.</p>",
      "refs": {
        "DataIntegrationFlowSource$s3Source": "<p>The S3 DataIntegrationFlow source.</p>"
      }
    },
    "DataIntegrationFlowS3TargetConfiguration": {
      "base": "<p>The S3 DataIntegrationFlow target configuration parameters.</p>",
      "refs": {
        "DataIntegrationFlowTarget$s3Target": "<p>The S3 DataIntegrationFlow target.</p>"
      }
    },
    "DataIntegrationFlowSQLQuery": {
      "base": null,
      "refs": {
        "DataIntegrationFlowSQLTransformationConfiguration$query": "<p>The transformation SQL query body based on SparkSQL.</p>"
      }
    },
    "DataIntegrationFlowSQLTransformationConfiguration": {
      "base": "<p>The SQL DataIntegrationFlow transformation configuration parameters.</p>",
      "refs": {
        "DataIntegrationFlowTransformation$sqlTransformation": "<p>The SQL DataIntegrationFlow transformation configuration.</p>"
      }
    },
    "DataIntegrationFlowSource": {
      "base": "<p>The DataIntegrationFlow source parameters.</p>",
      "refs": {
        "DataIntegrationFlowSourceList$member": null
      }
    },
    "DataIntegrationFlowSourceList": {
      "base": null,
      "refs": {
        "CreateDataIntegrationFlowRequest$sources": "<p>The source configurations for DataIntegrationFlow.</p>",
        "DataIntegrationFlow$sources": "<p>The DataIntegrationFlow source configurations.</p>",
        "UpdateDataIntegrationFlowRequest$sources": "<p>The new source configurations for the DataIntegrationFlow.</p>"
      }
    },
    "DataIntegrationFlowSourceName": {
      "base": null,
      "refs": {
        "DataIntegrationFlowSource$sourceName": "<p>The DataIntegrationFlow source name that can be used as table alias in SQL transformation query.</p>"
      }
    },
    "DataIntegrationFlowSourceType": {
      "base": null,
      "refs": {
        "DataIntegrationFlowExecutionSourceInfo$sourceType": "<p>The data integration flow execution source type.</p>",
        "DataIntegrationFlowSource$sourceType": "<p>The DataIntegrationFlow source type.</p>"
      }
    },
    "DataIntegrationFlowTarget": {
      "base": "<p>The DataIntegrationFlow target parameters.</p>",
      "refs": {
        "CreateDataIntegrationFlowRequest$target": "<p>The target configurations for DataIntegrationFlow.</p>",
        "DataIntegrationFlow$target": "<p>The DataIntegrationFlow target configuration.</p>",
        "UpdateDataIntegrationFlowRequest$target": "<p>The new target configurations for the DataIntegrationFlow.</p>"
      }
    },
    "DataIntegrationFlowTargetType": {
      "base": null,
      "refs": {
        "DataIntegrationFlowTarget$targetType": "<p>The DataIntegrationFlow target type.</p>"
      }
    },
    "DataIntegrationFlowTransformation": {
      "base": "<p>The DataIntegrationFlow transformation parameters.</p>",
      "refs": {
        "CreateDataIntegrationFlowRequest$transformation": "<p>The transformation configurations for DataIntegrationFlow.</p>",
        "DataIntegrationFlow$transformation": "<p>The DataIntegrationFlow transformation configurations.</p>",
        "UpdateDataIntegrationFlowRequest$transformation": "<p>The new transformation configurations for the DataIntegrationFlow.</p>"
      }
    },
    "DataIntegrationFlowTransformationType": {
      "base": null,
      "refs": {
        "DataIntegrationFlowTransformation$transformationType": "<p>The DataIntegrationFlow transformation type.</p>"
      }
    },
    "DataIntegrationS3ObjectKey": {
      "base": null,
      "refs": {
        "DataIntegrationFlowS3Source$key": "<p>The S3 object key of the S3 source.</p>"
      }
    },
    "DataLakeDataset": {
      "base": "<p>The data lake dataset details.</p>",
      "refs": {
        "CreateDataLakeDatasetResponse$dataset": "<p>The detail of created dataset.</p>",
        "DataLakeDatasetList$member": null,
        "GetDataLakeDatasetResponse$dataset": "<p>The fetched dataset details.</p>",
        "UpdateDataLakeDatasetResponse$dataset": "<p>The updated dataset details.</p>"
      }
    },
    "DataLakeDatasetDescription": {
      "base": null,
      "refs": {
        "CreateDataLakeDatasetRequest$description": "<p>The description of the dataset.</p>",
        "DataLakeDataset$description": "<p>The description of the dataset.</p>",
        "UpdateDataLakeDatasetRequest$description": "<p>The updated description of the data lake dataset.</p>"
      }
    },
    "DataLakeDatasetList": {
      "base": null,
      "refs": {
        "ListDataLakeDatasetsResponse$datasets": "<p>The list of fetched dataset details.</p>"
      }
    },
    "DataLakeDatasetMaxResults": {
      "base": null,
      "refs": {
        "ListDataLakeDatasetsRequest$maxResults": "<p>The max number of datasets to fetch in this paginated request.</p>"
      }
    },
    "DataLakeDatasetName": {
      "base": null,
      "refs": {
        "CreateDataLakeDatasetRequest$name": "<p>The name of the dataset. For <b>asc</b> name space, the name must be one of the supported data entities under <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html\">https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html</a>.</p>",
        "DataLakeDataset$name": "<p>The name of the dataset. For <b>asc</b> namespace, the name must be one of the supported data entities under <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html\">https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html</a>.</p>",
        "DeleteDataLakeDatasetRequest$name": "<p>The name of the dataset. For <b>asc</b> namespace, the name must be one of the supported data entities under <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html\">https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html</a>.</p>",
        "DeleteDataLakeDatasetResponse$name": "<p>The name of deleted dataset.</p>",
        "GetDataLakeDatasetRequest$name": "<p>The name of the dataset. For <b>asc</b> namespace, the name must be one of the supported data entities under <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html\">https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html</a>.</p>",
        "UpdateDataLakeDatasetRequest$name": "<p>The name of the dataset. For <b>asc</b> namespace, the name must be one of the supported data entities under <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html\">https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html</a>.</p>"
      }
    },
    "DataLakeDatasetNextToken": {
      "base": null,
      "refs": {
        "ListDataLakeDatasetsRequest$nextToken": "<p>The pagination token to fetch next page of datasets.</p>",
        "ListDataLakeDatasetsResponse$nextToken": "<p>The pagination token to fetch next page of datasets.</p>"
      }
    },
    "DataLakeDatasetPartitionField": {
      "base": "<p>The detail of the partition field.</p>",
      "refs": {
        "DataLakeDatasetPartitionFieldList$member": null
      }
    },
    "DataLakeDatasetPartitionFieldList": {
      "base": null,
      "refs": {
        "DataLakeDatasetPartitionSpec$fields": "<p>The fields on which to partition a dataset. The partitions will be applied hierarchically based on the order of this list.</p>"
      }
    },
    "DataLakeDatasetPartitionFieldTransform": {
      "base": "<p>The detail of the partition field transformation.</p>",
      "refs": {
        "DataLakeDatasetPartitionField$transform": "<p>The transformation of the partition field. A transformation specifies how to partition on a given field. For example, with timestamp you can specify that you'd like to partition fields by day, e.g. data record with value 2025-01-03T00:00:00Z in partition field is in 2025-01-03 partition. Also noted that data record without any value in optional partition field is in NULL partition.</p>"
      }
    },
    "DataLakeDatasetPartitionSpec": {
      "base": "<p>The partition specification for a dataset.</p>",
      "refs": {
        "CreateDataLakeDatasetRequest$partitionSpec": "<p>The partition specification of the dataset. Partitioning can effectively improve the dataset query performance by reducing the amount of data scanned during query execution. But partitioning or not will affect how data get ingested by data ingestion methods, such as SendDataIntegrationEvent's dataset UPSERT will upsert records within partition (instead of within whole dataset). For more details, refer to those data ingestion documentations.</p>",
        "DataLakeDataset$partitionSpec": null
      }
    },
    "DataLakeDatasetPartitionTransformType": {
      "base": null,
      "refs": {
        "DataLakeDatasetPartitionFieldTransform$type": "<p>The type of partitioning transformation for this field. The available options are:</p> <ul> <li> <p> <b>IDENTITY</b> - Partitions data on a given field by its exact values.</p> </li> <li> <p> <b>YEAR</b> - Partitions data on a timestamp field using year granularity.</p> </li> <li> <p> <b>MONTH</b> - Partitions data on a timestamp field using month granularity.</p> </li> <li> <p> <b>DAY</b> - Partitions data on a timestamp field using day granularity.</p> </li> <li> <p> <b>HOUR</b> - Partitions data on a timestamp field using hour granularity.</p> </li> </ul>"
      }
    },
    "DataLakeDatasetPrimaryKeyField": {
      "base": "<p>The detail of the primary key field.</p>",
      "refs": {
        "DataLakeDatasetPrimaryKeyFieldList$member": null
      }
    },
    "DataLakeDatasetPrimaryKeyFieldList": {
      "base": null,
      "refs": {
        "DataLakeDatasetSchema$primaryKeys": "<p>The list of primary key fields for the dataset. Primary keys defined can help data ingestion methods to ensure data uniqueness: CreateDataIntegrationFlow's dedupe strategy will leverage primary keys to perform records deduplication before write to dataset; SendDataIntegrationEvent's UPSERT and DELETE can only work with dataset with primary keys. For more details, refer to those data ingestion documentations.</p> <p>Note that defining primary keys does not necessarily mean the dataset cannot have duplicate records, duplicate records can still be ingested if CreateDataIntegrationFlow's dedupe disabled or through SendDataIntegrationEvent's APPEND operation.</p>"
      }
    },
    "DataLakeDatasetSchema": {
      "base": "<p>The schema details of the dataset. Note that for AWS Supply Chain dataset under <b>asc</b> namespace, it may have internal fields like connection_id that will be auto populated by data ingestion methods.</p>",
      "refs": {
        "CreateDataLakeDatasetRequest$schema": "<p>The custom schema of the data lake dataset and required for dataset in <b>default</b> and custom namespaces.</p>",
        "DataLakeDataset$schema": "<p>The schema of the dataset.</p>"
      }
    },
    "DataLakeDatasetSchemaField": {
      "base": "<p>The dataset field details.</p>",
      "refs": {
        "DataLakeDatasetSchemaFieldList$member": null
      }
    },
    "DataLakeDatasetSchemaFieldList": {
      "base": null,
      "refs": {
        "DataLakeDatasetSchema$fields": "<p>The list of field details of the dataset schema.</p>"
      }
    },
    "DataLakeDatasetSchemaFieldName": {
      "base": null,
      "refs": {
        "DataLakeDatasetPartitionField$name": "<p>The name of the partition field.</p>",
        "DataLakeDatasetPrimaryKeyField$name": "<p>The name of the primary key field.</p>",
        "DataLakeDatasetSchemaField$name": "<p>The dataset field name.</p>"
      }
    },
    "DataLakeDatasetSchemaFieldType": {
      "base": null,
      "refs": {
        "DataLakeDatasetSchemaField$type": "<p>The dataset field type.</p>"
      }
    },
    "DataLakeDatasetSchemaName": {
      "base": null,
      "refs": {
        "DataLakeDatasetSchema$name": "<p>The name of the dataset schema.</p>"
      }
    },
    "DataLakeNamespace": {
      "base": "<p>The data lake namespace details.</p>",
      "refs": {
        "CreateDataLakeNamespaceResponse$namespace": "<p>The detail of created namespace.</p>",
        "DataLakeNamespaceList$member": null,
        "GetDataLakeNamespaceResponse$namespace": "<p>The fetched namespace details.</p>",
        "UpdateDataLakeNamespaceResponse$namespace": "<p>The updated namespace details.</p>"
      }
    },
    "DataLakeNamespaceDescription": {
      "base": null,
      "refs": {
        "CreateDataLakeNamespaceRequest$description": "<p>The description of the namespace.</p>",
        "DataLakeNamespace$description": "<p>The description of the namespace.</p>",
        "UpdateDataLakeNamespaceRequest$description": "<p>The updated description of the data lake namespace.</p>"
      }
    },
    "DataLakeNamespaceList": {
      "base": null,
      "refs": {
        "ListDataLakeNamespacesResponse$namespaces": "<p>The list of fetched namespace details. Noted it only contains custom namespaces, pre-defined namespaces are not included.</p>"
      }
    },
    "DataLakeNamespaceMaxResults": {
      "base": null,
      "refs": {
        "ListDataLakeNamespacesRequest$maxResults": "<p>The max number of namespaces to fetch in this paginated request.</p>"
      }
    },
    "DataLakeNamespaceName": {
      "base": null,
      "refs": {
        "CreateDataLakeDatasetRequest$namespace": "<p>The namespace of the dataset, besides the custom defined namespace, every instance comes with below pre-defined namespaces:</p> <ul> <li> <p> <b>asc</b> - For information on the Amazon Web Services Supply Chain supported datasets see <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html\">https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html</a>.</p> </li> <li> <p> <b>default</b> - For datasets with custom user-defined schemas.</p> </li> </ul>",
        "CreateDataLakeNamespaceRequest$name": "<p>The name of the namespace. Noted you cannot create namespace with name starting with <b>asc</b>, <b>default</b>, <b>scn</b>, <b>aws</b>, <b>amazon</b>, <b>amzn</b> </p>",
        "DataLakeDataset$namespace": "<p>The namespace of the dataset, besides the custom defined namespace, every instance comes with below pre-defined namespaces:</p> <ul> <li> <p> <b>asc</b> - For information on the Amazon Web Services Supply Chain supported datasets see <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html\">https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html</a>.</p> </li> <li> <p> <b>default</b> - For datasets with custom user-defined schemas.</p> </li> </ul>",
        "DataLakeNamespace$name": "<p>The name of the namespace.</p>",
        "DeleteDataLakeDatasetRequest$namespace": "<p>The namespace of the dataset, besides the custom defined namespace, every instance comes with below pre-defined namespaces:</p> <ul> <li> <p> <b>asc</b> - For information on the Amazon Web Services Supply Chain supported datasets see <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html\">https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html</a>.</p> </li> <li> <p> <b>default</b> - For datasets with custom user-defined schemas.</p> </li> </ul>",
        "DeleteDataLakeDatasetResponse$namespace": "<p>The namespace of deleted dataset.</p>",
        "DeleteDataLakeNamespaceRequest$name": "<p>The name of the namespace. Noted you cannot delete pre-defined namespace like <b>asc</b>, <b>default</b> which are only deleted through instance deletion.</p>",
        "DeleteDataLakeNamespaceResponse$name": "<p>The name of deleted namespace.</p>",
        "GetDataLakeDatasetRequest$namespace": "<p>The namespace of the dataset, besides the custom defined namespace, every instance comes with below pre-defined namespaces:</p> <ul> <li> <p> <b>asc</b> - For information on the Amazon Web Services Supply Chain supported datasets see <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html\">https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html</a>.</p> </li> <li> <p> <b>default</b> - For datasets with custom user-defined schemas.</p> </li> </ul>",
        "GetDataLakeNamespaceRequest$name": "<p>The name of the namespace. Besides the namespaces user created, you can also specify the pre-defined namespaces:</p> <ul> <li> <p> <b>asc</b> - Pre-defined namespace containing Amazon Web Services Supply Chain supported datasets, see <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html\">https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html</a>.</p> </li> <li> <p> <b>default</b> - Pre-defined namespace containing datasets with custom user-defined schemas.</p> </li> </ul>",
        "ListDataLakeDatasetsRequest$namespace": "<p>The namespace of the dataset, besides the custom defined namespace, every instance comes with below pre-defined namespaces:</p> <ul> <li> <p> <b>asc</b> - For information on the Amazon Web Services Supply Chain supported datasets see <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html\">https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html</a>.</p> </li> <li> <p> <b>default</b> - For datasets with custom user-defined schemas.</p> </li> </ul>",
        "UpdateDataLakeDatasetRequest$namespace": "<p>The namespace of the dataset, besides the custom defined namespace, every instance comes with below pre-defined namespaces:</p> <ul> <li> <p> <b>asc</b> - For information on the Amazon Web Services Supply Chain supported datasets see <a href=\"https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html\">https://docs.aws.amazon.com/aws-supply-chain/latest/userguide/data-model-asc.html</a>.</p> </li> <li> <p> <b>default</b> - For datasets with custom user-defined schemas.</p> </li> </ul>",
        "UpdateDataLakeNamespaceRequest$name": "<p>The name of the namespace. Noted you cannot update namespace with name starting with <b>asc</b>, <b>default</b>, <b>scn</b>, <b>aws</b>, <b>amazon</b>, <b>amzn</b> </p>"
      }
    },
    "DataLakeNamespaceNextToken": {
      "base": null,
      "refs": {
        "ListDataLakeNamespacesRequest$nextToken": "<p>The pagination token to fetch next page of namespaces.</p>",
        "ListDataLakeNamespacesResponse$nextToken": "<p>The pagination token to fetch next page of namespaces.</p>"
      }
    },
    "DatasetIdentifier": {
      "base": null,
      "refs": {
        "DataIntegrationFlowDatasetSourceConfiguration$datasetIdentifier": "<p>The ARN of the dataset.</p>",
        "DataIntegrationFlowDatasetTargetConfiguration$datasetIdentifier": "<p>The dataset ARN.</p>"
      }
    },
    "DeleteDataIntegrationFlowRequest": {
      "base": "<p>The request parameters for DeleteDataIntegrationFlow.</p>",
      "refs": {
      }
    },
    "DeleteDataIntegrationFlowResponse": {
      "base": "<p>The response parameters for DeleteDataIntegrationFlow.</p>",
      "refs": {
      }
    },
    "DeleteDataLakeDatasetRequest": {
      "base": "<p>The request parameters of DeleteDataLakeDataset.</p>",
      "refs": {
      }
    },
    "DeleteDataLakeDatasetResponse": {
      "base": "<p>The response parameters of DeleteDataLakeDataset.</p>",
      "refs": {
      }
    },
    "DeleteDataLakeNamespaceRequest": {
      "base": "<p>The request parameters of DeleteDataLakeNamespace.</p>",
      "refs": {
      }
    },
    "DeleteDataLakeNamespaceResponse": {
      "base": "<p>The response parameters of DeleteDataLakeNamespace.</p>",
      "refs": {
      }
    },
    "DeleteInstanceRequest": {
      "base": "<p>The request parameters for DeleteInstance.</p>",
      "refs": {
      }
    },
    "DeleteInstanceResponse": {
      "base": "<p>The response parameters for DeleteInstance.</p>",
      "refs": {
      }
    },
    "Double": {
      "base": null,
      "refs": {
        "Instance$versionNumber": "<p>The version number of the instance.</p>"
      }
    },
    "GetBillOfMaterialsImportJobRequest": {
      "base": "<p>The request parameters for GetBillOfMaterialsImportJob.</p>",
      "refs": {
      }
    },
    "GetBillOfMaterialsImportJobResponse": {
      "base": "<p>The response parameters for GetBillOfMaterialsImportJob.</p>",
      "refs": {
      }
    },
    "GetDataIntegrationEventRequest": {
      "base": "<p>The request parameters for GetDataIntegrationEvent.</p>",
      "refs": {
      }
    },
    "GetDataIntegrationEventResponse": {
      "base": "<p>The response parameters for GetDataIntegrationEvent.</p>",
      "refs": {
      }
    },
    "GetDataIntegrationFlowExecutionRequest": {
      "base": "<p>The request parameters of GetFlowExecution.</p>",
      "refs": {
      }
    },
    "GetDataIntegrationFlowExecutionResponse": {
      "base": "<p>The response parameters of GetFlowExecution.</p>",
      "refs": {
      }
    },
    "GetDataIntegrationFlowRequest": {
      "base": "<p>The request parameters for GetDataIntegrationFlow.</p>",
      "refs": {
      }
    },
    "GetDataIntegrationFlowResponse": {
      "base": "<p>The response parameters for GetDataIntegrationFlow.</p>",
      "refs": {
      }
    },
    "GetDataLakeDatasetRequest": {
      "base": "<p>The request parameters for GetDataLakeDataset.</p>",
      "refs": {
      }
    },
    "GetDataLakeDatasetResponse": {
      "base": "<p>The response parameters for GetDataLakeDataset.</p>",
      "refs": {
      }
    },
    "GetDataLakeNamespaceRequest": {
      "base": "<p>The request parameters for GetDataLakeNamespace.</p>",
      "refs": {
      }
    },
    "GetDataLakeNamespaceResponse": {
      "base": "<p>The response parameters for GetDataLakeNamespace.</p>",
      "refs": {
      }
    },
    "GetInstanceRequest": {
      "base": "<p>The request parameters for GetInstance.</p>",
      "refs": {
      }
    },
    "GetInstanceResponse": {
      "base": "<p>The response parameters for GetInstance.</p>",
      "refs": {
      }
    },
    "Instance": {
      "base": "<p>The details of the instance.</p>",
      "refs": {
        "CreateInstanceResponse$instance": "<p>The AWS Supply Chain instance resource data details.</p>",
        "DeleteInstanceResponse$instance": "<p>The AWS Supply Chain instance resource data details.</p>",
        "GetInstanceResponse$instance": "<p>The instance resource data details.</p>",
        "InstanceList$member": null,
        "UpdateInstanceResponse$instance": "<p>The instance resource data details.</p>"
      }
    },
    "InstanceDescription": {
      "base": null,
      "refs": {
        "CreateInstanceRequest$instanceDescription": "<p>The AWS Supply Chain instance description.</p>",
        "Instance$instanceDescription": "<p>The Amazon Web Services Supply Chain instance description.</p>",
        "UpdateInstanceRequest$instanceDescription": "<p>The AWS Supply Chain instance description.</p>"
      }
    },
    "InstanceList": {
      "base": null,
      "refs": {
        "ListInstancesResponse$instances": "<p>The list of instances resource data details.</p>"
      }
    },
    "InstanceMaxResults": {
      "base": null,
      "refs": {
        "ListInstancesRequest$maxResults": "<p>Specify the maximum number of instances to fetch in this paginated request.</p>"
      }
    },
    "InstanceName": {
      "base": null,
      "refs": {
        "CreateInstanceRequest$instanceName": "<p>The AWS Supply Chain instance name.</p>",
        "Instance$instanceName": "<p>The Amazon Web Services Supply Chain instance name.</p>",
        "InstanceNameList$member": null,
        "UpdateInstanceRequest$instanceName": "<p>The AWS Supply Chain instance name.</p>"
      }
    },
    "InstanceNameList": {
      "base": null,
      "refs": {
        "ListInstancesRequest$instanceNameFilter": "<p>The filter to ListInstances based on their names.</p>"
      }
    },
    "InstanceNextToken": {
      "base": null,
      "refs": {
        "ListInstancesRequest$nextToken": "<p>The pagination token to fetch the next page of instances.</p>",
        "ListInstancesResponse$nextToken": "<p>The pagination token to fetch the next page of instances.</p>"
      }
    },
    "InstanceState": {
      "base": null,
      "refs": {
        "Instance$state": "<p>The state of the instance.</p>",
        "InstanceStateList$member": null
      }
    },
    "InstanceStateList": {
      "base": null,
      "refs": {
        "ListInstancesRequest$instanceStateFilter": "<p>The filter to ListInstances based on their state.</p>"
      }
    },
    "InstanceWebAppDnsDomain": {
      "base": null,
      "refs": {
        "CreateInstanceRequest$webAppDnsDomain": "<p>The DNS subdomain of the web app. This would be \"example\" in the URL \"example.scn.global.on.aws\". You can set this to a custom value, as long as the domain isn't already being used by someone else. The name may only include alphanumeric characters and hyphens.</p>",
        "Instance$webAppDnsDomain": "<p>The WebApp DNS domain name of the instance.</p>"
      }
    },
    "InternalServerException": {
      "base": "<p>Unexpected error during processing of request.</p>",
      "refs": {
      }
    },
    "KmsKeyArn": {
      "base": null,
      "refs": {
        "CreateInstanceRequest$kmsKeyArn": "<p>The ARN (Amazon Resource Name) of the Key Management Service (KMS) key you provide for encryption. This is required if you do not want to use the Amazon Web Services owned KMS key. If you don't provide anything here, AWS Supply Chain uses the Amazon Web Services owned KMS key.</p>",
        "Instance$kmsKeyArn": "<p>The ARN (Amazon Resource Name) of the Key Management Service (KMS) key you optionally provided for encryption. If you did not provide anything here, AWS Supply Chain uses the Amazon Web Services owned KMS key and nothing is returned.</p>"
      }
    },
    "ListDataIntegrationEventsRequest": {
      "base": "<p>The request parameters for ListDataIntegrationEvents.</p>",
      "refs": {
      }
    },
    "ListDataIntegrationEventsResponse": {
      "base": "<p>The response parameters for ListDataIntegrationEvents.</p>",
      "refs": {
      }
    },
    "ListDataIntegrationFlowExecutionsRequest": {
      "base": "<p>The request parameters of ListFlowExecutions.</p>",
      "refs": {
      }
    },
    "ListDataIntegrationFlowExecutionsResponse": {
      "base": "<p>The response parameters of ListFlowExecutions.</p>",
      "refs": {
      }
    },
    "ListDataIntegrationFlowsRequest": {
      "base": "<p>The request parameters for ListDataIntegrationFlows.</p>",
      "refs": {
      }
    },
    "ListDataIntegrationFlowsResponse": {
      "base": "<p>The response parameters for ListDataIntegrationFlows.</p>",
      "refs": {
      }
    },
    "ListDataLakeDatasetsRequest": {
      "base": "<p>The request parameters of ListDataLakeDatasets.</p>",
      "refs": {
      }
    },
    "ListDataLakeDatasetsResponse": {
      "base": "<p>The response parameters of ListDataLakeDatasets.</p>",
      "refs": {
      }
    },
    "ListDataLakeNamespacesRequest": {
      "base": "<p>The request parameters of ListDataLakeNamespaces.</p>",
      "refs": {
      }
    },
    "ListDataLakeNamespacesResponse": {
      "base": "<p>The response parameters of ListDataLakeNamespaces.</p>",
      "refs": {
      }
    },
    "ListInstancesRequest": {
      "base": "<p>The request parameters for ListInstances.</p>",
      "refs": {
      }
    },
    "ListInstancesResponse": {
      "base": "<p>The response parameters for ListInstances.</p>",
      "refs": {
      }
    },
    "ListTagsForResourceRequest": {
      "base": "<p>The request parameters of ListTagsForResource.</p>",
      "refs": {
      }
    },
    "ListTagsForResourceResponse": {
      "base": "<p>The response parameters of ListTagsForResource.</p>",
      "refs": {
      }
    },
    "ResourceNotFoundException": {
      "base": "<p>Request references a resource which does not exist.</p>",
      "refs": {
      }
    },
    "S3BucketName": {
      "base": null,
      "refs": {
        "DataIntegrationFlowS3Source$bucketName": "<p>The S3 bucket name of the S3 source.</p>",
        "DataIntegrationFlowS3SourceConfiguration$bucketName": "<p>The bucketName of the S3 source objects.</p>",
        "DataIntegrationFlowS3TargetConfiguration$bucketName": "<p>The bucketName of the S3 target objects.</p>"
      }
    },
    "SendDataIntegrationEventRequest": {
      "base": "<p>The request parameters for SendDataIntegrationEvent.</p>",
      "refs": {
      }
    },
    "SendDataIntegrationEventResponse": {
      "base": "<p>The response parameters for SendDataIntegrationEvent.</p>",
      "refs": {
      }
    },
    "ServiceQuotaExceededException": {
      "base": "<p>Request would cause a service quota to be exceeded.</p>",
      "refs": {
      }
    },
    "String": {
      "base": null,
      "refs": {
        "AccessDeniedException$message": null,
        "BillOfMaterialsImportJob$message": "<p>When the BillOfMaterialsImportJob has reached a terminal state, there will be a message.</p>",
        "ConflictException$message": null,
        "DataIntegrationEventDatasetLoadExecutionDetails$message": "<p>The failure message (if any) of failed event load execution to dataset.</p>",
        "DataIntegrationFlowExecution$message": "<p>The failure message (if any) of failed flow execution.</p>",
        "Instance$errorMessage": "<p>The Amazon Web Services Supply Chain instance error message. If the instance results in an unhealthy state, customers need to check the error message, delete the current instance, and recreate a new one based on the mitigation from the error message.</p>",
        "InternalServerException$message": null,
        "ResourceNotFoundException$message": null,
        "ServiceQuotaExceededException$message": null,
        "ThrottlingException$message": null,
        "ValidationException$message": null
      }
    },
    "SyntheticTimestamp_epoch_seconds": {
      "base": null,
      "refs": {
        "SendDataIntegrationEventRequest$eventTimestamp": "<p>The timestamp (in epoch seconds) associated with the event. If not provided, it will be assigned with current timestamp.</p>"
      }
    },
    "TagKey": {
      "base": null,
      "refs": {
        "TagKeyList$member": null,
        "TagMap$key": null
      }
    },
    "TagKeyList": {
      "base": null,
      "refs": {
        "UntagResourceRequest$tagKeys": "<p>The list of tag keys to be deleted for an Amazon Web Services Supply Chain resource.</p>"
      }
    },
    "TagMap": {
      "base": null,
      "refs": {
        "CreateDataIntegrationFlowRequest$tags": "<p>The tags of the DataIntegrationFlow to be created</p>",
        "CreateDataLakeDatasetRequest$tags": "<p>The tags of the dataset.</p>",
        "CreateDataLakeNamespaceRequest$tags": "<p>The tags of the namespace.</p>",
        "CreateInstanceRequest$tags": "<p>The Amazon Web Services tags of an instance to be created.</p>",
        "ListTagsForResourceResponse$tags": "<p>The tags added to an Amazon Web Services Supply Chain resource.</p>",
        "TagResourceRequest$tags": "<p>The tags of the Amazon Web Services Supply chain resource to be created.</p>"
      }
    },
    "TagResourceRequest": {
      "base": "<p>The request parameters of TagResource.</p>",
      "refs": {
      }
    },
    "TagResourceResponse": {
      "base": "<p>The response parameters for TagResource.</p>",
      "refs": {
      }
    },
    "TagValue": {
      "base": null,
      "refs": {
        "TagMap$value": null
      }
    },
    "ThrottlingException": {
      "base": "<p>Request was denied due to request throttling.</p>",
      "refs": {
      }
    },
    "Timestamp": {
      "base": null,
      "refs": {
        "DataIntegrationEvent$eventTimestamp": "<p>The event timestamp (in epoch seconds).</p>",
        "DataIntegrationFlow$createdTime": "<p>The DataIntegrationFlow creation timestamp.</p>",
        "DataIntegrationFlow$lastModifiedTime": "<p>The DataIntegrationFlow last modified timestamp.</p>",
        "DataIntegrationFlowExecution$startTime": "<p>The flow execution start timestamp.</p>",
        "DataIntegrationFlowExecution$endTime": "<p>The flow execution end timestamp.</p>",
        "DataLakeDataset$createdTime": "<p>The creation time of the dataset.</p>",
        "DataLakeDataset$lastModifiedTime": "<p>The last modified time of the dataset.</p>",
        "DataLakeNamespace$createdTime": "<p>The creation time of the namespace.</p>",
        "DataLakeNamespace$lastModifiedTime": "<p>The last modified time of the namespace.</p>",
        "Instance$createdTime": "<p>The instance creation timestamp.</p>",
        "Instance$lastModifiedTime": "<p>The instance last modified timestamp.</p>"
      }
    },
    "UUID": {
      "base": null,
      "refs": {
        "BillOfMaterialsImportJob$instanceId": "<p>The BillOfMaterialsImportJob instanceId.</p>",
        "BillOfMaterialsImportJob$jobId": "<p>The BillOfMaterialsImportJob jobId.</p>",
        "CreateBillOfMaterialsImportJobRequest$instanceId": "<p>The AWS Supply Chain instance identifier.</p>",
        "CreateBillOfMaterialsImportJobResponse$jobId": "<p>The new BillOfMaterialsImportJob identifier.</p>",
        "CreateDataIntegrationFlowRequest$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "CreateDataIntegrationFlowResponse$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "CreateDataLakeDatasetRequest$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "CreateDataLakeNamespaceRequest$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "DataIntegrationEvent$instanceId": "<p>The AWS Supply Chain instance identifier.</p>",
        "DataIntegrationEvent$eventId": "<p>The unique event identifier.</p>",
        "DataIntegrationFlow$instanceId": "<p>The DataIntegrationFlow instance ID.</p>",
        "DataIntegrationFlowExecution$instanceId": "<p>The flow execution's instanceId.</p>",
        "DataIntegrationFlowExecution$executionId": "<p>The flow executionId.</p>",
        "DataLakeDataset$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "DataLakeNamespace$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "DeleteDataIntegrationFlowRequest$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "DeleteDataIntegrationFlowResponse$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "DeleteDataLakeDatasetRequest$instanceId": "<p>The AWS Supply Chain instance identifier.</p>",
        "DeleteDataLakeDatasetResponse$instanceId": "<p>The AWS Supply Chain instance identifier.</p>",
        "DeleteDataLakeNamespaceRequest$instanceId": "<p>The AWS Supply Chain instance identifier.</p>",
        "DeleteDataLakeNamespaceResponse$instanceId": "<p>The AWS Supply Chain instance identifier.</p>",
        "DeleteInstanceRequest$instanceId": "<p>The AWS Supply Chain instance identifier.</p>",
        "GetBillOfMaterialsImportJobRequest$instanceId": "<p>The AWS Supply Chain instance identifier.</p>",
        "GetBillOfMaterialsImportJobRequest$jobId": "<p>The BillOfMaterialsImportJob identifier.</p>",
        "GetDataIntegrationEventRequest$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "GetDataIntegrationEventRequest$eventId": "<p>The unique event identifier.</p>",
        "GetDataIntegrationFlowExecutionRequest$instanceId": "<p>The AWS Supply Chain instance identifier.</p>",
        "GetDataIntegrationFlowExecutionRequest$executionId": "<p>The flow execution identifier.</p>",
        "GetDataIntegrationFlowRequest$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "GetDataLakeDatasetRequest$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "GetDataLakeNamespaceRequest$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "GetInstanceRequest$instanceId": "<p>The AWS Supply Chain instance identifier</p>",
        "Instance$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "ListDataIntegrationEventsRequest$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "ListDataIntegrationFlowExecutionsRequest$instanceId": "<p>The AWS Supply Chain instance identifier.</p>",
        "ListDataIntegrationFlowsRequest$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "ListDataLakeDatasetsRequest$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "ListDataLakeNamespacesRequest$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "SendDataIntegrationEventRequest$instanceId": "<p>The AWS Supply Chain instance identifier.</p>",
        "SendDataIntegrationEventResponse$eventId": "<p>The unique event identifier.</p>",
        "UpdateDataIntegrationFlowRequest$instanceId": "<p>The Amazon Web Services Supply Chain instance identifier.</p>",
        "UpdateDataLakeDatasetRequest$instanceId": "<p>The Amazon Web Services Chain instance identifier.</p>",
        "UpdateDataLakeNamespaceRequest$instanceId": "<p>The Amazon Web Services Chain instance identifier.</p>",
        "UpdateInstanceRequest$instanceId": "<p>The AWS Supply Chain instance identifier.</p>"
      }
    },
    "UntagResourceRequest": {
      "base": "<p>The request parameters of UntagResource.</p>",
      "refs": {
      }
    },
    "UntagResourceResponse": {
      "base": "<p>The response parameters of UntagResource.</p>",
      "refs": {
      }
    },
    "UpdateDataIntegrationFlowRequest": {
      "base": "<p>The request parameters for UpdateDataIntegrationFlow.</p>",
      "refs": {
      }
    },
    "UpdateDataIntegrationFlowResponse": {
      "base": "<p>The response parameters for UpdateDataIntegrationFlow.</p>",
      "refs": {
      }
    },
    "UpdateDataLakeDatasetRequest": {
      "base": "<p>The request parameters of UpdateDataLakeDataset.</p>",
      "refs": {
      }
    },
    "UpdateDataLakeDatasetResponse": {
      "base": "<p>The response parameters of UpdateDataLakeDataset.</p>",
      "refs": {
      }
    },
    "UpdateDataLakeNamespaceRequest": {
      "base": "<p>The request parameters of UpdateDataLakeNamespace.</p>",
      "refs": {
      }
    },
    "UpdateDataLakeNamespaceResponse": {
      "base": "<p>The response parameters of UpdateDataLakeNamespace.</p>",
      "refs": {
      }
    },
    "UpdateInstanceRequest": {
      "base": "<p>The request parameters for UpdateInstance.</p>",
      "refs": {
      }
    },
    "UpdateInstanceResponse": {
      "base": "<p>The response parameters for UpdateInstance.</p>",
      "refs": {
      }
    },
    "ValidationException": {
      "base": "<p>The input does not satisfy the constraints specified by an AWS service.</p>",
      "refs": {
      }
    }
  }
}
