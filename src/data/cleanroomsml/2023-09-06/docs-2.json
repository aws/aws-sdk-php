{
  "version": "2.0",
  "service": "<p>Welcome to the <i>Amazon Web Services Clean Rooms ML API Reference</i>.</p> <p>Amazon Web Services Clean Rooms ML provides a privacy-enhancing method for two parties to identify similar users in their data without the need to share their data with each other. The first party brings the training data to Clean Rooms so that they can create and configure an audience model (lookalike model) and associate it with a collaboration. The second party then brings their seed data to Clean Rooms and generates an audience (lookalike segment) that resembles the training data.</p> <p>To learn more about Amazon Web Services Clean Rooms ML concepts, procedures, and best practices, see the <a href=\"https://docs.aws.amazon.com/clean-rooms/latest/userguide/machine-learning.html\">Clean Rooms User Guide</a>.</p> <p>To learn more about SQL commands, functions, and conditions supported in Clean Rooms, see the <a href=\"https://docs.aws.amazon.com/clean-rooms/latest/sql-reference/sql-reference.html\">Clean Rooms SQL Reference</a>.</p>",
  "operations": {
    "CancelTrainedModel": "<p>Submits a request to cancel the trained model job.</p>",
    "CancelTrainedModelInferenceJob": "<p>Submits a request to cancel a trained model inference job.</p>",
    "CreateAudienceModel": "<p>Defines the information necessary to create an audience model. An audience model is a machine learning model that Clean Rooms ML trains to measure similarity between users. Clean Rooms ML manages training and storing the audience model. The audience model can be used in multiple calls to the <a>StartAudienceGenerationJob</a> API.</p>",
    "CreateConfiguredAudienceModel": "<p>Defines the information necessary to create a configured audience model.</p>",
    "CreateConfiguredModelAlgorithm": "<p>Creates a configured model algorithm using a container image stored in an ECR repository.</p>",
    "CreateConfiguredModelAlgorithmAssociation": "<p>Associates a configured model algorithm to a collaboration for use by any member of the collaboration.</p>",
    "CreateMLInputChannel": "<p>Provides the information to create an ML input channel. An ML input channel is the result of a query that can be used for ML modeling.</p>",
    "CreateTrainedModel": "<p>Creates a trained model from an associated configured model algorithm using data from any member of the collaboration.</p>",
    "CreateTrainingDataset": "<p>Defines the information necessary to create a training dataset. In Clean Rooms ML, the <code>TrainingDataset</code> is metadata that points to a Glue table, which is read only during <code>AudienceModel</code> creation.</p>",
    "DeleteAudienceGenerationJob": "<p>Deletes the specified audience generation job, and removes all data associated with the job.</p>",
    "DeleteAudienceModel": "<p>Specifies an audience model that you want to delete. You can't delete an audience model if there are any configured audience models that depend on the audience model.</p>",
    "DeleteConfiguredAudienceModel": "<p>Deletes the specified configured audience model. You can't delete a configured audience model if there are any lookalike models that use the configured audience model. If you delete a configured audience model, it will be removed from any collaborations that it is associated to.</p>",
    "DeleteConfiguredAudienceModelPolicy": "<p>Deletes the specified configured audience model policy.</p>",
    "DeleteConfiguredModelAlgorithm": "<p>Deletes a configured model algorithm.</p>",
    "DeleteConfiguredModelAlgorithmAssociation": "<p>Deletes a configured model algorithm association.</p>",
    "DeleteMLConfiguration": "<p>Deletes a ML modeling configuration.</p>",
    "DeleteMLInputChannelData": "<p>Provides the information necessary to delete an ML input channel.</p>",
    "DeleteTrainedModelOutput": "<p>Deletes the model artifacts stored by the service.</p>",
    "DeleteTrainingDataset": "<p>Specifies a training dataset that you want to delete. You can't delete a training dataset if there are any audience models that depend on the training dataset. In Clean Rooms ML, the <code>TrainingDataset</code> is metadata that points to a Glue table, which is read only during <code>AudienceModel</code> creation. This action deletes the metadata.</p>",
    "GetAudienceGenerationJob": "<p>Returns information about an audience generation job.</p>",
    "GetAudienceModel": "<p>Returns information about an audience model</p>",
    "GetCollaborationConfiguredModelAlgorithmAssociation": "<p>Returns information about the configured model algorithm association in a collaboration.</p>",
    "GetCollaborationMLInputChannel": "<p>Returns information about a specific ML input channel in a collaboration.</p>",
    "GetCollaborationTrainedModel": "<p>Returns information about a trained model in a collaboration.</p>",
    "GetConfiguredAudienceModel": "<p>Returns information about a specified configured audience model.</p>",
    "GetConfiguredAudienceModelPolicy": "<p>Returns information about a configured audience model policy.</p>",
    "GetConfiguredModelAlgorithm": "<p>Returns information about a configured model algorithm.</p>",
    "GetConfiguredModelAlgorithmAssociation": "<p>Returns information about a configured model algorithm association.</p>",
    "GetMLConfiguration": "<p>Returns information about a specific ML configuration.</p>",
    "GetMLInputChannel": "<p>Returns information about an ML input channel.</p>",
    "GetTrainedModel": "<p>Returns information about a trained model.</p>",
    "GetTrainedModelInferenceJob": "<p>Returns information about a trained model inference job.</p>",
    "GetTrainingDataset": "<p>Returns information about a training dataset.</p>",
    "ListAudienceExportJobs": "<p>Returns a list of the audience export jobs.</p>",
    "ListAudienceGenerationJobs": "<p>Returns a list of audience generation jobs.</p>",
    "ListAudienceModels": "<p>Returns a list of audience models.</p>",
    "ListCollaborationConfiguredModelAlgorithmAssociations": "<p>Returns a list of the configured model algorithm associations in a collaboration.</p>",
    "ListCollaborationMLInputChannels": "<p>Returns a list of the ML input channels in a collaboration.</p>",
    "ListCollaborationTrainedModelExportJobs": "<p>Returns a list of the export jobs for a trained model in a collaboration.</p>",
    "ListCollaborationTrainedModelInferenceJobs": "<p>Returns a list of trained model inference jobs in a specified collaboration.</p>",
    "ListCollaborationTrainedModels": "<p>Returns a list of the trained models in a collaboration.</p>",
    "ListConfiguredAudienceModels": "<p>Returns a list of the configured audience models.</p>",
    "ListConfiguredModelAlgorithmAssociations": "<p>Returns a list of configured model algorithm associations.</p>",
    "ListConfiguredModelAlgorithms": "<p>Returns a list of configured model algorithms.</p>",
    "ListMLInputChannels": "<p>Returns a list of ML input channels.</p>",
    "ListTagsForResource": "<p>Returns a list of tags for a provided resource.</p>",
    "ListTrainedModelInferenceJobs": "<p>Returns a list of trained model inference jobs that match the request parameters.</p>",
    "ListTrainedModelVersions": "<p>Returns a list of trained model versions for a specified trained model. This operation allows you to view all versions of a trained model, including information about their status and creation details. You can use this to track the evolution of your trained models and select specific versions for inference or further training.</p>",
    "ListTrainedModels": "<p>Returns a list of trained models.</p>",
    "ListTrainingDatasets": "<p>Returns a list of training datasets.</p>",
    "PutConfiguredAudienceModelPolicy": "<p>Create or update the resource policy for a configured audience model.</p>",
    "PutMLConfiguration": "<p>Assigns information about an ML configuration.</p>",
    "StartAudienceExportJob": "<p>Export an audience of a specified size after you have generated an audience.</p>",
    "StartAudienceGenerationJob": "<p>Information necessary to start the audience generation job.</p>",
    "StartTrainedModelExportJob": "<p>Provides the information necessary to start a trained model export job.</p>",
    "StartTrainedModelInferenceJob": "<p>Defines the information necessary to begin a trained model inference job.</p>",
    "TagResource": "<p>Adds metadata tags to a specified resource.</p>",
    "UntagResource": "<p>Removes metadata tags from a specified resource.</p>",
    "UpdateConfiguredAudienceModel": "<p>Provides the information necessary to update a configured audience model. Updates that impact audience generation jobs take effect when a new job starts, but do not impact currently running jobs.</p>"
  },
  "shapes": {
    "AccessDeniedException": {
      "base": "<p>You do not have sufficient access to perform this action.</p>",
      "refs": {
      }
    },
    "AccountId": {
      "base": null,
      "refs": {
        "AudienceGenerationJobSummary$startedBy": "<p>The AWS Account that submitted the job.</p>",
        "CollaborationConfiguredModelAlgorithmAssociationSummary$creatorAccountId": "<p>The account ID of the member that created the configured model algorithm association.</p>",
        "CollaborationMLInputChannelSummary$creatorAccountId": "<p>The account ID of the member who created the ML input channel.</p>",
        "CollaborationTrainedModelExportJobSummary$creatorAccountId": "<p>The account ID of the member that created the trained model.</p>",
        "CollaborationTrainedModelInferenceJobSummary$creatorAccountId": "<p>The account ID that created the trained model inference job.</p>",
        "CollaborationTrainedModelSummary$creatorAccountId": "<p>The account ID of the member that created the trained model.</p>",
        "GetAudienceGenerationJobResponse$startedBy": "<p>The AWS account that started this audience generation job.</p>",
        "GetCollaborationConfiguredModelAlgorithmAssociationResponse$creatorAccountId": "<p>The account ID of the member that created the configured model algorithm association.</p>",
        "GetCollaborationMLInputChannelResponse$creatorAccountId": "<p>The account ID of the member who created the ML input channel.</p>",
        "GetCollaborationTrainedModelResponse$creatorAccountId": "<p>The account ID of the member that created the trained model.</p>",
        "GlueDataSource$catalogId": "<p>The Glue catalog that contains the training data.</p>",
        "InferenceReceiverMember$accountId": "<p>The account ID of the member that can receive inference results.</p>",
        "TrainedModelExportReceiverMember$accountId": "<p>The account ID of the member who will receive trained model exports.</p>"
      }
    },
    "AccountIdList": {
      "base": null,
      "refs": {
        "LogsConfigurationPolicy$allowedAccountIds": "<p>A list of account IDs that are allowed to access the logs.</p>"
      }
    },
    "AlgorithmImage": {
      "base": null,
      "refs": {
        "ContainerConfig$imageUri": "<p>The registry path of the docker image that contains the algorithm. Clean Rooms ML currently only supports the <code>registry/repository[:tag]</code> image path format. For more information about using images in Clean Rooms ML, see the <a href=\"https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_AlgorithmSpecification.html#sagemaker-Type-AlgorithmSpecification-TrainingImage\">Sagemaker API reference</a>.</p>",
        "InferenceContainerConfig$imageUri": "<p>The registry path of the docker image that contains the inference algorithm. Clean Rooms ML currently only supports the <code>registry/repository[:tag]</code> image path format. For more information about using images in Clean Rooms ML, see the <a href=\"https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_AlgorithmSpecification.html#sagemaker-Type-AlgorithmSpecification-TrainingImage\">Sagemaker API reference</a>.</p>"
      }
    },
    "AnalysisTemplateArn": {
      "base": null,
      "refs": {
        "ProtectedQuerySQLParameters$analysisTemplateArn": "<p>The Amazon Resource Name (ARN) associated with the analysis template within a collaboration.</p>"
      }
    },
    "AudienceDestination": {
      "base": "<p>Defines the Amazon S3 bucket where the configured audience is stored.</p>",
      "refs": {
        "ConfiguredAudienceModelOutputConfig$destination": null
      }
    },
    "AudienceExportJobList": {
      "base": null,
      "refs": {
        "ListAudienceExportJobsResponse$audienceExportJobs": "<p>The audience export jobs that match the request.</p>"
      }
    },
    "AudienceExportJobStatus": {
      "base": null,
      "refs": {
        "AudienceExportJobSummary$status": "<p>The status of the audience export job.</p>"
      }
    },
    "AudienceExportJobSummary": {
      "base": "<p>Provides information about the audience export job.</p>",
      "refs": {
        "AudienceExportJobList$member": null
      }
    },
    "AudienceGenerationJobArn": {
      "base": null,
      "refs": {
        "AudienceExportJobSummary$audienceGenerationJobArn": "<p>The Amazon Resource Name (ARN) of the audience generation job that was exported.</p>",
        "AudienceGenerationJobSummary$audienceGenerationJobArn": "<p>The Amazon Resource Name (ARN) of the audience generation job.</p>",
        "DeleteAudienceGenerationJobRequest$audienceGenerationJobArn": "<p>The Amazon Resource Name (ARN) of the audience generation job that you want to delete.</p>",
        "GetAudienceGenerationJobRequest$audienceGenerationJobArn": "<p>The Amazon Resource Name (ARN) of the audience generation job that you are interested in.</p>",
        "GetAudienceGenerationJobResponse$audienceGenerationJobArn": "<p>The Amazon Resource Name (ARN) of the audience generation job.</p>",
        "ListAudienceExportJobsRequest$audienceGenerationJobArn": "<p>The Amazon Resource Name (ARN) of the audience generation job that you are interested in.</p>",
        "StartAudienceExportJobRequest$audienceGenerationJobArn": "<p>The Amazon Resource Name (ARN) of the audience generation job that you want to export.</p>",
        "StartAudienceGenerationJobResponse$audienceGenerationJobArn": "<p>The Amazon Resource Name (ARN) of the audience generation job.</p>"
      }
    },
    "AudienceGenerationJobDataSource": {
      "base": "<p>Defines the Amazon S3 bucket where the seed audience for the generating audience is stored.</p>",
      "refs": {
        "GetAudienceGenerationJobResponse$seedAudience": "<p>The seed audience that was used for this audience generation job. This field will be null if the account calling the API is the account that started this audience generation job. </p>",
        "StartAudienceGenerationJobRequest$seedAudience": "<p>The seed audience that is used to generate the audience.</p>"
      }
    },
    "AudienceGenerationJobList": {
      "base": null,
      "refs": {
        "ListAudienceGenerationJobsResponse$audienceGenerationJobs": "<p>The audience generation jobs that match the request.</p>"
      }
    },
    "AudienceGenerationJobStatus": {
      "base": null,
      "refs": {
        "AudienceGenerationJobSummary$status": "<p>The status of the audience generation job.</p>",
        "GetAudienceGenerationJobResponse$status": "<p>The status of the audience generation job.</p>"
      }
    },
    "AudienceGenerationJobSummary": {
      "base": "<p>Provides information about the configured audience generation job.</p>",
      "refs": {
        "AudienceGenerationJobList$member": null
      }
    },
    "AudienceModelArn": {
      "base": null,
      "refs": {
        "AudienceModelSummary$audienceModelArn": "<p>The Amazon Resource Name (ARN) of the audience model.</p>",
        "ConfiguredAudienceModelSummary$audienceModelArn": "<p>The Amazon Resource Name (ARN) of the audience model that was used to create the configured audience model.</p>",
        "CreateAudienceModelResponse$audienceModelArn": "<p>The Amazon Resource Name (ARN) of the audience model.</p>",
        "CreateConfiguredAudienceModelRequest$audienceModelArn": "<p>The Amazon Resource Name (ARN) of the audience model to use for the configured audience model.</p>",
        "DeleteAudienceModelRequest$audienceModelArn": "<p>The Amazon Resource Name (ARN) of the audience model that you want to delete.</p>",
        "GetAudienceModelRequest$audienceModelArn": "<p>The Amazon Resource Name (ARN) of the audience model that you are interested in.</p>",
        "GetAudienceModelResponse$audienceModelArn": "<p>The Amazon Resource Name (ARN) of the audience model.</p>",
        "GetConfiguredAudienceModelResponse$audienceModelArn": "<p>The Amazon Resource Name (ARN) of the audience model used for this configured audience model.</p>",
        "UpdateConfiguredAudienceModelRequest$audienceModelArn": "<p>The Amazon Resource Name (ARN) of the new audience model that you want to use.</p>"
      }
    },
    "AudienceModelList": {
      "base": null,
      "refs": {
        "ListAudienceModelsResponse$audienceModels": "<p>The audience models that match the request.</p>"
      }
    },
    "AudienceModelStatus": {
      "base": null,
      "refs": {
        "AudienceModelSummary$status": "<p>The status of the audience model.</p>",
        "GetAudienceModelResponse$status": "<p>The status of the audience model.</p>"
      }
    },
    "AudienceModelSummary": {
      "base": "<p>Information about the audience model.</p>",
      "refs": {
        "AudienceModelList$member": null
      }
    },
    "AudienceQualityMetrics": {
      "base": "<p>Metrics that describe the quality of the generated audience.</p>",
      "refs": {
        "GetAudienceGenerationJobResponse$metrics": "<p>The relevance scores for different audience sizes and the recall score of the generated audience. </p>"
      }
    },
    "AudienceQualityMetricsRecallMetricDouble": {
      "base": null,
      "refs": {
        "AudienceQualityMetrics$recallMetric": "<p>The recall score of the generated audience. Recall is the percentage of the most similar users (by default, the most similar 20%) from a sample of the training data that are included in the seed audience by the audience generation job. Values range from 0-1, larger values indicate a better audience. A recall value approximately equal to the maximum bin size indicates that the audience model is equivalent to random selection. </p>"
      }
    },
    "AudienceSize": {
      "base": "<p>The size of the generated audience. Must match one of the sizes in the configured audience model.</p>",
      "refs": {
        "AudienceExportJobSummary$audienceSize": null,
        "RelevanceMetric$audienceSize": null,
        "StartAudienceExportJobRequest$audienceSize": null
      }
    },
    "AudienceSizeBins": {
      "base": null,
      "refs": {
        "AudienceSizeConfig$audienceSizeBins": "<p>An array of the different audience output sizes.</p>"
      }
    },
    "AudienceSizeConfig": {
      "base": "<p>Returns the relevance scores at these audience sizes when used in the <a>GetAudienceGenerationJob</a> for a specified audience generation job and configured audience model.</p> <p>Specifies the list of allowed <code>audienceSize</code> values when used in the <a>StartAudienceExportJob</a> for an audience generation job. You can use the <code>ABSOLUTE</code> <a>AudienceSize</a> to configure out audience sizes using the count of identifiers in the output. You can use the <code>Percentage</code> <a>AudienceSize</a> to configure sizes in the range 1-100 percent.</p>",
      "refs": {
        "CreateConfiguredAudienceModelRequest$audienceSizeConfig": "<p>Configure the list of output sizes of audiences that can be created using this configured audience model. A request to <a>StartAudienceGenerationJob</a> that uses this configured audience model must have an <code>audienceSize</code> selected from this list. You can use the <code>ABSOLUTE</code> <a>AudienceSize</a> to configure out audience sizes using the count of identifiers in the output. You can use the <code>Percentage</code> <a>AudienceSize</a> to configure sizes in the range 1-100 percent.</p>",
        "GetConfiguredAudienceModelResponse$audienceSizeConfig": "<p>The list of output sizes of audiences that can be created using this configured audience model. A request to <a>StartAudienceGenerationJob</a> that uses this configured audience model must have an <code>audienceSize</code> selected from this list. You can use the <code>ABSOLUTE</code> <a>AudienceSize</a> to configure out audience sizes using the count of identifiers in the output. You can use the <code>Percentage</code> <a>AudienceSize</a> to configure sizes in the range 1-100 percent.</p>",
        "UpdateConfiguredAudienceModelRequest$audienceSizeConfig": "<p>The new audience size configuration.</p>"
      }
    },
    "AudienceSizeType": {
      "base": null,
      "refs": {
        "AudienceSize$type": "<p>Whether the audience size is defined in absolute terms or as a percentage. You can use the <code>ABSOLUTE</code> <a>AudienceSize</a> to configure out audience sizes using the count of identifiers in the output. You can use the <code>Percentage</code> <a>AudienceSize</a> to configure sizes in the range 1-100 percent.</p>",
        "AudienceSizeConfig$audienceSizeType": "<p>Whether the audience output sizes are defined as an absolute number or a percentage.</p>"
      }
    },
    "AudienceSizeValue": {
      "base": null,
      "refs": {
        "AudienceSize$value": "<p>Specify an audience size value.</p>",
        "AudienceSizeBins$member": null
      }
    },
    "Boolean": {
      "base": null,
      "refs": {
        "GetAudienceGenerationJobResponse$includeSeedInOutput": "<p>Configure whether the seed users are included in the output audience. By default, Clean Rooms ML removes seed users from the output audience. If you specify <code>TRUE</code>, the seed users will appear first in the output. Clean Rooms ML does not explicitly reveal whether a user was in the seed, but the recipient of the audience will know that the first <code>minimumSeedSize</code> count of users are from the seed.</p>",
        "StartAudienceGenerationJobRequest$includeSeedInOutput": "<p>Whether the seed audience is included in the audience generation output.</p>"
      }
    },
    "CancelTrainedModelInferenceJobRequest": {
      "base": null,
      "refs": {
      }
    },
    "CancelTrainedModelRequest": {
      "base": null,
      "refs": {
      }
    },
    "CollaborationConfiguredModelAlgorithmAssociationList": {
      "base": null,
      "refs": {
        "ListCollaborationConfiguredModelAlgorithmAssociationsResponse$collaborationConfiguredModelAlgorithmAssociations": "<p>The configured model algorithm associations that belong to this collaboration.</p>"
      }
    },
    "CollaborationConfiguredModelAlgorithmAssociationSummary": {
      "base": "<p>Provides summary information about a configured model algorithm in a collaboration.</p>",
      "refs": {
        "CollaborationConfiguredModelAlgorithmAssociationList$member": null
      }
    },
    "CollaborationMLInputChannelSummary": {
      "base": "<p>Provides summary information about an ML input channel in a collaboration.</p>",
      "refs": {
        "CollaborationMLInputChannelsList$member": null
      }
    },
    "CollaborationMLInputChannelSummaryConfiguredModelAlgorithmAssociationsList": {
      "base": null,
      "refs": {
        "CollaborationMLInputChannelSummary$configuredModelAlgorithmAssociations": "<p>The associated configured model algorithms used to create the ML input channel.</p>"
      }
    },
    "CollaborationMLInputChannelsList": {
      "base": null,
      "refs": {
        "ListCollaborationMLInputChannelsResponse$collaborationMLInputChannelsList": "<p>The list of ML input channels that you wanted.</p>"
      }
    },
    "CollaborationTrainedModelExportJobList": {
      "base": null,
      "refs": {
        "ListCollaborationTrainedModelExportJobsResponse$collaborationTrainedModelExportJobs": "<p>The exports jobs that exist for the requested trained model in the requested collaboration.</p>"
      }
    },
    "CollaborationTrainedModelExportJobSummary": {
      "base": "<p>Provides summary information about a trained model export job in a collaboration.</p>",
      "refs": {
        "CollaborationTrainedModelExportJobList$member": null
      }
    },
    "CollaborationTrainedModelInferenceJobList": {
      "base": null,
      "refs": {
        "ListCollaborationTrainedModelInferenceJobsResponse$collaborationTrainedModelInferenceJobs": "<p>The trained model inference jobs that you are interested in.</p>"
      }
    },
    "CollaborationTrainedModelInferenceJobSummary": {
      "base": "<p>Provides summary information about a trained model inference job in a collaboration.</p>",
      "refs": {
        "CollaborationTrainedModelInferenceJobList$member": null
      }
    },
    "CollaborationTrainedModelList": {
      "base": null,
      "refs": {
        "ListCollaborationTrainedModelsResponse$collaborationTrainedModels": "<p>The trained models in the collaboration that you requested.</p>"
      }
    },
    "CollaborationTrainedModelSummary": {
      "base": "<p>Provides summary information about a trained model in a collaboration.</p>",
      "refs": {
        "CollaborationTrainedModelList$member": null
      }
    },
    "ColumnName": {
      "base": null,
      "refs": {
        "ColumnSchema$columnName": "<p>The name of a column.</p>"
      }
    },
    "ColumnSchema": {
      "base": "<p>Metadata for a column.</p>",
      "refs": {
        "DatasetInputConfigSchemaList$member": null
      }
    },
    "ColumnType": {
      "base": null,
      "refs": {
        "ColumnTypeList$member": null
      }
    },
    "ColumnTypeList": {
      "base": null,
      "refs": {
        "ColumnSchema$columnTypes": "<p>The data type of column.</p>"
      }
    },
    "ComputeConfiguration": {
      "base": "<p>Provides configuration information for the instances that will perform the compute work.</p>",
      "refs": {
        "AudienceGenerationJobDataSource$sqlComputeConfiguration": null,
        "ProtectedQueryInputParameters$computeConfiguration": "<p>Provides configuration information for the workers that will perform the protected query.</p>"
      }
    },
    "ConfiguredAudienceModelArn": {
      "base": null,
      "refs": {
        "AudienceGenerationJobSummary$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model that was used for this audience generation job.</p>",
        "ConfiguredAudienceModelSummary$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model that you are interested in.</p>",
        "CreateConfiguredAudienceModelResponse$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model.</p>",
        "DeleteConfiguredAudienceModelPolicyRequest$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model policy that you want to delete.</p>",
        "DeleteConfiguredAudienceModelRequest$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model that you want to delete.</p>",
        "GetAudienceGenerationJobResponse$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model used for this audience generation job.</p>",
        "GetConfiguredAudienceModelPolicyRequest$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model that you are interested in.</p>",
        "GetConfiguredAudienceModelPolicyResponse$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model.</p>",
        "GetConfiguredAudienceModelRequest$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model that you are interested in.</p>",
        "GetConfiguredAudienceModelResponse$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model.</p>",
        "ListAudienceGenerationJobsRequest$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model that was used for the audience generation jobs that you are interested in.</p>",
        "PutConfiguredAudienceModelPolicyRequest$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model that the resource policy will govern.</p>",
        "StartAudienceGenerationJobRequest$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model that is used for this audience generation job.</p>",
        "UpdateConfiguredAudienceModelRequest$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model that you want to update.</p>",
        "UpdateConfiguredAudienceModelResponse$configuredAudienceModelArn": "<p>The Amazon Resource Name (ARN) of the configured audience model that was updated.</p>"
      }
    },
    "ConfiguredAudienceModelList": {
      "base": null,
      "refs": {
        "ListConfiguredAudienceModelsResponse$configuredAudienceModels": "<p>The configured audience models.</p>"
      }
    },
    "ConfiguredAudienceModelOutputConfig": {
      "base": "<p>Configuration information necessary for the configure audience model output.</p>",
      "refs": {
        "ConfiguredAudienceModelSummary$outputConfig": "<p>The output configuration of the configured audience model.</p>",
        "CreateConfiguredAudienceModelRequest$outputConfig": "<p>Configure the Amazon S3 location and IAM Role for audiences created using this configured audience model. Each audience will have a unique location. The IAM Role must have <code>s3:PutObject</code> permission on the destination Amazon S3 location. If the destination is protected with Amazon S3 KMS-SSE, then the Role must also have the required KMS permissions.</p>",
        "GetConfiguredAudienceModelResponse$outputConfig": "<p>The output configuration of the configured audience model</p>",
        "UpdateConfiguredAudienceModelRequest$outputConfig": "<p>The new output configuration.</p>"
      }
    },
    "ConfiguredAudienceModelStatus": {
      "base": null,
      "refs": {
        "ConfiguredAudienceModelSummary$status": "<p>The status of the configured audience model.</p>",
        "GetConfiguredAudienceModelResponse$status": "<p>The status of the configured audience model.</p>"
      }
    },
    "ConfiguredAudienceModelSummary": {
      "base": "<p>Information about the configured audience model.</p>",
      "refs": {
        "ConfiguredAudienceModelList$member": null
      }
    },
    "ConfiguredModelAlgorithmArn": {
      "base": null,
      "refs": {
        "CollaborationConfiguredModelAlgorithmAssociationSummary$configuredModelAlgorithmArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm that is associated to the collaboration.</p>",
        "ConfiguredModelAlgorithmAssociationSummary$configuredModelAlgorithmArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm that is being associated.</p>",
        "ConfiguredModelAlgorithmSummary$configuredModelAlgorithmArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm.</p>",
        "CreateConfiguredModelAlgorithmAssociationRequest$configuredModelAlgorithmArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm that you want to associate.</p>",
        "CreateConfiguredModelAlgorithmResponse$configuredModelAlgorithmArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm.</p>",
        "DeleteConfiguredModelAlgorithmRequest$configuredModelAlgorithmArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm that you want to delete.</p>",
        "GetCollaborationConfiguredModelAlgorithmAssociationResponse$configuredModelAlgorithmArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association.</p>",
        "GetConfiguredModelAlgorithmAssociationResponse$configuredModelAlgorithmArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm that was associated to the collaboration.</p>",
        "GetConfiguredModelAlgorithmRequest$configuredModelAlgorithmArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm that you want to return information about.</p>",
        "GetConfiguredModelAlgorithmResponse$configuredModelAlgorithmArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm.</p>"
      }
    },
    "ConfiguredModelAlgorithmAssociationArn": {
      "base": null,
      "refs": {
        "CollaborationConfiguredModelAlgorithmAssociationSummary$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association.</p>",
        "CollaborationMLInputChannelSummaryConfiguredModelAlgorithmAssociationsList$member": null,
        "CollaborationTrainedModelInferenceJobSummary$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association that is used for the trained model inference job.</p>",
        "CollaborationTrainedModelSummary$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association that is used for this trained model.</p>",
        "ConfiguredModelAlgorithmAssociationSummary$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association.</p>",
        "CreateConfiguredModelAlgorithmAssociationResponse$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association.</p>",
        "CreateMLInputChannelRequestConfiguredModelAlgorithmAssociationsList$member": null,
        "CreateTrainedModelRequest$configuredModelAlgorithmAssociationArn": "<p>The associated configured model algorithm used to train this model.</p>",
        "DeleteConfiguredModelAlgorithmAssociationRequest$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association that you want to delete.</p>",
        "GetCollaborationConfiguredModelAlgorithmAssociationRequest$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association that you want to return information about.</p>",
        "GetCollaborationConfiguredModelAlgorithmAssociationResponse$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association.</p>",
        "GetCollaborationMLInputChannelResponseConfiguredModelAlgorithmAssociationsList$member": null,
        "GetCollaborationTrainedModelResponse$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association that was used to create this trained model.</p>",
        "GetConfiguredModelAlgorithmAssociationRequest$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association that you want to return information about.</p>",
        "GetConfiguredModelAlgorithmAssociationResponse$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association.</p>",
        "GetMLInputChannelResponseConfiguredModelAlgorithmAssociationsList$member": null,
        "GetTrainedModelInferenceJobResponse$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association that was used for the trained model inference job.</p>",
        "GetTrainedModelResponse$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association that was used to create the trained model.</p>",
        "MLInputChannelSummaryConfiguredModelAlgorithmAssociationsList$member": null,
        "StartTrainedModelInferenceJobRequest$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association that is used for this trained model inference job.</p>",
        "TrainedModelInferenceJobSummary$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association that is used for the trained model inference job.</p>",
        "TrainedModelSummary$configuredModelAlgorithmAssociationArn": "<p>The Amazon Resource Name (ARN) of the configured model algorithm association that was used to create this trained model.</p>"
      }
    },
    "ConfiguredModelAlgorithmAssociationList": {
      "base": null,
      "refs": {
        "ListConfiguredModelAlgorithmAssociationsResponse$configuredModelAlgorithmAssociations": "<p>The list of configured model algorithm associations.</p>"
      }
    },
    "ConfiguredModelAlgorithmAssociationSummary": {
      "base": "<p>Provides summary information about the configured model algorithm association.</p>",
      "refs": {
        "ConfiguredModelAlgorithmAssociationList$member": null
      }
    },
    "ConfiguredModelAlgorithmList": {
      "base": null,
      "refs": {
        "ListConfiguredModelAlgorithmsResponse$configuredModelAlgorithms": "<p>The list of configured model algorithms.</p>"
      }
    },
    "ConfiguredModelAlgorithmSummary": {
      "base": "<p>Provides summary information about a configured model algorithm.</p>",
      "refs": {
        "ConfiguredModelAlgorithmList$member": null
      }
    },
    "ConflictException": {
      "base": "<p>You can't complete this action because another resource depends on this resource.</p>",
      "refs": {
      }
    },
    "ContainerArgument": {
      "base": null,
      "refs": {
        "ContainerArguments$member": null
      }
    },
    "ContainerArguments": {
      "base": null,
      "refs": {
        "ContainerConfig$arguments": "<p>The arguments for a container used to run a training job. See How Amazon SageMaker Runs Your Training Image for additional information. For more information, see <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-dockerfile.html\">How Sagemaker runs your training image</a>.</p>"
      }
    },
    "ContainerConfig": {
      "base": "<p>Provides configuration information for the dockerized container where the model algorithm is stored.</p>",
      "refs": {
        "CreateConfiguredModelAlgorithmRequest$trainingContainerConfig": "<p>Configuration information for the training container, including entrypoints and arguments.</p>",
        "GetConfiguredModelAlgorithmResponse$trainingContainerConfig": "<p>The configuration information of the training container for the configured model algorithm.</p>"
      }
    },
    "ContainerEntrypoint": {
      "base": null,
      "refs": {
        "ContainerConfig$entrypoint": "<p>The entrypoint script for a Docker container used to run a training job. This script takes precedence over the default train processing instructions. See How Amazon SageMaker Runs Your Training Image for additional information. For more information, see <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-dockerfile.html\">How Sagemaker runs your training image</a>.</p>"
      }
    },
    "ContainerEntrypointString": {
      "base": null,
      "refs": {
        "ContainerEntrypoint$member": null
      }
    },
    "CreateAudienceModelRequest": {
      "base": null,
      "refs": {
      }
    },
    "CreateAudienceModelResponse": {
      "base": null,
      "refs": {
      }
    },
    "CreateConfiguredAudienceModelRequest": {
      "base": null,
      "refs": {
      }
    },
    "CreateConfiguredAudienceModelResponse": {
      "base": null,
      "refs": {
      }
    },
    "CreateConfiguredModelAlgorithmAssociationRequest": {
      "base": null,
      "refs": {
      }
    },
    "CreateConfiguredModelAlgorithmAssociationResponse": {
      "base": null,
      "refs": {
      }
    },
    "CreateConfiguredModelAlgorithmRequest": {
      "base": null,
      "refs": {
      }
    },
    "CreateConfiguredModelAlgorithmResponse": {
      "base": null,
      "refs": {
      }
    },
    "CreateMLInputChannelRequest": {
      "base": null,
      "refs": {
      }
    },
    "CreateMLInputChannelRequestConfiguredModelAlgorithmAssociationsList": {
      "base": null,
      "refs": {
        "CreateMLInputChannelRequest$configuredModelAlgorithmAssociations": "<p>The associated configured model algorithms that are necessary to create this ML input channel.</p>"
      }
    },
    "CreateMLInputChannelRequestRetentionInDaysInteger": {
      "base": null,
      "refs": {
        "CreateMLInputChannelRequest$retentionInDays": "<p>The number of days that the data in the ML input channel is retained.</p>"
      }
    },
    "CreateMLInputChannelResponse": {
      "base": null,
      "refs": {
      }
    },
    "CreateTrainedModelRequest": {
      "base": null,
      "refs": {
      }
    },
    "CreateTrainedModelResponse": {
      "base": null,
      "refs": {
      }
    },
    "CreateTrainingDatasetRequest": {
      "base": null,
      "refs": {
      }
    },
    "CreateTrainingDatasetRequestTrainingDataList": {
      "base": null,
      "refs": {
        "CreateTrainingDatasetRequest$trainingData": "<p>An array of information that lists the Dataset objects, which specifies the dataset type and details on its location and schema. You must provide a role that has read access to these tables.</p>"
      }
    },
    "CreateTrainingDatasetResponse": {
      "base": null,
      "refs": {
      }
    },
    "DataSource": {
      "base": "<p>Defines information about the Glue data source that contains the training data.</p>",
      "refs": {
        "DatasetInputConfig$dataSource": "<p>A DataSource object that specifies the Glue data source for the training data.</p>"
      }
    },
    "Dataset": {
      "base": "<p>Defines where the training dataset is located, what type of data it contains, and how to access the data.</p>",
      "refs": {
        "CreateTrainingDatasetRequestTrainingDataList$member": null,
        "DatasetList$member": null
      }
    },
    "DatasetInputConfig": {
      "base": "<p>Defines the Glue data source and schema mapping information.</p>",
      "refs": {
        "Dataset$inputConfig": "<p>A DatasetInputConfig object that defines the data source and schema mapping.</p>"
      }
    },
    "DatasetInputConfigSchemaList": {
      "base": null,
      "refs": {
        "DatasetInputConfig$schema": "<p>The schema information for the training data.</p>"
      }
    },
    "DatasetList": {
      "base": null,
      "refs": {
        "GetTrainingDatasetResponse$trainingData": "<p>Metadata about the requested training data. </p>"
      }
    },
    "DatasetType": {
      "base": null,
      "refs": {
        "Dataset$type": "<p>What type of information is found in the dataset.</p>"
      }
    },
    "DeleteAudienceGenerationJobRequest": {
      "base": null,
      "refs": {
      }
    },
    "DeleteAudienceModelRequest": {
      "base": null,
      "refs": {
      }
    },
    "DeleteConfiguredAudienceModelPolicyRequest": {
      "base": null,
      "refs": {
      }
    },
    "DeleteConfiguredAudienceModelRequest": {
      "base": null,
      "refs": {
      }
    },
    "DeleteConfiguredModelAlgorithmAssociationRequest": {
      "base": null,
      "refs": {
      }
    },
    "DeleteConfiguredModelAlgorithmRequest": {
      "base": null,
      "refs": {
      }
    },
    "DeleteMLConfigurationRequest": {
      "base": null,
      "refs": {
      }
    },
    "DeleteMLInputChannelDataRequest": {
      "base": null,
      "refs": {
      }
    },
    "DeleteTrainedModelOutputRequest": {
      "base": null,
      "refs": {
      }
    },
    "DeleteTrainingDatasetRequest": {
      "base": null,
      "refs": {
      }
    },
    "Destination": {
      "base": "<p>The Amazon S3 location where the exported model artifacts are stored.</p>",
      "refs": {
        "MLOutputConfiguration$destination": "<p>The Amazon S3 location where exported model artifacts are stored.</p>"
      }
    },
    "Environment": {
      "base": null,
      "refs": {
        "CreateTrainedModelRequest$environment": "<p>The environment variables to set in the Docker container.</p>",
        "GetTrainedModelResponse$environment": "<p>The EC2 environment that was used to create the trained model.</p>"
      }
    },
    "EnvironmentKeyString": {
      "base": null,
      "refs": {
        "Environment$key": null
      }
    },
    "EnvironmentValueString": {
      "base": null,
      "refs": {
        "Environment$value": null
      }
    },
    "GetAudienceGenerationJobRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetAudienceGenerationJobResponse": {
      "base": null,
      "refs": {
      }
    },
    "GetAudienceModelRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetAudienceModelResponse": {
      "base": null,
      "refs": {
      }
    },
    "GetCollaborationConfiguredModelAlgorithmAssociationRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetCollaborationConfiguredModelAlgorithmAssociationResponse": {
      "base": null,
      "refs": {
      }
    },
    "GetCollaborationMLInputChannelRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetCollaborationMLInputChannelResponse": {
      "base": null,
      "refs": {
      }
    },
    "GetCollaborationMLInputChannelResponseConfiguredModelAlgorithmAssociationsList": {
      "base": null,
      "refs": {
        "GetCollaborationMLInputChannelResponse$configuredModelAlgorithmAssociations": "<p>The configured model algorithm associations that were used to create the ML input channel.</p>"
      }
    },
    "GetCollaborationMLInputChannelResponseNumberOfRecordsLong": {
      "base": null,
      "refs": {
        "GetCollaborationMLInputChannelResponse$numberOfRecords": "<p>The number of records in the ML input channel.</p>"
      }
    },
    "GetCollaborationMLInputChannelResponseRetentionInDaysInteger": {
      "base": null,
      "refs": {
        "GetCollaborationMLInputChannelResponse$retentionInDays": "<p>The number of days to retain the data for the ML input channel.</p>"
      }
    },
    "GetCollaborationTrainedModelRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetCollaborationTrainedModelResponse": {
      "base": null,
      "refs": {
      }
    },
    "GetConfiguredAudienceModelPolicyRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetConfiguredAudienceModelPolicyResponse": {
      "base": null,
      "refs": {
      }
    },
    "GetConfiguredAudienceModelRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetConfiguredAudienceModelResponse": {
      "base": null,
      "refs": {
      }
    },
    "GetConfiguredModelAlgorithmAssociationRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetConfiguredModelAlgorithmAssociationResponse": {
      "base": null,
      "refs": {
      }
    },
    "GetConfiguredModelAlgorithmRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetConfiguredModelAlgorithmResponse": {
      "base": null,
      "refs": {
      }
    },
    "GetMLConfigurationRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetMLConfigurationResponse": {
      "base": null,
      "refs": {
      }
    },
    "GetMLInputChannelRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetMLInputChannelResponse": {
      "base": null,
      "refs": {
      }
    },
    "GetMLInputChannelResponseConfiguredModelAlgorithmAssociationsList": {
      "base": null,
      "refs": {
        "GetMLInputChannelResponse$configuredModelAlgorithmAssociations": "<p>The configured model algorithm associations that were used to create the ML input channel.</p>"
      }
    },
    "GetMLInputChannelResponseNumberOfFilesDouble": {
      "base": null,
      "refs": {
        "GetMLInputChannelResponse$numberOfFiles": "<p>The number of files in the ML input channel.</p>"
      }
    },
    "GetMLInputChannelResponseNumberOfRecordsLong": {
      "base": null,
      "refs": {
        "GetMLInputChannelResponse$numberOfRecords": "<p>The number of records in the ML input channel.</p>"
      }
    },
    "GetMLInputChannelResponseRetentionInDaysInteger": {
      "base": null,
      "refs": {
        "GetMLInputChannelResponse$retentionInDays": "<p>The number of days to keep the data in the ML input channel.</p>"
      }
    },
    "GetMLInputChannelResponseSizeInGbDouble": {
      "base": null,
      "refs": {
        "GetMLInputChannelResponse$sizeInGb": "<p>The size, in GB, of the ML input channel.</p>"
      }
    },
    "GetTrainedModelInferenceJobRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetTrainedModelInferenceJobResponse": {
      "base": null,
      "refs": {
      }
    },
    "GetTrainedModelRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetTrainedModelResponse": {
      "base": null,
      "refs": {
      }
    },
    "GetTrainingDatasetRequest": {
      "base": null,
      "refs": {
      }
    },
    "GetTrainingDatasetResponse": {
      "base": null,
      "refs": {
      }
    },
    "GlueDataSource": {
      "base": "<p>Defines the Glue data source that contains the training data.</p>",
      "refs": {
        "DataSource$glueDataSource": "<p>A GlueDataSource object that defines the catalog ID, database name, and table name for the training data.</p>"
      }
    },
    "GlueDatabaseName": {
      "base": null,
      "refs": {
        "GlueDataSource$databaseName": "<p>The Glue database that contains the training data.</p>"
      }
    },
    "GlueTableName": {
      "base": null,
      "refs": {
        "GlueDataSource$tableName": "<p>The Glue table that contains the training data.</p>"
      }
    },
    "Hash": {
      "base": null,
      "refs": {
        "GetConfiguredAudienceModelPolicyResponse$policyHash": "<p>A cryptographic hash of the contents of the policy used to prevent unexpected concurrent modification of the policy.</p>",
        "PutConfiguredAudienceModelPolicyRequest$previousPolicyHash": "<p>A cryptographic hash of the contents of the policy used to prevent unexpected concurrent modification of the policy.</p>",
        "PutConfiguredAudienceModelPolicyResponse$policyHash": "<p>A cryptographic hash of the contents of the policy used to prevent unexpected concurrent modification of the policy.</p>"
      }
    },
    "HyperParameters": {
      "base": null,
      "refs": {
        "CreateTrainedModelRequest$hyperparameters": "<p>Algorithm-specific parameters that influence the quality of the model. You set hyperparameters before you start the learning process.</p>",
        "GetTrainedModelResponse$hyperparameters": "<p>The hyperparameters that were used to create the trained model.</p>"
      }
    },
    "HyperParametersKeyString": {
      "base": null,
      "refs": {
        "HyperParameters$key": null
      }
    },
    "HyperParametersValueString": {
      "base": null,
      "refs": {
        "HyperParameters$value": null
      }
    },
    "IamRoleArn": {
      "base": null,
      "refs": {
        "AudienceGenerationJobDataSource$roleArn": "<p>The ARN of the IAM role that can read the Amazon S3 bucket where the seed audience is stored.</p>",
        "ConfiguredAudienceModelOutputConfig$roleArn": "<p>The ARN of the IAM role that can write the Amazon S3 bucket.</p>",
        "CreateConfiguredModelAlgorithmRequest$roleArn": "<p>The Amazon Resource Name (ARN) of the role that is used to access the repository.</p>",
        "CreateTrainingDatasetRequest$roleArn": "<p>The ARN of the IAM role that Clean Rooms ML can assume to read the data referred to in the <code>dataSource</code> field of each dataset.</p> <p>Passing a role across AWS accounts is not allowed. If you pass a role that isn't in your account, you get an <code>AccessDeniedException</code> error.</p>",
        "GetConfiguredModelAlgorithmResponse$roleArn": "<p>The Amazon Resource Name (ARN) of the service role that was used to create the configured model algorithm.</p>",
        "GetTrainingDatasetResponse$roleArn": "<p>The IAM role used to read the training data.</p>",
        "InputChannel$roleArn": "<p>The Amazon Resource Name (ARN) of the role used to run the query specified in the <code>dataSource</code> field of the input channel.</p> <p>Passing a role across AWS accounts is not allowed. If you pass a role that isn't in your account, you get an <code>AccessDeniedException</code> error.</p>",
        "MLOutputConfiguration$roleArn": "<p>The Amazon Resource Name (ARN) of the service access role that is used to store the model artifacts.</p>"
      }
    },
    "IncrementalTrainingDataChannel": {
      "base": "<p>Defines an incremental training data channel that references a previously trained model. Incremental training allows you to update an existing trained model with new data, building upon the knowledge from a base model rather than training from scratch. This can significantly reduce training time and computational costs while improving model performance with additional data.</p>",
      "refs": {
        "IncrementalTrainingDataChannels$member": null
      }
    },
    "IncrementalTrainingDataChannelOutput": {
      "base": "<p>Contains information about an incremental training data channel that was used to create a trained model. This structure provides details about the base model and channel configuration used during incremental training.</p>",
      "refs": {
        "IncrementalTrainingDataChannelsOutput$member": null
      }
    },
    "IncrementalTrainingDataChannels": {
      "base": null,
      "refs": {
        "CreateTrainedModelRequest$incrementalTrainingDataChannels": "<p>Specifies the incremental training data channels for the trained model. </p> <p>Incremental training allows you to create a new trained model with updates without retraining from scratch. You can specify up to one incremental training data channel that references a previously trained model and its version.</p> <p>Limit: Maximum of 20 channels total (including both <code>incrementalTrainingDataChannels</code> and <code>dataChannels</code>).</p>"
      }
    },
    "IncrementalTrainingDataChannelsOutput": {
      "base": null,
      "refs": {
        "CollaborationTrainedModelSummary$incrementalTrainingDataChannels": "<p>Information about the incremental training data channels used to create this version of the trained model.</p>",
        "GetCollaborationTrainedModelResponse$incrementalTrainingDataChannels": "<p>Information about the incremental training data channels used to create this version of the trained model. This includes details about the base model that was used for incremental training and the channel configuration.</p>",
        "GetTrainedModelResponse$incrementalTrainingDataChannels": "<p>Information about the incremental training data channels used to create this version of the trained model. This includes details about the base model that was used for incremental training and the channel configuration.</p>",
        "TrainedModelSummary$incrementalTrainingDataChannels": "<p>Information about the incremental training data channels used to create this version of the trained model.</p>"
      }
    },
    "InferenceContainerConfig": {
      "base": "<p>Provides configuration information for the inference container.</p>",
      "refs": {
        "CreateConfiguredModelAlgorithmRequest$inferenceContainerConfig": "<p>Configuration information for the inference container that is used when you run an inference job on a configured model algorithm.</p>",
        "GetConfiguredModelAlgorithmResponse$inferenceContainerConfig": "<p>Configuration information for the inference container.</p>"
      }
    },
    "InferenceContainerExecutionParameters": {
      "base": "<p>Provides execution parameters for the inference container.</p>",
      "refs": {
        "GetTrainedModelInferenceJobResponse$containerExecutionParameters": "<p>The execution parameters for the model inference job container.</p>",
        "StartTrainedModelInferenceJobRequest$containerExecutionParameters": "<p>The execution parameters for the container.</p>"
      }
    },
    "InferenceContainerExecutionParametersMaxPayloadInMBInteger": {
      "base": null,
      "refs": {
        "InferenceContainerExecutionParameters$maxPayloadInMB": "<p>The maximum size of the inference container payload, specified in MB. </p>"
      }
    },
    "InferenceEnvironmentMap": {
      "base": null,
      "refs": {
        "GetTrainedModelInferenceJobResponse$environment": "<p>The environment variables to set in the Docker container.</p>",
        "StartTrainedModelInferenceJobRequest$environment": "<p>The environment variables to set in the Docker container.</p>"
      }
    },
    "InferenceEnvironmentMapKeyString": {
      "base": null,
      "refs": {
        "InferenceEnvironmentMap$key": null
      }
    },
    "InferenceEnvironmentMapValueString": {
      "base": null,
      "refs": {
        "InferenceEnvironmentMap$value": null
      }
    },
    "InferenceInstanceType": {
      "base": null,
      "refs": {
        "InferenceResourceConfig$instanceType": "<p>The type of instance that is used to perform model inference.</p>"
      }
    },
    "InferenceOutputConfiguration": {
      "base": "<p>Configuration information about how the inference output is stored.</p>",
      "refs": {
        "CollaborationTrainedModelInferenceJobSummary$outputConfiguration": "<p>Returns output configuration information for the trained model inference job.</p>",
        "GetTrainedModelInferenceJobResponse$outputConfiguration": "<p>The output configuration information for the trained model inference job.</p>",
        "StartTrainedModelInferenceJobRequest$outputConfiguration": "<p>Defines the output configuration information for the trained model inference job.</p>",
        "TrainedModelInferenceJobSummary$outputConfiguration": "<p>The output configuration information of the trained model job.</p>"
      }
    },
    "InferenceOutputConfigurationAcceptString": {
      "base": null,
      "refs": {
        "InferenceOutputConfiguration$accept": "<p>The MIME type used to specify the output data.</p>"
      }
    },
    "InferenceReceiverMember": {
      "base": "<p>Defines who will receive inference results.</p>",
      "refs": {
        "InferenceReceiverMembers$member": null
      }
    },
    "InferenceReceiverMembers": {
      "base": null,
      "refs": {
        "InferenceOutputConfiguration$members": "<p>Defines the members that can receive inference output.</p>"
      }
    },
    "InferenceResourceConfig": {
      "base": "<p>Defines the resources used to perform model inference.</p>",
      "refs": {
        "GetTrainedModelInferenceJobResponse$resourceConfig": "<p>The resource configuration information for the trained model inference job.</p>",
        "StartTrainedModelInferenceJobRequest$resourceConfig": "<p>Defines the resource configuration for the trained model inference job.</p>"
      }
    },
    "InferenceResourceConfigInstanceCountInteger": {
      "base": null,
      "refs": {
        "InferenceResourceConfig$instanceCount": "<p>The number of instances to use.</p>"
      }
    },
    "InputChannel": {
      "base": "<p>Provides information about the data source that is used to create an ML input channel.</p>",
      "refs": {
        "CreateMLInputChannelRequest$inputChannel": "<p>The input data that is used to create this ML input channel.</p>",
        "GetMLInputChannelResponse$inputChannel": "<p>The input channel that was used to create the ML input channel.</p>"
      }
    },
    "InputChannelDataSource": {
      "base": "<p>Provides the data source that is used to define an input channel.</p>",
      "refs": {
        "InputChannel$dataSource": "<p>The data source that is used to create the ML input channel.</p>"
      }
    },
    "InstanceType": {
      "base": null,
      "refs": {
        "ResourceConfig$instanceType": "<p>The instance type that is used to train the model.</p>"
      }
    },
    "InternalServiceException": {
      "base": "<p>An internal service error occurred. Retry your request. If the problem persists, contact AWS Support.</p>",
      "refs": {
      }
    },
    "KmsKeyArn": {
      "base": null,
      "refs": {
        "CreateAudienceModelRequest$kmsKeyArn": "<p>The Amazon Resource Name (ARN) of the KMS key. This key is used to encrypt and decrypt customer-owned data in the trained ML model and the associated data.</p>",
        "CreateConfiguredModelAlgorithmRequest$kmsKeyArn": "<p>The Amazon Resource Name (ARN) of the KMS key. This key is used to encrypt and decrypt customer-owned data in the configured ML model algorithm and associated data.</p>",
        "CreateMLInputChannelRequest$kmsKeyArn": "<p>The Amazon Resource Name (ARN) of the KMS key that is used to access the input channel.</p>",
        "CreateTrainedModelRequest$kmsKeyArn": "<p>The Amazon Resource Name (ARN) of the KMS key. This key is used to encrypt and decrypt customer-owned data in the trained ML model and the associated data.</p>",
        "GetAudienceModelResponse$kmsKeyArn": "<p>The KMS key ARN used for the audience model.</p>",
        "GetConfiguredModelAlgorithmResponse$kmsKeyArn": "<p>The Amazon Resource Name (ARN) of the KMS key. This key is used to encrypt and decrypt customer-owned data in the configured ML model and associated data.</p>",
        "GetMLInputChannelResponse$kmsKeyArn": "<p>The Amazon Resource Name (ARN) of the KMS key that was used to create the ML input channel.</p>",
        "GetTrainedModelInferenceJobResponse$kmsKeyArn": "<p>The Amazon Resource Name (ARN) of the KMS key. This key is used to encrypt and decrypt customer-owned data in the ML inference job and associated data.</p>",
        "GetTrainedModelResponse$kmsKeyArn": "<p>The Amazon Resource Name (ARN) of the KMS key. This key is used to encrypt and decrypt customer-owned data in the trained ML model and associated data.</p>",
        "StartTrainedModelInferenceJobRequest$kmsKeyArn": "<p>The Amazon Resource Name (ARN) of the KMS key. This key is used to encrypt and decrypt customer-owned data in the ML inference job and associated data.</p>"
      }
    },
    "ListAudienceExportJobsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListAudienceExportJobsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListAudienceGenerationJobsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListAudienceGenerationJobsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListAudienceModelsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListAudienceModelsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListCollaborationConfiguredModelAlgorithmAssociationsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListCollaborationConfiguredModelAlgorithmAssociationsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListCollaborationMLInputChannelsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListCollaborationMLInputChannelsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListCollaborationTrainedModelExportJobsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListCollaborationTrainedModelExportJobsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListCollaborationTrainedModelInferenceJobsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListCollaborationTrainedModelInferenceJobsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListCollaborationTrainedModelsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListCollaborationTrainedModelsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListConfiguredAudienceModelsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListConfiguredAudienceModelsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListConfiguredModelAlgorithmAssociationsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListConfiguredModelAlgorithmAssociationsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListConfiguredModelAlgorithmsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListConfiguredModelAlgorithmsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListMLInputChannelsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListMLInputChannelsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListTagsForResourceRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListTagsForResourceResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListTrainedModelInferenceJobsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListTrainedModelInferenceJobsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListTrainedModelVersionsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListTrainedModelVersionsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListTrainedModelsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListTrainedModelsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListTrainingDatasetsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListTrainingDatasetsResponse": {
      "base": null,
      "refs": {
      }
    },
    "LogsConfigurationPolicy": {
      "base": "<p>Provides the information necessary for a user to access the logs.</p>",
      "refs": {
        "LogsConfigurationPolicyList$member": null
      }
    },
    "LogsConfigurationPolicyFilterPatternString": {
      "base": null,
      "refs": {
        "LogsConfigurationPolicy$filterPattern": "<p>A regular expression pattern that is used to parse the logs and return information that matches the pattern.</p>"
      }
    },
    "LogsConfigurationPolicyList": {
      "base": null,
      "refs": {
        "TrainedModelInferenceJobsConfigurationPolicy$containerLogs": "<p>The logs container for the trained model inference job.</p>",
        "TrainedModelsConfigurationPolicy$containerLogs": "<p>The container for the logs of the trained model.</p>"
      }
    },
    "LogsStatus": {
      "base": null,
      "refs": {
        "CollaborationTrainedModelInferenceJobSummary$logsStatus": "<p>The trained model inference job logs status.</p>",
        "GetCollaborationTrainedModelResponse$logsStatus": "<p>Status information for the logs.</p>",
        "GetTrainedModelInferenceJobResponse$logsStatus": "<p>The logs status for the trained model inference job.</p>",
        "GetTrainedModelResponse$logsStatus": "<p>The logs status for the trained model.</p>",
        "TrainedModelInferenceJobSummary$logsStatus": "<p>The log status of the trained model inference job.</p>"
      }
    },
    "MLInputChannelArn": {
      "base": null,
      "refs": {
        "CollaborationMLInputChannelSummary$mlInputChannelArn": "<p>The Amazon Resource Name (ARN) of the ML input channel.</p>",
        "CreateMLInputChannelResponse$mlInputChannelArn": "<p>The Amazon Resource Name (ARN) of the ML input channel.</p>",
        "DeleteMLInputChannelDataRequest$mlInputChannelArn": "<p>The Amazon Resource Name (ARN) of the ML input channel that you want to delete.</p>",
        "GetCollaborationMLInputChannelRequest$mlInputChannelArn": "<p>The Amazon Resource Name (ARN) of the ML input channel that you want to get.</p>",
        "GetCollaborationMLInputChannelResponse$mlInputChannelArn": "<p>The Amazon Resource Name (ARN) of the ML input channel.</p>",
        "GetMLInputChannelRequest$mlInputChannelArn": "<p>The Amazon Resource Name (ARN) of the ML input channel that you want to get.</p>",
        "GetMLInputChannelResponse$mlInputChannelArn": "<p>The Amazon Resource Name (ARN) of the ML input channel.</p>",
        "MLInputChannelSummary$mlInputChannelArn": "<p>The Amazon Resource Name (ARN) of the ML input channel.</p>",
        "ModelInferenceDataSource$mlInputChannelArn": "<p>The Amazon Resource Name (ARN) of the ML input channel for this model inference data source.</p>",
        "ModelTrainingDataChannel$mlInputChannelArn": "<p>The Amazon Resource Name (ARN) of the ML input channel for this model training data channel.</p>"
      }
    },
    "MLInputChannelStatus": {
      "base": null,
      "refs": {
        "CollaborationMLInputChannelSummary$status": "<p>The status of the ML input channel.</p>",
        "GetCollaborationMLInputChannelResponse$status": "<p>The status of the ML input channel.</p>",
        "GetMLInputChannelResponse$status": "<p>The status of the ML input channel.</p>",
        "MLInputChannelSummary$status": "<p>The status of the ML input channel.</p>"
      }
    },
    "MLInputChannelSummary": {
      "base": "<p>Provides summary information about the ML input channel.</p>",
      "refs": {
        "MLInputChannelsList$member": null
      }
    },
    "MLInputChannelSummaryConfiguredModelAlgorithmAssociationsList": {
      "base": null,
      "refs": {
        "MLInputChannelSummary$configuredModelAlgorithmAssociations": "<p>The associated configured model algorithms used to create the ML input channel.</p>"
      }
    },
    "MLInputChannelsList": {
      "base": null,
      "refs": {
        "ListMLInputChannelsResponse$mlInputChannelsList": "<p>The list of ML input channels that you wanted.</p>"
      }
    },
    "MLOutputConfiguration": {
      "base": "<p>Configuration information about how the exported model artifacts are stored.</p>",
      "refs": {
        "GetMLConfigurationResponse$defaultOutputLocation": "<p>The Amazon S3 location where ML model output is stored.</p>",
        "PutMLConfigurationRequest$defaultOutputLocation": "<p>The default Amazon S3 location where ML output is stored for the specified member.</p>"
      }
    },
    "MaxResults": {
      "base": null,
      "refs": {
        "ListAudienceExportJobsRequest$maxResults": "<p>The maximum size of the results that is returned per call.</p>",
        "ListAudienceGenerationJobsRequest$maxResults": "<p>The maximum size of the results that is returned per call.</p>",
        "ListAudienceModelsRequest$maxResults": "<p>The maximum size of the results that is returned per call.</p>",
        "ListCollaborationConfiguredModelAlgorithmAssociationsRequest$maxResults": "<p>The maximum size of the results that is returned per call.</p>",
        "ListCollaborationMLInputChannelsRequest$maxResults": "<p>The maximum number of results to return.</p>",
        "ListCollaborationTrainedModelExportJobsRequest$maxResults": "<p>The maximum size of the results that is returned per call.</p>",
        "ListCollaborationTrainedModelInferenceJobsRequest$maxResults": "<p>The maximum size of the results that is returned per call.</p>",
        "ListCollaborationTrainedModelsRequest$maxResults": "<p>The maximum size of the results that is returned per call.</p>",
        "ListConfiguredAudienceModelsRequest$maxResults": "<p>The maximum size of the results that is returned per call.</p>",
        "ListConfiguredModelAlgorithmAssociationsRequest$maxResults": "<p>The maximum size of the results that is returned per call.</p>",
        "ListConfiguredModelAlgorithmsRequest$maxResults": "<p>The maximum size of the results that is returned per call.</p>",
        "ListMLInputChannelsRequest$maxResults": "<p>The maximum number of ML input channels to return.</p>",
        "ListTrainedModelInferenceJobsRequest$maxResults": "<p>The maximum size of the results that is returned per call.</p>",
        "ListTrainedModelVersionsRequest$maxResults": "<p>The maximum number of trained model versions to return in a single page. The default value is 10, and the maximum value is 100.</p>",
        "ListTrainedModelsRequest$maxResults": "<p>The maximum size of the results that is returned per call.</p>",
        "ListTrainingDatasetsRequest$maxResults": "<p>The maximum size of the results that is returned per call.</p>"
      }
    },
    "MetricDefinition": {
      "base": "<p>Information about the model metric that is reported for a trained model.</p>",
      "refs": {
        "MetricDefinitionList$member": null
      }
    },
    "MetricDefinitionList": {
      "base": null,
      "refs": {
        "ContainerConfig$metricDefinitions": "<p>A list of metric definition objects. Each object specifies the metric name and regular expressions used to parse algorithm logs. Amazon Web Services Clean Rooms ML publishes each metric to all members' Amazon CloudWatch using IAM role configured in <a>PutMLConfiguration</a>.</p>"
      }
    },
    "MetricName": {
      "base": null,
      "refs": {
        "MetricDefinition$name": "<p>The name of the model metric.</p>"
      }
    },
    "MetricRegex": {
      "base": null,
      "refs": {
        "MetricDefinition$regex": "<p>The regular expression statement that defines how the model metric is reported.</p>"
      }
    },
    "MetricsConfigurationPolicy": {
      "base": "<p>Provides the configuration policy for metrics generation.</p>",
      "refs": {
        "TrainedModelsConfigurationPolicy$containerMetrics": "<p>The container for the metrics of the trained model.</p>"
      }
    },
    "MetricsList": {
      "base": null,
      "refs": {
        "CreateConfiguredAudienceModelRequest$sharedAudienceMetrics": "<p>Whether audience metrics are shared.</p>",
        "GetConfiguredAudienceModelResponse$sharedAudienceMetrics": "<p>Whether audience metrics are shared.</p>",
        "UpdateConfiguredAudienceModelRequest$sharedAudienceMetrics": "<p>The new value for whether to share audience metrics.</p>"
      }
    },
    "MetricsStatus": {
      "base": null,
      "refs": {
        "CollaborationTrainedModelInferenceJobSummary$metricsStatus": "<p>the trained model inference job metrics status.</p>",
        "GetCollaborationTrainedModelResponse$metricsStatus": "<p>The status of the model metrics.</p>",
        "GetTrainedModelInferenceJobResponse$metricsStatus": "<p>The metrics status for the trained model inference job.</p>",
        "GetTrainedModelResponse$metricsStatus": "<p>The status of the model metrics.</p>",
        "TrainedModelInferenceJobSummary$metricsStatus": "<p>The metric status of the trained model inference job.</p>"
      }
    },
    "MinMatchingSeedSize": {
      "base": null,
      "refs": {
        "CreateConfiguredAudienceModelRequest$minMatchingSeedSize": "<p>The minimum number of users from the seed audience that must match with users in the training data of the audience model. The default value is 500.</p>",
        "GetConfiguredAudienceModelResponse$minMatchingSeedSize": "<p>The minimum number of users from the seed audience that must match with users in the training data of the audience model.</p>",
        "UpdateConfiguredAudienceModelRequest$minMatchingSeedSize": "<p>The minimum number of users from the seed audience that must match with users in the training data of the audience model.</p>"
      }
    },
    "ModelInferenceDataSource": {
      "base": "<p>Defines information about the data source used for model inference.</p>",
      "refs": {
        "GetTrainedModelInferenceJobResponse$dataSource": "<p>The data source that was used for the trained model inference job.</p>",
        "StartTrainedModelInferenceJobRequest$dataSource": "<p>Defines the data source that is used for the trained model inference job.</p>"
      }
    },
    "ModelTrainingDataChannel": {
      "base": "<p>Information about the model training data channel. A training data channel is a named data source that the training algorithms can consume. </p>",
      "refs": {
        "ModelTrainingDataChannels$member": null
      }
    },
    "ModelTrainingDataChannelName": {
      "base": null,
      "refs": {
        "IncrementalTrainingDataChannel$channelName": "<p>The name of the incremental training data channel. This name is used to identify the channel during the training process and must be unique within the training job.</p>",
        "IncrementalTrainingDataChannelOutput$channelName": "<p>The name of the incremental training data channel that was used.</p>",
        "ModelTrainingDataChannel$channelName": "<p>The name of the training data channel.</p>"
      }
    },
    "ModelTrainingDataChannels": {
      "base": null,
      "refs": {
        "CreateTrainedModelRequest$dataChannels": "<p>Defines the data channels that are used as input for the trained model request.</p> <p>Limit: Maximum of 20 channels total (including both <code>dataChannels</code> and <code>incrementalTrainingDataChannels</code>).</p>",
        "GetTrainedModelResponse$dataChannels": "<p>The data channels that were used for the trained model.</p>"
      }
    },
    "NameString": {
      "base": null,
      "refs": {
        "AudienceExportJobSummary$name": "<p>The name of the audience export job.</p>",
        "AudienceGenerationJobSummary$name": "<p>The name of the audience generation job.</p>",
        "AudienceModelSummary$name": "<p>The name of the audience model.</p>",
        "CollaborationConfiguredModelAlgorithmAssociationSummary$name": "<p>The name of the configured model algorithm association.</p>",
        "CollaborationMLInputChannelSummary$name": "<p>The name of the ML input channel.</p>",
        "CollaborationTrainedModelExportJobSummary$name": "<p>The name of the trained model export job.</p>",
        "CollaborationTrainedModelInferenceJobSummary$name": "<p>The name of the trained model inference job.</p>",
        "CollaborationTrainedModelSummary$name": "<p>The name of the trained model.</p>",
        "ConfiguredAudienceModelSummary$name": "<p>The name of the configured audience model.</p>",
        "ConfiguredModelAlgorithmAssociationSummary$name": "<p>The name of the configured model algorithm association.</p>",
        "ConfiguredModelAlgorithmSummary$name": "<p>The name of the configured model algorithm.</p>",
        "CreateAudienceModelRequest$name": "<p>The name of the audience model resource.</p>",
        "CreateConfiguredAudienceModelRequest$name": "<p>The name of the configured audience model.</p>",
        "CreateConfiguredModelAlgorithmAssociationRequest$name": "<p>The name of the configured model algorithm association.</p>",
        "CreateConfiguredModelAlgorithmRequest$name": "<p>The name of the configured model algorithm.</p>",
        "CreateMLInputChannelRequest$name": "<p>The name of the ML input channel.</p>",
        "CreateTrainedModelRequest$name": "<p>The name of the trained model.</p>",
        "CreateTrainingDatasetRequest$name": "<p>The name of the training dataset. This name must be unique in your account and region.</p>",
        "GetAudienceGenerationJobResponse$name": "<p>The name of the audience generation job.</p>",
        "GetAudienceModelResponse$name": "<p>The name of the audience model.</p>",
        "GetCollaborationConfiguredModelAlgorithmAssociationResponse$name": "<p>The name of the configured model algorithm association.</p>",
        "GetCollaborationMLInputChannelResponse$name": "<p>The name of the ML input channel.</p>",
        "GetCollaborationTrainedModelResponse$name": "<p>The name of the trained model.</p>",
        "GetConfiguredAudienceModelResponse$name": "<p>The name of the configured audience model.</p>",
        "GetConfiguredModelAlgorithmAssociationResponse$name": "<p>The name of the configured model algorithm association.</p>",
        "GetConfiguredModelAlgorithmResponse$name": "<p>The name of the configured model algorithm.</p>",
        "GetMLInputChannelResponse$name": "<p>The name of the ML input channel.</p>",
        "GetTrainedModelInferenceJobResponse$name": "<p>The name of the trained model inference job.</p>",
        "GetTrainedModelResponse$name": "<p>The name of the trained model.</p>",
        "GetTrainingDatasetResponse$name": "<p>The name of the training dataset.</p>",
        "IncrementalTrainingDataChannelOutput$modelName": "<p>The name of the base trained model that was used for incremental training.</p>",
        "MLInputChannelSummary$name": "<p>The name of the ML input channel.</p>",
        "StartAudienceExportJobRequest$name": "<p>The name of the audience export job.</p>",
        "StartAudienceGenerationJobRequest$name": "<p>The name of the audience generation job.</p>",
        "StartTrainedModelExportJobRequest$name": "<p>The name of the trained model export job.</p>",
        "StartTrainedModelInferenceJobRequest$name": "<p>The name of the trained model inference job.</p>",
        "TrainedModelInferenceJobSummary$name": "<p>The name of the trained model inference job.</p>",
        "TrainedModelSummary$name": "<p>The name of the trained model.</p>",
        "TrainingDatasetSummary$name": "<p>The name of the training dataset.</p>"
      }
    },
    "NextToken": {
      "base": null,
      "refs": {
        "ListAudienceExportJobsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListAudienceExportJobsResponse$nextToken": "<p>The token value used to access the next page of results.</p>",
        "ListAudienceGenerationJobsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListAudienceGenerationJobsResponse$nextToken": "<p>The token value used to access the next page of results.</p>",
        "ListAudienceModelsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListAudienceModelsResponse$nextToken": "<p>The token value used to access the next page of results.</p>",
        "ListCollaborationConfiguredModelAlgorithmAssociationsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListCollaborationConfiguredModelAlgorithmAssociationsResponse$nextToken": "<p>The token value used to access the next page of results.</p>",
        "ListCollaborationMLInputChannelsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListCollaborationMLInputChannelsResponse$nextToken": "<p>The token value used to access the next page of results.</p>",
        "ListCollaborationTrainedModelExportJobsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListCollaborationTrainedModelExportJobsResponse$nextToken": "<p>The token value used to access the next page of results.</p>",
        "ListCollaborationTrainedModelInferenceJobsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListCollaborationTrainedModelInferenceJobsResponse$nextToken": "<p>The token value used to access the next page of results.</p>",
        "ListCollaborationTrainedModelsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListCollaborationTrainedModelsResponse$nextToken": "<p>The token value used to access the next page of results.</p>",
        "ListConfiguredAudienceModelsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListConfiguredAudienceModelsResponse$nextToken": "<p>The token value used to access the next page of results.</p>",
        "ListConfiguredModelAlgorithmAssociationsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListConfiguredModelAlgorithmAssociationsResponse$nextToken": "<p>The token value used to access the next page of results.</p>",
        "ListConfiguredModelAlgorithmsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListConfiguredModelAlgorithmsResponse$nextToken": "<p>The token value used to access the next page of results.</p>",
        "ListMLInputChannelsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListMLInputChannelsResponse$nextToken": "<p>The token value used to access the next page of results.</p>",
        "ListTrainedModelInferenceJobsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListTrainedModelInferenceJobsResponse$nextToken": "<p>The token value used to access the next page of results.</p>",
        "ListTrainedModelVersionsRequest$nextToken": "<p>The pagination token from a previous <code>ListTrainedModelVersions</code> request. Use this token to retrieve the next page of results.</p>",
        "ListTrainedModelVersionsResponse$nextToken": "<p>The pagination token to use in a subsequent <code>ListTrainedModelVersions</code> request to retrieve the next page of results. This value is null when there are no more results to return.</p>",
        "ListTrainedModelsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListTrainedModelsResponse$nextToken": "<p>The token value used to access the next page of results.</p>",
        "ListTrainingDatasetsRequest$nextToken": "<p>The token value retrieved from a previous call to access the next page of results.</p>",
        "ListTrainingDatasetsResponse$nextToken": "<p>The token value used to access the next page of results.</p>"
      }
    },
    "NoiseLevelType": {
      "base": null,
      "refs": {
        "MetricsConfigurationPolicy$noiseLevel": "<p>The noise level for the generated metrics.</p>"
      }
    },
    "ParameterKey": {
      "base": null,
      "refs": {
        "ParameterMap$key": null
      }
    },
    "ParameterMap": {
      "base": null,
      "refs": {
        "ProtectedQuerySQLParameters$parameters": "<p>The protected query SQL parameters.</p>"
      }
    },
    "ParameterValue": {
      "base": null,
      "refs": {
        "ParameterMap$value": null
      }
    },
    "PolicyExistenceCondition": {
      "base": null,
      "refs": {
        "PutConfiguredAudienceModelPolicyRequest$policyExistenceCondition": "<p>Use this to prevent unexpected concurrent modification of the policy.</p>"
      }
    },
    "PrivacyConfiguration": {
      "base": "<p>Information about the privacy configuration for a configured model algorithm association.</p>",
      "refs": {
        "CreateConfiguredModelAlgorithmAssociationRequest$privacyConfiguration": "<p>Specifies the privacy configuration information for the configured model algorithm association. This information includes the maximum data size that can be exported.</p>",
        "GetCollaborationConfiguredModelAlgorithmAssociationResponse$privacyConfiguration": null,
        "GetConfiguredModelAlgorithmAssociationResponse$privacyConfiguration": "<p>The privacy configuration information for the configured model algorithm association.</p>"
      }
    },
    "PrivacyConfigurationPolicies": {
      "base": "<p>Information about the privacy configuration policies for a configured model algorithm association.</p>",
      "refs": {
        "PrivacyConfiguration$policies": "<p>The privacy configuration policies for a configured model algorithm association.</p>"
      }
    },
    "ProtectedQueryInputParameters": {
      "base": "<p>Provides information necessary to perform the protected query.</p>",
      "refs": {
        "InputChannelDataSource$protectedQueryInputParameters": null
      }
    },
    "ProtectedQuerySQLParameters": {
      "base": "<p>The parameters for the SQL type Protected Query.</p>",
      "refs": {
        "AudienceGenerationJobDataSource$sqlParameters": "<p>The protected SQL query parameters.</p>",
        "ProtectedQueryInputParameters$sqlParameters": null
      }
    },
    "ProtectedQuerySQLParametersQueryStringString": {
      "base": null,
      "refs": {
        "ProtectedQuerySQLParameters$queryString": "<p>The query string to be submitted.</p>"
      }
    },
    "PutConfiguredAudienceModelPolicyRequest": {
      "base": null,
      "refs": {
      }
    },
    "PutConfiguredAudienceModelPolicyResponse": {
      "base": null,
      "refs": {
      }
    },
    "PutMLConfigurationRequest": {
      "base": null,
      "refs": {
      }
    },
    "RelevanceMetric": {
      "base": "<p>The relevance score of a generated audience.</p>",
      "refs": {
        "RelevanceMetrics$member": null
      }
    },
    "RelevanceMetricScoreDouble": {
      "base": null,
      "refs": {
        "RelevanceMetric$score": "<p>The relevance score of the generated audience.</p>"
      }
    },
    "RelevanceMetrics": {
      "base": null,
      "refs": {
        "AudienceQualityMetrics$relevanceMetrics": "<p>The relevance scores of the generated audience.</p>"
      }
    },
    "ResourceConfig": {
      "base": "<p>Information about the EC2 resources that are used to train the model.</p>",
      "refs": {
        "CreateTrainedModelRequest$resourceConfig": "<p>Information about the EC2 resources that are used to train this model.</p>",
        "GetCollaborationTrainedModelResponse$resourceConfig": "<p>The EC2 resource configuration that was used to train this model.</p>",
        "GetTrainedModelResponse$resourceConfig": "<p>The EC2 resource configuration that was used to create the trained model.</p>"
      }
    },
    "ResourceConfigInstanceCountInteger": {
      "base": null,
      "refs": {
        "ResourceConfig$instanceCount": "<p>The number of resources that are used to train the model.</p>"
      }
    },
    "ResourceConfigVolumeSizeInGBInteger": {
      "base": null,
      "refs": {
        "ResourceConfig$volumeSizeInGB": "<p>The maximum size of the instance that is used to train the model.</p>"
      }
    },
    "ResourceDescription": {
      "base": null,
      "refs": {
        "AudienceExportJobSummary$description": "<p>The description of the audience export job.</p>",
        "AudienceGenerationJobSummary$description": "<p>The description of the audience generation job.</p>",
        "AudienceModelSummary$description": "<p>The description of the audience model.</p>",
        "CollaborationConfiguredModelAlgorithmAssociationSummary$description": "<p>The description of the configured model algorithm association.</p>",
        "CollaborationMLInputChannelSummary$description": "<p>The description of the ML input channel.</p>",
        "CollaborationTrainedModelExportJobSummary$description": "<p>The description of the trained model.</p>",
        "CollaborationTrainedModelInferenceJobSummary$description": "<p>The description of the trained model inference job.</p>",
        "CollaborationTrainedModelSummary$description": "<p>The description of the trained model.</p>",
        "ConfiguredAudienceModelSummary$description": "<p>The description of the configured audience model.</p>",
        "ConfiguredModelAlgorithmAssociationSummary$description": "<p>The description of the configured model algorithm association.</p>",
        "ConfiguredModelAlgorithmSummary$description": "<p>The description of the configured model algorithm.</p>",
        "CreateAudienceModelRequest$description": "<p>The description of the audience model.</p>",
        "CreateConfiguredAudienceModelRequest$description": "<p>The description of the configured audience model.</p>",
        "CreateConfiguredModelAlgorithmAssociationRequest$description": "<p>The description of the configured model algorithm association.</p>",
        "CreateConfiguredModelAlgorithmRequest$description": "<p>The description of the configured model algorithm.</p>",
        "CreateMLInputChannelRequest$description": "<p>The description of the ML input channel.</p>",
        "CreateTrainedModelRequest$description": "<p>The description of the trained model.</p>",
        "CreateTrainingDatasetRequest$description": "<p>The description of the training dataset.</p>",
        "GetAudienceGenerationJobResponse$description": "<p>The description of the audience generation job.</p>",
        "GetAudienceModelResponse$description": "<p>The description of the audience model.</p>",
        "GetCollaborationConfiguredModelAlgorithmAssociationResponse$description": "<p>The description of the configured model algorithm association.</p>",
        "GetCollaborationMLInputChannelResponse$description": "<p>The description of the ML input channel.</p>",
        "GetCollaborationTrainedModelResponse$description": "<p>The description of the trained model.</p>",
        "GetConfiguredAudienceModelResponse$description": "<p>The description of the configured audience model.</p>",
        "GetConfiguredModelAlgorithmAssociationResponse$description": "<p>The description of the configured model algorithm association.</p>",
        "GetConfiguredModelAlgorithmResponse$description": "<p>The description of the configured model algorithm.</p>",
        "GetMLInputChannelResponse$description": "<p>The description of the ML input channel.</p>",
        "GetTrainedModelInferenceJobResponse$description": "<p>The description of the trained model inference job.</p>",
        "GetTrainedModelResponse$description": "<p>The description of the trained model.</p>",
        "GetTrainingDatasetResponse$description": "<p>The description of the training dataset.</p>",
        "MLInputChannelSummary$description": "<p>The description of the ML input channel.</p>",
        "StartAudienceExportJobRequest$description": "<p>The description of the audience export job.</p>",
        "StartAudienceGenerationJobRequest$description": "<p>The description of the audience generation job.</p>",
        "StartTrainedModelExportJobRequest$description": "<p>The description of the trained model export job.</p>",
        "StartTrainedModelInferenceJobRequest$description": "<p>The description of the trained model inference job.</p>",
        "TrainedModelInferenceJobSummary$description": "<p>The description of the trained model inference job.</p>",
        "TrainedModelSummary$description": "<p>The description of the trained model.</p>",
        "TrainingDatasetSummary$description": "<p>The description of the training dataset.</p>",
        "UpdateConfiguredAudienceModelRequest$description": "<p>The new description of the configured audience model.</p>"
      }
    },
    "ResourceNotFoundException": {
      "base": "<p>The resource you are requesting does not exist.</p>",
      "refs": {
      }
    },
    "ResourcePolicy": {
      "base": null,
      "refs": {
        "GetConfiguredAudienceModelPolicyResponse$configuredAudienceModelPolicy": "<p>The configured audience model policy. This is a JSON IAM resource policy.</p>",
        "PutConfiguredAudienceModelPolicyRequest$configuredAudienceModelPolicy": "<p>The IAM resource policy.</p>",
        "PutConfiguredAudienceModelPolicyResponse$configuredAudienceModelPolicy": "<p>The IAM resource policy.</p>"
      }
    },
    "S3ConfigMap": {
      "base": "<p>Provides information about an Amazon S3 bucket and path.</p>",
      "refs": {
        "AudienceDestination$s3Destination": "<p>The Amazon S3 bucket and path for the configured audience.</p>",
        "AudienceGenerationJobDataSource$dataSource": "<p>Defines the Amazon S3 bucket where the seed audience for the generating audience is stored. A valid data source is a JSON line file in the following format:</p> <p> <code>{\"user_id\": \"111111\"}</code> </p> <p> <code>{\"user_id\": \"222222\"}</code> </p> <p> <code>...</code> </p>",
        "Destination$s3Destination": null
      }
    },
    "S3DataDistributionType": {
      "base": null,
      "refs": {
        "ModelTrainingDataChannel$s3DataDistributionType": "<p>Specifies how the training data stored in Amazon S3 should be distributed to training instances. This parameter controls the data distribution strategy for the training job:</p> <ul> <li> <p> <code>FullyReplicated</code> - The entire dataset is replicated on each training instance. This is suitable for smaller datasets and algorithms that require access to the complete dataset.</p> </li> <li> <p> <code>ShardedByS3Key</code> - The dataset is distributed across training instances based on Amazon S3 key names. This is suitable for larger datasets and distributed training scenarios where each instance processes a subset of the data.</p> </li> </ul>"
      }
    },
    "S3Path": {
      "base": null,
      "refs": {
        "AudienceExportJobSummary$outputLocation": "<p>The Amazon S3 bucket where the audience export is stored.</p>",
        "S3ConfigMap$s3Uri": "<p>The Amazon S3 location URI.</p>"
      }
    },
    "ServiceQuotaExceededException": {
      "base": "<p>You have exceeded your service quota.</p>",
      "refs": {
      }
    },
    "ServiceQuotaExceededExceptionQuotaValueDouble": {
      "base": null,
      "refs": {
        "ServiceQuotaExceededException$quotaValue": "<p>The current limit on the service quota that was exceeded</p>"
      }
    },
    "SharedAudienceMetrics": {
      "base": null,
      "refs": {
        "MetricsList$member": null
      }
    },
    "StartAudienceExportJobRequest": {
      "base": null,
      "refs": {
      }
    },
    "StartAudienceGenerationJobRequest": {
      "base": null,
      "refs": {
      }
    },
    "StartAudienceGenerationJobResponse": {
      "base": null,
      "refs": {
      }
    },
    "StartTrainedModelExportJobRequest": {
      "base": null,
      "refs": {
      }
    },
    "StartTrainedModelInferenceJobRequest": {
      "base": null,
      "refs": {
      }
    },
    "StartTrainedModelInferenceJobResponse": {
      "base": null,
      "refs": {
      }
    },
    "StatusDetails": {
      "base": "<p>Details about the status of a resource.</p>",
      "refs": {
        "AudienceExportJobSummary$statusDetails": null,
        "CollaborationTrainedModelExportJobSummary$statusDetails": null,
        "GetAudienceGenerationJobResponse$statusDetails": "<p>Details about the status of the audience generation job.</p>",
        "GetAudienceModelResponse$statusDetails": "<p>Details about the status of the audience model.</p>",
        "GetCollaborationMLInputChannelResponse$statusDetails": null,
        "GetCollaborationTrainedModelResponse$statusDetails": null,
        "GetMLInputChannelResponse$statusDetails": null,
        "GetTrainedModelInferenceJobResponse$statusDetails": null,
        "GetTrainedModelResponse$statusDetails": null
      }
    },
    "StoppingCondition": {
      "base": "<p>The criteria used to stop model training.</p>",
      "refs": {
        "CreateTrainedModelRequest$stoppingCondition": "<p>The criteria that is used to stop model training.</p>",
        "GetCollaborationTrainedModelResponse$stoppingCondition": "<p>The stopping condition that determined when model training ended.</p>",
        "GetTrainedModelResponse$stoppingCondition": "<p>The stopping condition that was used to terminate model training.</p>"
      }
    },
    "StoppingConditionMaxRuntimeInSecondsInteger": {
      "base": null,
      "refs": {
        "StoppingCondition$maxRuntimeInSeconds": "<p>The maximum amount of time, in seconds, that model training can run before it is terminated.</p>"
      }
    },
    "String": {
      "base": null,
      "refs": {
        "AccessDeniedException$message": null,
        "AccountIdList$member": null,
        "CollaborationTrainedModelInferenceJobSummary$metricsStatusDetails": "<p>Details about the metrics status for trained model inference job.</p>",
        "CollaborationTrainedModelInferenceJobSummary$logsStatusDetails": "<p>Details about the logs status for the trained model inference job.</p>",
        "ConflictException$message": null,
        "GetAudienceGenerationJobResponse$protectedQueryIdentifier": "<p>The unique identifier of the protected query for this audience generation job.</p>",
        "GetCollaborationTrainedModelResponse$metricsStatusDetails": "<p>Details about the status information for the model metrics.</p>",
        "GetCollaborationTrainedModelResponse$logsStatusDetails": "<p>Details about the status information for the logs.</p>",
        "GetCollaborationTrainedModelResponse$trainingContainerImageDigest": "<p>Information about the training container image.</p>",
        "GetTrainedModelInferenceJobResponse$inferenceContainerImageDigest": "<p>Information about the training container image.</p>",
        "GetTrainedModelInferenceJobResponse$metricsStatusDetails": "<p>Details about the metrics status for the trained model inference job.</p>",
        "GetTrainedModelInferenceJobResponse$logsStatusDetails": "<p>Details about the logs status for the trained model inference job.</p>",
        "GetTrainedModelResponse$metricsStatusDetails": "<p>Details about the metrics status for the trained model.</p>",
        "GetTrainedModelResponse$logsStatusDetails": "<p>Details about the logs status for the trained model.</p>",
        "GetTrainedModelResponse$trainingContainerImageDigest": "<p>Information about the training image container.</p>",
        "InternalServiceException$message": null,
        "ResourceNotFoundException$message": null,
        "ServiceQuotaExceededException$message": null,
        "ServiceQuotaExceededException$quotaName": "<p>The name of the service quota limit that was exceeded</p>",
        "StatusDetails$statusCode": "<p>The status code that was returned. The status code is intended for programmatic error handling. Clean Rooms ML will not change the status code for existing error conditions.</p>",
        "StatusDetails$message": "<p>The error message that was returned. The message is intended for human consumption and can change at any time. Use the <code>statusCode</code> for programmatic error handling.</p>",
        "ThrottlingException$message": null,
        "TrainedModelInferenceJobSummary$metricsStatusDetails": "<p>Details about the metrics status for the trained model inference job.</p>",
        "TrainedModelInferenceJobSummary$logsStatusDetails": "<p>Details about the log status for the trained model inference job.</p>",
        "ValidationException$message": null
      }
    },
    "SyntheticTimestamp_date_time": {
      "base": null,
      "refs": {
        "AudienceExportJobSummary$createTime": "<p>The time at which the audience export job was created.</p>",
        "AudienceExportJobSummary$updateTime": "<p>The most recent time at which the audience export job was updated.</p>",
        "AudienceGenerationJobSummary$createTime": "<p>The time at which the audience generation job was created.</p>",
        "AudienceGenerationJobSummary$updateTime": "<p>The most recent time at which the audience generation job was updated.</p>",
        "AudienceModelSummary$createTime": "<p>The time at which the audience model was created.</p>",
        "AudienceModelSummary$updateTime": "<p>The most recent time at which the audience model was updated.</p>",
        "CollaborationConfiguredModelAlgorithmAssociationSummary$createTime": "<p>The time at which the configured model algorithm association was created.</p>",
        "CollaborationConfiguredModelAlgorithmAssociationSummary$updateTime": "<p>The most recent time at which the configured model algorithm association was updated.</p>",
        "CollaborationMLInputChannelSummary$createTime": "<p>The time at which the ML input channel was created.</p>",
        "CollaborationMLInputChannelSummary$updateTime": "<p>The most recent time at which the ML input channel was updated.</p>",
        "CollaborationTrainedModelExportJobSummary$createTime": "<p>The time at which the trained model export job was created.</p>",
        "CollaborationTrainedModelExportJobSummary$updateTime": "<p>The most recent time at which the trained model export job was updated.</p>",
        "CollaborationTrainedModelInferenceJobSummary$createTime": "<p>The time at which the trained model inference job was created.</p>",
        "CollaborationTrainedModelInferenceJobSummary$updateTime": "<p>The most recent time at which the trained model inference job was updated.</p>",
        "CollaborationTrainedModelSummary$createTime": "<p>The time at which the trained model was created.</p>",
        "CollaborationTrainedModelSummary$updateTime": "<p>The most recent time at which the trained model was updated.</p>",
        "ConfiguredAudienceModelSummary$createTime": "<p>The time at which the configured audience model was created.</p>",
        "ConfiguredAudienceModelSummary$updateTime": "<p>The most recent time at which the configured audience model was updated.</p>",
        "ConfiguredModelAlgorithmAssociationSummary$createTime": "<p>The time at which the configured model algorithm association was created.</p>",
        "ConfiguredModelAlgorithmAssociationSummary$updateTime": "<p>The most recent time at which the configured model algorithm association was updated.</p>",
        "ConfiguredModelAlgorithmSummary$createTime": "<p>The time at which the configured model algorithm was created.</p>",
        "ConfiguredModelAlgorithmSummary$updateTime": "<p>The most recent time at which the configured model algorithm was updated.</p>",
        "CreateAudienceModelRequest$trainingDataStartTime": "<p>The start date and time of the training window.</p>",
        "CreateAudienceModelRequest$trainingDataEndTime": "<p>The end date and time of the training window.</p>",
        "GetAudienceGenerationJobResponse$createTime": "<p>The time at which the audience generation job was created.</p>",
        "GetAudienceGenerationJobResponse$updateTime": "<p>The most recent time at which the audience generation job was updated.</p>",
        "GetAudienceModelResponse$createTime": "<p>The time at which the audience model was created.</p>",
        "GetAudienceModelResponse$updateTime": "<p>The most recent time at which the audience model was updated.</p>",
        "GetAudienceModelResponse$trainingDataStartTime": "<p>The start date specified for the training window.</p>",
        "GetAudienceModelResponse$trainingDataEndTime": "<p>The end date specified for the training window.</p>",
        "GetCollaborationConfiguredModelAlgorithmAssociationResponse$createTime": "<p>The time at which the configured model algorithm association was created.</p>",
        "GetCollaborationConfiguredModelAlgorithmAssociationResponse$updateTime": "<p>The most recent time at which the configured model algorithm association was updated.</p>",
        "GetCollaborationMLInputChannelResponse$createTime": "<p>The time at which the ML input channel was created.</p>",
        "GetCollaborationMLInputChannelResponse$updateTime": "<p>The most recent time at which the ML input channel was updated.</p>",
        "GetCollaborationTrainedModelResponse$createTime": "<p>The time at which the trained model was created.</p>",
        "GetCollaborationTrainedModelResponse$updateTime": "<p>The most recent time at which the trained model was updated.</p>",
        "GetConfiguredAudienceModelResponse$createTime": "<p>The time at which the configured audience model was created.</p>",
        "GetConfiguredAudienceModelResponse$updateTime": "<p>The most recent time at which the configured audience model was updated.</p>",
        "GetConfiguredModelAlgorithmAssociationResponse$createTime": "<p>The time at which the configured model algorithm association was created.</p>",
        "GetConfiguredModelAlgorithmAssociationResponse$updateTime": "<p>The most recent time at which the configured model algorithm association was updated.</p>",
        "GetConfiguredModelAlgorithmResponse$createTime": "<p>The time at which the configured model algorithm was created.</p>",
        "GetConfiguredModelAlgorithmResponse$updateTime": "<p>The most recent time at which the configured model algorithm was updated.</p>",
        "GetMLConfigurationResponse$createTime": "<p>The time at which the ML configuration was created.</p>",
        "GetMLConfigurationResponse$updateTime": "<p>The most recent time at which the ML configuration was updated.</p>",
        "GetMLInputChannelResponse$createTime": "<p>The time at which the ML input channel was created.</p>",
        "GetMLInputChannelResponse$updateTime": "<p>The most recent time at which the ML input channel was updated.</p>",
        "GetTrainedModelInferenceJobResponse$createTime": "<p>The time at which the trained model inference job was created.</p>",
        "GetTrainedModelInferenceJobResponse$updateTime": "<p>The most recent time at which the trained model inference job was updated.</p>",
        "GetTrainedModelResponse$createTime": "<p>The time at which the trained model was created.</p>",
        "GetTrainedModelResponse$updateTime": "<p>The most recent time at which the trained model was updated.</p>",
        "GetTrainingDatasetResponse$createTime": "<p>The time at which the training dataset was created.</p>",
        "GetTrainingDatasetResponse$updateTime": "<p>The most recent time at which the training dataset was updated.</p>",
        "MLInputChannelSummary$createTime": "<p>The time at which the ML input channel was created.</p>",
        "MLInputChannelSummary$updateTime": "<p>The most recent time at which the ML input channel was updated.</p>",
        "TrainedModelInferenceJobSummary$createTime": "<p>The time at which the trained model inference job was created.</p>",
        "TrainedModelInferenceJobSummary$updateTime": "<p>The most recent time at which the trained model inference job was updated.</p>",
        "TrainedModelSummary$createTime": "<p>The time at which the trained model was created.</p>",
        "TrainedModelSummary$updateTime": "<p>The most recent time at which the trained model was updated.</p>",
        "TrainingDatasetSummary$createTime": "<p>The time at which the training dataset was created.</p>",
        "TrainingDatasetSummary$updateTime": "<p>The most recent time at which the training dataset was updated.</p>"
      }
    },
    "TagKey": {
      "base": null,
      "refs": {
        "TagKeys$member": null,
        "TagMap$key": null
      }
    },
    "TagKeys": {
      "base": null,
      "refs": {
        "UntagResourceRequest$tagKeys": "<p>The key values of tags that you want to remove.</p>"
      }
    },
    "TagMap": {
      "base": null,
      "refs": {
        "CreateAudienceModelRequest$tags": "<p>The optional metadata that you apply to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms ML considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>",
        "CreateConfiguredAudienceModelRequest$tags": "<p>The optional metadata that you apply to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms ML considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>",
        "CreateConfiguredModelAlgorithmAssociationRequest$tags": "<p>The optional metadata that you apply to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms ML considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>",
        "CreateConfiguredModelAlgorithmRequest$tags": "<p>The optional metadata that you apply to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms ML considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>",
        "CreateMLInputChannelRequest$tags": "<p>The optional metadata that you apply to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms ML considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>",
        "CreateTrainedModelRequest$tags": "<p>The optional metadata that you apply to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms ML considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>",
        "CreateTrainingDatasetRequest$tags": "<p>The optional metadata that you apply to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms ML considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>",
        "GetAudienceGenerationJobResponse$tags": "<p>The tags that are associated to this audience generation job.</p>",
        "GetAudienceModelResponse$tags": "<p>The tags that are assigned to the audience model.</p>",
        "GetConfiguredAudienceModelResponse$tags": "<p>The tags that are associated to this configured audience model.</p>",
        "GetConfiguredModelAlgorithmAssociationResponse$tags": "<p>The optional metadata that you applied to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms ML considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>",
        "GetConfiguredModelAlgorithmResponse$tags": "<p>The optional metadata that you applied to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms ML considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>",
        "GetMLInputChannelResponse$tags": "<p>The optional metadata that you applied to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms ML considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>",
        "GetTrainedModelInferenceJobResponse$tags": "<p>The optional metadata that you applied to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms ML considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>",
        "GetTrainedModelResponse$tags": "<p>The optional metadata that you applied to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms ML considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>",
        "GetTrainingDatasetResponse$tags": "<p>The tags that are assigned to this training dataset.</p>",
        "ListTagsForResourceResponse$tags": "<p>The tags that are associated with the resource.</p>",
        "StartAudienceGenerationJobRequest$tags": "<p>The optional metadata that you apply to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms ML considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>",
        "StartTrainedModelInferenceJobRequest$tags": "<p>The optional metadata that you apply to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms ML considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>",
        "TagResourceRequest$tags": "<p>The optional metadata that you apply to the resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.</p> <p>The following basic restrictions apply to tags:</p> <ul> <li> <p>Maximum number of tags per resource - 50.</p> </li> <li> <p>For each resource, each tag key must be unique, and each tag key can have only one value.</p> </li> <li> <p>Maximum key length - 128 Unicode characters in UTF-8.</p> </li> <li> <p>Maximum value length - 256 Unicode characters in UTF-8.</p> </li> <li> <p>If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.</p> </li> <li> <p>Tag keys and values are case sensitive.</p> </li> <li> <p>Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for AWS use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Clean Rooms considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.</p> </li> </ul>"
      }
    },
    "TagOnCreatePolicy": {
      "base": null,
      "refs": {
        "CreateConfiguredAudienceModelRequest$childResourceTagOnCreatePolicy": "<p>Configure how the service tags audience generation jobs created using this configured audience model. If you specify <code>NONE</code>, the tags from the <a>StartAudienceGenerationJob</a> request determine the tags of the audience generation job. If you specify <code>FROM_PARENT_RESOURCE</code>, the audience generation job inherits the tags from the configured audience model, by default. Tags in the <a>StartAudienceGenerationJob</a> will override the default.</p> <p>When the client is in a different account than the configured audience model, the tags from the client are never applied to a resource in the caller's account.</p>",
        "GetConfiguredAudienceModelResponse$childResourceTagOnCreatePolicy": "<p>Provides the <code>childResourceTagOnCreatePolicy</code> that was used for this configured audience model.</p>"
      }
    },
    "TagResourceRequest": {
      "base": null,
      "refs": {
      }
    },
    "TagResourceResponse": {
      "base": null,
      "refs": {
      }
    },
    "TagValue": {
      "base": null,
      "refs": {
        "TagMap$value": null
      }
    },
    "TaggableArn": {
      "base": null,
      "refs": {
        "ListTagsForResourceRequest$resourceArn": "<p>The Amazon Resource Name (ARN) of the resource that you are interested in.</p>",
        "TagResourceRequest$resourceArn": "<p>The Amazon Resource Name (ARN) of the resource that you want to assign tags.</p>",
        "UntagResourceRequest$resourceArn": "<p>The Amazon Resource Name (ARN) of the resource that you want to remove tags from.</p>"
      }
    },
    "ThrottlingException": {
      "base": "<p>The request was denied due to request throttling.</p>",
      "refs": {
      }
    },
    "TrainedModelArn": {
      "base": null,
      "refs": {
        "CancelTrainedModelRequest$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model job that you want to cancel.</p>",
        "CollaborationTrainedModelExportJobSummary$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model that is being exported.</p>",
        "CollaborationTrainedModelInferenceJobSummary$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model that is used for the trained model inference job.</p>",
        "CollaborationTrainedModelSummary$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model.</p>",
        "CreateTrainedModelResponse$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model.</p>",
        "DeleteTrainedModelOutputRequest$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model whose output you want to delete.</p>",
        "GetCollaborationTrainedModelRequest$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model that you want to return information about.</p>",
        "GetCollaborationTrainedModelResponse$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model.</p>",
        "GetTrainedModelInferenceJobResponse$trainedModelArn": "<p>The Amazon Resource Name (ARN) for the trained model that was used for the trained model inference job.</p>",
        "GetTrainedModelRequest$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model that you are interested in.</p>",
        "GetTrainedModelResponse$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model.</p>",
        "IncrementalTrainingDataChannel$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the base trained model to use for incremental training. This model serves as the starting point for the incremental training process.</p>",
        "ListCollaborationTrainedModelExportJobsRequest$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model that was used to create the export jobs that you are interested in.</p>",
        "ListCollaborationTrainedModelInferenceJobsRequest$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model that was used to create the trained model inference jobs that you are interested in.</p>",
        "ListTrainedModelInferenceJobsRequest$trainedModelArn": "<p>The Amazon Resource Name (ARN) of a trained model that was used to create the trained model inference jobs that you are interested in.</p>",
        "ListTrainedModelVersionsRequest$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model for which to list versions.</p>",
        "StartTrainedModelExportJobRequest$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model that you want to export.</p>",
        "StartTrainedModelInferenceJobRequest$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model that is used for this trained model inference job.</p>",
        "TrainedModelInferenceJobSummary$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model that is used for the trained model inference job.</p>",
        "TrainedModelSummary$trainedModelArn": "<p>The Amazon Resource Name (ARN) of the trained model.</p>"
      }
    },
    "TrainedModelArtifactMaxSize": {
      "base": "<p>Specifies the maximum size limit for trained model artifacts. This configuration helps control storage costs and ensures that trained models don't exceed specified size constraints. The size limit applies to the total size of all artifacts produced by the training job.</p>",
      "refs": {
        "TrainedModelsConfigurationPolicy$maxArtifactSize": "<p>The maximum size limit for trained model artifacts as defined in the configuration policy. This setting helps enforce consistent size limits across trained models in the collaboration.</p>"
      }
    },
    "TrainedModelArtifactMaxSizeUnitType": {
      "base": null,
      "refs": {
        "TrainedModelArtifactMaxSize$unit": "<p>The unit of measurement for the maximum artifact size. Valid values include common storage units such as bytes, kilobytes, megabytes, gigabytes, and terabytes.</p>"
      }
    },
    "TrainedModelArtifactMaxSizeValue": {
      "base": null,
      "refs": {
        "TrainedModelArtifactMaxSize$value": "<p>The numerical value for the maximum artifact size limit. This value is interpreted according to the specified unit.</p>"
      }
    },
    "TrainedModelExportFileType": {
      "base": null,
      "refs": {
        "TrainedModelExportFileTypeList$member": null
      }
    },
    "TrainedModelExportFileTypeList": {
      "base": null,
      "refs": {
        "TrainedModelExportsConfigurationPolicy$filesToExport": "<p>The files that are exported during the trained model export job.</p>"
      }
    },
    "TrainedModelExportJobStatus": {
      "base": null,
      "refs": {
        "CollaborationTrainedModelExportJobSummary$status": "<p>The status of the trained model.</p>"
      }
    },
    "TrainedModelExportOutputConfiguration": {
      "base": "<p>Information about the output of the trained model export job.</p>",
      "refs": {
        "CollaborationTrainedModelExportJobSummary$outputConfiguration": null,
        "StartTrainedModelExportJobRequest$outputConfiguration": "<p>The output configuration information for the trained model export job.</p>"
      }
    },
    "TrainedModelExportReceiverMember": {
      "base": "<p>Provides information about the member who will receive trained model exports.</p>",
      "refs": {
        "TrainedModelExportReceiverMembers$member": null
      }
    },
    "TrainedModelExportReceiverMembers": {
      "base": null,
      "refs": {
        "TrainedModelExportOutputConfiguration$members": "<p>The members that will received the exported trained model output.</p>"
      }
    },
    "TrainedModelExportsConfigurationPolicy": {
      "base": "<p>Information about how the trained model exports are configured.</p>",
      "refs": {
        "PrivacyConfigurationPolicies$trainedModelExports": "<p>Specifies who will receive the trained model export.</p>"
      }
    },
    "TrainedModelExportsMaxSize": {
      "base": "<p>The maximum size of the trained model metrics that can be exported. If the trained model metrics dataset is larger than this value, it will not be exported.</p>",
      "refs": {
        "TrainedModelExportsConfigurationPolicy$maxSize": "<p>The maximum size of the data that can be exported.</p>"
      }
    },
    "TrainedModelExportsMaxSizeUnitType": {
      "base": null,
      "refs": {
        "TrainedModelExportsMaxSize$unit": "<p>The unit of measurement for the data size.</p>"
      }
    },
    "TrainedModelExportsMaxSizeValue": {
      "base": null,
      "refs": {
        "TrainedModelExportsMaxSize$value": "<p>The maximum size of the dataset to export.</p>"
      }
    },
    "TrainedModelInferenceJobArn": {
      "base": null,
      "refs": {
        "CancelTrainedModelInferenceJobRequest$trainedModelInferenceJobArn": "<p>The Amazon Resource Name (ARN) of the trained model inference job that you want to cancel.</p>",
        "CollaborationTrainedModelInferenceJobSummary$trainedModelInferenceJobArn": "<p>The Amazon Resource Name (ARN) of the trained model inference job.</p>",
        "GetTrainedModelInferenceJobRequest$trainedModelInferenceJobArn": "<p>Provides the Amazon Resource Name (ARN) of the trained model inference job that you are interested in.</p>",
        "GetTrainedModelInferenceJobResponse$trainedModelInferenceJobArn": "<p>The Amazon Resource Name (ARN) of the trained model inference job.</p>",
        "StartTrainedModelInferenceJobResponse$trainedModelInferenceJobArn": "<p>The Amazon Resource Name (ARN) of the trained model inference job.</p>",
        "TrainedModelInferenceJobSummary$trainedModelInferenceJobArn": "<p>The Amazon Resource Name (ARN) of the trained model inference job.</p>"
      }
    },
    "TrainedModelInferenceJobList": {
      "base": null,
      "refs": {
        "ListTrainedModelInferenceJobsResponse$trainedModelInferenceJobs": "<p>Returns the requested trained model inference jobs.</p>"
      }
    },
    "TrainedModelInferenceJobStatus": {
      "base": null,
      "refs": {
        "CollaborationTrainedModelInferenceJobSummary$status": "<p>The status of the trained model inference job.</p>",
        "GetTrainedModelInferenceJobResponse$status": "<p>The status of the trained model inference job.</p>",
        "TrainedModelInferenceJobSummary$status": "<p>The status of the trained model inference job.</p>"
      }
    },
    "TrainedModelInferenceJobSummary": {
      "base": "<p>Provides information about the trained model inference job.</p>",
      "refs": {
        "TrainedModelInferenceJobList$member": null
      }
    },
    "TrainedModelInferenceJobsConfigurationPolicy": {
      "base": "<p>Provides configuration information for the trained model inference job.</p>",
      "refs": {
        "PrivacyConfigurationPolicies$trainedModelInferenceJobs": "<p>Specifies who will receive the trained model inference jobs.</p>"
      }
    },
    "TrainedModelInferenceMaxOutputSize": {
      "base": "<p>Information about the maximum output size for a trained model inference job.</p>",
      "refs": {
        "TrainedModelInferenceJobsConfigurationPolicy$maxOutputSize": "<p>The maximum allowed size of the output of the trained model inference job.</p>"
      }
    },
    "TrainedModelInferenceMaxOutputSizeUnitType": {
      "base": null,
      "refs": {
        "TrainedModelInferenceMaxOutputSize$unit": "<p>The measurement unit to use.</p>"
      }
    },
    "TrainedModelInferenceMaxOutputSizeValue": {
      "base": null,
      "refs": {
        "TrainedModelInferenceMaxOutputSize$value": "<p>The maximum output size value.</p>"
      }
    },
    "TrainedModelList": {
      "base": null,
      "refs": {
        "ListTrainedModelVersionsResponse$trainedModels": "<p>A list of trained model versions that match the specified criteria. Each entry contains summary information about a trained model version, including its version identifier, status, and creation details.</p>",
        "ListTrainedModelsResponse$trainedModels": "<p>The list of trained models.</p>"
      }
    },
    "TrainedModelStatus": {
      "base": null,
      "refs": {
        "CollaborationTrainedModelSummary$status": "<p>The status of the trained model.</p>",
        "GetCollaborationTrainedModelResponse$status": "<p>The status of the trained model.</p>",
        "GetTrainedModelResponse$status": "<p>The status of the trained model.</p>",
        "ListTrainedModelVersionsRequest$status": "<p>Filter the results to only include trained model versions with the specified status. Valid values include <code>CREATE_PENDING</code>, <code>CREATE_IN_PROGRESS</code>, <code>ACTIVE</code>, <code>CREATE_FAILED</code>, and others.</p>",
        "TrainedModelSummary$status": "<p>The status of the trained model.</p>"
      }
    },
    "TrainedModelSummary": {
      "base": "<p>Summary information about the trained model.</p>",
      "refs": {
        "TrainedModelList$member": null
      }
    },
    "TrainedModelsConfigurationPolicy": {
      "base": "<p>The configuration policy for the trained models.</p>",
      "refs": {
        "PrivacyConfigurationPolicies$trainedModels": "<p>Specifies who will receive the trained models.</p>"
      }
    },
    "TrainingDatasetArn": {
      "base": null,
      "refs": {
        "AudienceModelSummary$trainingDatasetArn": "<p>The Amazon Resource Name (ARN) of the training dataset that was used for the audience model.</p>",
        "CreateAudienceModelRequest$trainingDatasetArn": "<p>The Amazon Resource Name (ARN) of the training dataset for this audience model.</p>",
        "CreateTrainingDatasetResponse$trainingDatasetArn": "<p>The Amazon Resource Name (ARN) of the training dataset resource.</p>",
        "DeleteTrainingDatasetRequest$trainingDatasetArn": "<p>The Amazon Resource Name (ARN) of the training dataset that you want to delete.</p>",
        "GetAudienceModelResponse$trainingDatasetArn": "<p>The Amazon Resource Name (ARN) of the training dataset that was used for this audience model.</p>",
        "GetTrainingDatasetRequest$trainingDatasetArn": "<p>The Amazon Resource Name (ARN) of the training dataset that you are interested in.</p>",
        "GetTrainingDatasetResponse$trainingDatasetArn": "<p>The Amazon Resource Name (ARN) of the training dataset.</p>",
        "TrainingDatasetSummary$trainingDatasetArn": "<p>The Amazon Resource Name (ARN) of the training dataset.</p>"
      }
    },
    "TrainingDatasetList": {
      "base": null,
      "refs": {
        "ListTrainingDatasetsResponse$trainingDatasets": "<p>The training datasets that match the request.</p>"
      }
    },
    "TrainingDatasetStatus": {
      "base": null,
      "refs": {
        "GetTrainingDatasetResponse$status": "<p>The status of the training dataset.</p>",
        "TrainingDatasetSummary$status": "<p>The status of the training dataset.</p>"
      }
    },
    "TrainingDatasetSummary": {
      "base": "<p>Provides information about the training dataset.</p>",
      "refs": {
        "TrainingDatasetList$member": null
      }
    },
    "TrainingInputMode": {
      "base": null,
      "refs": {
        "CreateTrainedModelRequest$trainingInputMode": "<p>The input mode for accessing the training data. This parameter determines how the training data is made available to the training algorithm. Valid values are:</p> <ul> <li> <p> <code>File</code> - The training data is downloaded to the training instance and made available as files.</p> </li> <li> <p> <code>FastFile</code> - The training data is streamed directly from Amazon S3 to the training algorithm, providing faster access for large datasets.</p> </li> <li> <p> <code>Pipe</code> - The training data is streamed to the training algorithm using named pipes, which can improve performance for certain algorithms.</p> </li> </ul>",
        "GetCollaborationTrainedModelResponse$trainingInputMode": "<p>The input mode that was used for accessing the training data when this trained model was created. This indicates how the training data was made available to the training algorithm.</p>",
        "GetTrainedModelResponse$trainingInputMode": "<p>The input mode that was used for accessing the training data when this trained model was created. This indicates how the training data was made available to the training algorithm.</p>"
      }
    },
    "UUID": {
      "base": null,
      "refs": {
        "AudienceGenerationJobSummary$collaborationId": "<p>The identifier of the collaboration that contains this audience generation job.</p>",
        "CancelTrainedModelInferenceJobRequest$membershipIdentifier": "<p>The membership ID of the trained model inference job that you want to cancel.</p>",
        "CancelTrainedModelRequest$membershipIdentifier": "<p>The membership ID of the trained model job that you want to cancel.</p>",
        "CancelTrainedModelRequest$versionIdentifier": "<p>The version identifier of the trained model to cancel. This parameter allows you to specify which version of the trained model you want to cancel when multiple versions exist.</p> <p>If <code>versionIdentifier</code> is not specified, the base model will be cancelled.</p>",
        "CollaborationConfiguredModelAlgorithmAssociationSummary$membershipIdentifier": "<p>The membership ID of the member that created the configured model algorithm association.</p>",
        "CollaborationConfiguredModelAlgorithmAssociationSummary$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the configured model algorithm association.</p>",
        "CollaborationMLInputChannelSummary$membershipIdentifier": "<p>The membership ID of the membership that contains the ML input channel.</p>",
        "CollaborationMLInputChannelSummary$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the ML input channel.</p>",
        "CollaborationTrainedModelExportJobSummary$trainedModelVersionIdentifier": "<p>The version identifier of the trained model that was exported in this job.</p>",
        "CollaborationTrainedModelExportJobSummary$membershipIdentifier": "<p>The membership ID of the member that created the trained model export job.</p>",
        "CollaborationTrainedModelExportJobSummary$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the trained model export job.</p>",
        "CollaborationTrainedModelInferenceJobSummary$membershipIdentifier": "<p>The membership ID of the membership that contains the trained model inference job.</p>",
        "CollaborationTrainedModelInferenceJobSummary$trainedModelVersionIdentifier": "<p>The version identifier of the trained model that was used for inference in this job.</p>",
        "CollaborationTrainedModelInferenceJobSummary$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the trained model inference job.</p>",
        "CollaborationTrainedModelSummary$versionIdentifier": "<p>The version identifier of this trained model version.</p>",
        "CollaborationTrainedModelSummary$membershipIdentifier": "<p>The membership ID of the member that created the trained model.</p>",
        "CollaborationTrainedModelSummary$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the trained model.</p>",
        "ConfiguredModelAlgorithmAssociationSummary$membershipIdentifier": "<p>The membership ID of the member that created the configured model algorithm association.</p>",
        "ConfiguredModelAlgorithmAssociationSummary$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the configured model algorithm association.</p>",
        "CreateConfiguredModelAlgorithmAssociationRequest$membershipIdentifier": "<p>The membership ID of the member who is associating this configured model algorithm.</p>",
        "CreateMLInputChannelRequest$membershipIdentifier": "<p>The membership ID of the member that is creating the ML input channel.</p>",
        "CreateTrainedModelRequest$membershipIdentifier": "<p>The membership ID of the member that is creating the trained model.</p>",
        "CreateTrainedModelResponse$versionIdentifier": "<p>The unique version identifier assigned to the newly created trained model. This identifier can be used to reference this specific version of the trained model in subsequent operations such as inference jobs or incremental training.</p> <p>The initial version identifier for the base version of the trained model is \"NULL\".</p>",
        "DeleteConfiguredModelAlgorithmAssociationRequest$membershipIdentifier": "<p>The membership ID of the member that is deleting the configured model algorithm association.</p>",
        "DeleteMLConfigurationRequest$membershipIdentifier": "<p>The membership ID of the of the member that is deleting the ML modeling configuration.</p>",
        "DeleteMLInputChannelDataRequest$membershipIdentifier": "<p>The membership ID of the membership that contains the ML input channel you want to delete.</p>",
        "DeleteTrainedModelOutputRequest$membershipIdentifier": "<p>The membership ID of the member that is deleting the trained model output.</p>",
        "DeleteTrainedModelOutputRequest$versionIdentifier": "<p>The version identifier of the trained model to delete. If not specified, the operation will delete the base version of the trained model. When specified, only the particular version will be deleted.</p>",
        "GetAudienceGenerationJobResponse$collaborationId": "<p>The identifier of the collaboration that this audience generation job is associated with.</p>",
        "GetCollaborationConfiguredModelAlgorithmAssociationRequest$collaborationIdentifier": "<p>The collaboration ID for the collaboration that contains the configured model algorithm association that you want to return information about.</p>",
        "GetCollaborationConfiguredModelAlgorithmAssociationResponse$membershipIdentifier": "<p>The membership ID of the member that created the configured model algorithm association.</p>",
        "GetCollaborationConfiguredModelAlgorithmAssociationResponse$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the configured model algorithm association.</p>",
        "GetCollaborationMLInputChannelRequest$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the ML input channel that you want to get.</p>",
        "GetCollaborationMLInputChannelResponse$membershipIdentifier": "<p>The membership ID of the membership that contains the ML input channel.</p>",
        "GetCollaborationMLInputChannelResponse$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the ML input channel.</p>",
        "GetCollaborationTrainedModelRequest$collaborationIdentifier": "<p>The collaboration ID that contains the trained model that you want to return information about.</p>",
        "GetCollaborationTrainedModelRequest$versionIdentifier": "<p>The version identifier of the trained model to retrieve. If not specified, the operation returns information about the latest version of the trained model.</p>",
        "GetCollaborationTrainedModelResponse$membershipIdentifier": "<p>The membership ID of the member that created the trained model.</p>",
        "GetCollaborationTrainedModelResponse$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the trained model.</p>",
        "GetCollaborationTrainedModelResponse$versionIdentifier": "<p>The version identifier of the trained model. This unique identifier distinguishes this version from other versions of the same trained model.</p>",
        "GetConfiguredModelAlgorithmAssociationRequest$membershipIdentifier": "<p>The membership ID of the member that created the configured model algorithm association.</p>",
        "GetConfiguredModelAlgorithmAssociationResponse$membershipIdentifier": "<p>The membership ID of the member that created the configured model algorithm association.</p>",
        "GetConfiguredModelAlgorithmAssociationResponse$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the configured model algorithm association.</p>",
        "GetMLConfigurationRequest$membershipIdentifier": "<p>The membership ID of the member that owns the ML configuration you want to return information about.</p>",
        "GetMLConfigurationResponse$membershipIdentifier": "<p>The membership ID of the member that owns the ML configuration you requested.</p>",
        "GetMLInputChannelRequest$membershipIdentifier": "<p>The membership ID of the membership that contains the ML input channel that you want to get.</p>",
        "GetMLInputChannelResponse$membershipIdentifier": "<p>The membership ID of the membership that contains the ML input channel.</p>",
        "GetMLInputChannelResponse$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the ML input channel.</p>",
        "GetMLInputChannelResponse$protectedQueryIdentifier": "<p>The ID of the protected query that was used to create the ML input channel.</p>",
        "GetTrainedModelInferenceJobRequest$membershipIdentifier": "<p>Provides the membership ID of the membership that contains the trained model inference job that you are interested in.</p>",
        "GetTrainedModelInferenceJobResponse$trainedModelVersionIdentifier": "<p>The version identifier of the trained model used for this inference job. This identifies the specific version of the trained model that was used to generate the inference results.</p>",
        "GetTrainedModelInferenceJobResponse$membershipIdentifier": "<p>The membership ID of the membership that contains the trained model inference job.</p>",
        "GetTrainedModelRequest$membershipIdentifier": "<p>The membership ID of the member that created the trained model that you are interested in.</p>",
        "GetTrainedModelRequest$versionIdentifier": "<p>The version identifier of the trained model to retrieve. If not specified, the operation returns information about the latest version of the trained model.</p>",
        "GetTrainedModelResponse$membershipIdentifier": "<p>The membership ID of the member that created the trained model.</p>",
        "GetTrainedModelResponse$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the trained model.</p>",
        "GetTrainedModelResponse$versionIdentifier": "<p>The version identifier of the trained model. This unique identifier distinguishes this version from other versions of the same trained model.</p>",
        "IncrementalTrainingDataChannel$versionIdentifier": "<p>The version identifier of the base trained model to use for incremental training. If not specified, the latest version of the trained model is used.</p>",
        "IncrementalTrainingDataChannelOutput$versionIdentifier": "<p>The version identifier of the trained model that was used for incremental training.</p>",
        "ListAudienceGenerationJobsRequest$collaborationId": "<p>The identifier of the collaboration that contains the audience generation jobs that you are interested in.</p>",
        "ListCollaborationConfiguredModelAlgorithmAssociationsRequest$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the configured model algorithm associations that you are interested in.</p>",
        "ListCollaborationMLInputChannelsRequest$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the ML input channels that you want to list.</p>",
        "ListCollaborationTrainedModelExportJobsRequest$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the trained model export jobs that you are interested in.</p>",
        "ListCollaborationTrainedModelExportJobsRequest$trainedModelVersionIdentifier": "<p>The version identifier of the trained model to filter export jobs by. When specified, only export jobs for this specific version of the trained model are returned.</p>",
        "ListCollaborationTrainedModelInferenceJobsRequest$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the trained model inference jobs that you are interested in.</p>",
        "ListCollaborationTrainedModelInferenceJobsRequest$trainedModelVersionIdentifier": "<p>The version identifier of the trained model to filter inference jobs by. When specified, only inference jobs that used this specific version of the trained model are returned.</p>",
        "ListCollaborationTrainedModelsRequest$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the trained models you are interested in.</p>",
        "ListConfiguredModelAlgorithmAssociationsRequest$membershipIdentifier": "<p>The membership ID of the member that created the configured model algorithm associations you are interested in.</p>",
        "ListMLInputChannelsRequest$membershipIdentifier": "<p>The membership ID of the membership that contains the ML input channels that you want to list.</p>",
        "ListTrainedModelInferenceJobsRequest$membershipIdentifier": "<p>The membership </p>",
        "ListTrainedModelInferenceJobsRequest$trainedModelVersionIdentifier": "<p>The version identifier of the trained model to filter inference jobs by. When specified, only inference jobs that used this specific version of the trained model are returned.</p>",
        "ListTrainedModelVersionsRequest$membershipIdentifier": "<p>The membership identifier for the collaboration that contains the trained model.</p>",
        "ListTrainedModelsRequest$membershipIdentifier": "<p>The membership ID of the member that created the trained models you are interested in.</p>",
        "MLInputChannelSummary$membershipIdentifier": "<p>The membership ID of the membership that contains the ML input channel.</p>",
        "MLInputChannelSummary$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the ML input channel.</p>",
        "MLInputChannelSummary$protectedQueryIdentifier": "<p>The ID of the protected query that was used to create the ML input channel.</p>",
        "PutMLConfigurationRequest$membershipIdentifier": "<p>The membership ID of the member that is being configured.</p>",
        "StartAudienceGenerationJobRequest$collaborationId": "<p>The identifier of the collaboration that contains the audience generation job.</p>",
        "StartTrainedModelExportJobRequest$trainedModelVersionIdentifier": "<p>The version identifier of the trained model to export. This specifies which version of the trained model should be exported to the specified destination.</p>",
        "StartTrainedModelExportJobRequest$membershipIdentifier": "<p>The membership ID of the member that is receiving the exported trained model artifacts.</p>",
        "StartTrainedModelInferenceJobRequest$membershipIdentifier": "<p>The membership ID of the membership that contains the trained model inference job.</p>",
        "StartTrainedModelInferenceJobRequest$trainedModelVersionIdentifier": "<p>The version identifier of the trained model to use for inference. This specifies which version of the trained model should be used to generate predictions on the input data.</p>",
        "TrainedModelInferenceJobSummary$membershipIdentifier": "<p>The membership ID of the membership that contains the trained model inference job.</p>",
        "TrainedModelInferenceJobSummary$trainedModelVersionIdentifier": "<p>The version identifier of the trained model that was used for inference in this job.</p>",
        "TrainedModelInferenceJobSummary$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the trained model inference job.</p>",
        "TrainedModelSummary$versionIdentifier": "<p>The version identifier of this trained model version.</p>",
        "TrainedModelSummary$membershipIdentifier": "<p>The membership ID of the member that created the trained model.</p>",
        "TrainedModelSummary$collaborationIdentifier": "<p>The collaboration ID of the collaboration that contains the trained model.</p>"
      }
    },
    "UntagResourceRequest": {
      "base": null,
      "refs": {
      }
    },
    "UntagResourceResponse": {
      "base": null,
      "refs": {
      }
    },
    "UpdateConfiguredAudienceModelRequest": {
      "base": null,
      "refs": {
      }
    },
    "UpdateConfiguredAudienceModelResponse": {
      "base": null,
      "refs": {
      }
    },
    "ValidationException": {
      "base": "<p>The request parameters for this request are incorrect.</p>",
      "refs": {
      }
    },
    "WorkerComputeConfiguration": {
      "base": "<p>Configuration information about the compute workers that perform the transform job.</p>",
      "refs": {
        "ComputeConfiguration$worker": "<p>The worker instances that will perform the compute work.</p>"
      }
    },
    "WorkerComputeConfigurationNumberInteger": {
      "base": null,
      "refs": {
        "WorkerComputeConfiguration$number": "<p>The number of compute workers that are used.</p>"
      }
    },
    "WorkerComputeType": {
      "base": null,
      "refs": {
        "WorkerComputeConfiguration$type": "<p>The instance type of the compute workers that are used.</p>"
      }
    }
  }
}
